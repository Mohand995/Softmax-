{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 809,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris[\"data\"]\n",
    "y = iris[\"target\"]\n",
    "df = pd.DataFrame({fname: values for fname, values in zip(iris[\"feature_names\"], X.T)})\n",
    "df[\"target\"] = y\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 810,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = StratifiedShuffleSplit(n_splits=3, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(df, df[\"target\"]):\n",
    "    strat_train_set = df.loc[train_index]\n",
    "    strat_test_set = df.loc[test_index]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train=strat_train_set.iloc[:,[0,1,2,3]],strat_train_set.iloc[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test,y_test=strat_test_set.iloc[:,[0,1,2,3]],strat_test_set.iloc[:,4]\n",
    "X_test=np.array(X_test)\n",
    "y_test=np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 4)"
      ]
     },
     "execution_count": 814,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train=np.array(X_train)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120,)"
      ]
     },
     "execution_count": 815,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train=np.array(y_train)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One_hot _encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 3)"
      ]
     },
     "execution_count": 816,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder \n",
    "en=OneHotEncoder(sparse=False)\n",
    "y_train_encoded=en.fit_transform(y_train.reshape(-1,1))\n",
    "y_train_encoded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soft_max_implmention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_max(z):\n",
    "    exp=np.exp(z-np.max(z))\n",
    "    for i in range(len(z)):\n",
    "        exp[i]/=np.sum(exp[i])\n",
    "    return exp\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini_batch optimiztion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mini_batch(x,y,y_encoded,batch_size):\n",
    "    for i in range(0,len(x),batch_size):\n",
    "        yield x[i:i+batch_size],y[i:i+batch_size],y_encoded[i:i+batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mini_batch_fit(X,y,batch_size,lr,iterations,c):\n",
    "    m,n=X.shape ##shape of trainning data\n",
    "    theta=np.random.random((n,c)) ##shape of theta (no of feautures vs no of classes)\n",
    "    b=np.random.random(c) ##shape of bias is (no of classes vs 1)\n",
    "    losses=[]\n",
    "    for i in range(iterations):\n",
    "        for x_batch,y_batch,y_encoded_batch in generate_mini_batch(X,y,y_train_encoded,batch_size): \n",
    "           \n",
    "            z=x_batch@theta+b  ##hypothesis\n",
    "            \n",
    "            y_hat=soft_max(z) ##convert hypothesis to probability\n",
    "            \n",
    "            theta_grad=(1/m)*np.dot(x_batch.T,(y_hat-y_encoded_batch)) ##cal theta gradient\n",
    "            b_grad =(1/m)*np.sum(y_hat - y_encoded_batch)  ##cal bias gradient\n",
    "            \n",
    "            theta=theta-lr*theta_grad  ##update theta\n",
    "            b=b-lr*b_grad            ##update bias\n",
    "            loss = -np.mean(np.log(y_hat[np.arange(len(y_batch)), y_batch.astype(np.int32)])) ##calculate loss by indexing the probabilites(in yhat)\n",
    "            #with value equal 1 in y_actual for each row\n",
    "            \n",
    "            losses.append(loss)\n",
    "            if i%100==0:\n",
    "                print(\"at {} iteration loss is {}\".format(i,loss))\n",
    "    return theta,b,losses\n",
    "            \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at 0 iteration loss is 1.1338685775806245\n",
      "at 0 iteration loss is 1.0291303156232925\n",
      "at 0 iteration loss is 0.8022123714991455\n",
      "at 0 iteration loss is 0.7247991194866458\n",
      "at 0 iteration loss is 0.6784498619944945\n",
      "at 100 iteration loss is 0.2740025989928258\n",
      "at 100 iteration loss is 0.1912439191372158\n",
      "at 100 iteration loss is 0.2902552145743777\n",
      "at 100 iteration loss is 0.29958872465210823\n",
      "at 100 iteration loss is 0.25112943098543455\n",
      "at 200 iteration loss is 0.1966128367392296\n",
      "at 200 iteration loss is 0.1294441168265366\n",
      "at 200 iteration loss is 0.23309981118082687\n",
      "at 200 iteration loss is 0.20848366801903584\n",
      "at 200 iteration loss is 0.18966550128181803\n",
      "at 300 iteration loss is 0.1600051857921062\n",
      "at 300 iteration loss is 0.10031083676337908\n",
      "at 300 iteration loss is 0.20817223510408353\n",
      "at 300 iteration loss is 0.1633741779835832\n",
      "at 300 iteration loss is 0.16056914184804066\n",
      "at 400 iteration loss is 0.13849069635578257\n",
      "at 400 iteration loss is 0.08307642656204563\n",
      "at 400 iteration loss is 0.19453435307874742\n",
      "at 400 iteration loss is 0.13640979754887775\n",
      "at 400 iteration loss is 0.14307228466830513\n",
      "at 500 iteration loss is 0.12421095523511244\n",
      "at 500 iteration loss is 0.07158175085168374\n",
      "at 500 iteration loss is 0.18611351904644538\n",
      "at 500 iteration loss is 0.11841358221924371\n",
      "at 500 iteration loss is 0.1310899107121192\n",
      "at 600 iteration loss is 0.11397264250938173\n",
      "at 600 iteration loss is 0.06331879978481335\n",
      "at 600 iteration loss is 0.18051457512162858\n",
      "at 600 iteration loss is 0.10550303191513037\n",
      "at 600 iteration loss is 0.12219667965208876\n",
      "at 700 iteration loss is 0.10623372806610996\n",
      "at 700 iteration loss is 0.05706619733126717\n",
      "at 700 iteration loss is 0.17660518766681463\n",
      "at 700 iteration loss is 0.09575929501359955\n",
      "at 700 iteration loss is 0.1152303688801114\n",
      "at 800 iteration loss is 0.10015630398941723\n",
      "at 800 iteration loss is 0.05215470290368326\n",
      "at 800 iteration loss is 0.1737817601272066\n",
      "at 800 iteration loss is 0.08812552398072682\n",
      "at 800 iteration loss is 0.1095605138464633\n",
      "at 900 iteration loss is 0.09524428322710692\n",
      "at 900 iteration loss is 0.04818540954106063\n",
      "at 900 iteration loss is 0.17169381892210356\n",
      "at 900 iteration loss is 0.08197119456905437\n",
      "at 900 iteration loss is 0.1048131676724358\n"
     ]
    }
   ],
   "source": [
    "theta,bias,l=mini_batch_fit(X_train,y_train,24, 0.2, 1000,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'loss')"
      ]
     },
     "execution_count": 837,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(l)\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X,w,b):\n",
    "    z=X@w+b\n",
    "    y_hat=soft_max(z)#.values)\n",
    "    return np.argmax(y_hat,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cal_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred,y_act):\n",
    "    return ((np.sum(y_pred==y_act)/len(y_pred))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.5\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(predict(X_train,theta,bias),y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test_acc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.0"
      ]
     },
     "execution_count": 825,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(predict(X_test,theta,bias),y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_data=strat_train_set.iloc[:,[0,1,2,3,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(data,folds):\n",
    "    data_split=list()\n",
    "    data_copy=data\n",
    "    fold_size=int(len(data_copy)/folds)\n",
    "    for i in range(folds):\n",
    "        fold=list()\n",
    "        while len(fold)<fold_size:\n",
    "            r=randrange(len(data_copy))\n",
    "            ind=data_copy.index[r]\n",
    "            fold.append(data_copy.loc[ind].values)\n",
    "            data_copy=data_copy.drop(ind)\n",
    "        data_split.append(np.asarray(fold))\n",
    "    return data_split\n",
    "def train_test(data,folds):\n",
    "    for i in range(folds):\n",
    "        val_set=data[i]\n",
    "        del data[i]\n",
    "        train_set=data\n",
    "        yield val_set,train_set\n",
    "        data.append(val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at 0 iteration loss is 1.719109762048829\n",
      "at 0 iteration loss is 1.3403997256240143\n",
      "at 0 iteration loss is 1.6020838529363541\n",
      "at 0 iteration loss is 2.094450681878013\n",
      "at 0 iteration loss is 2.2820095040672164\n",
      "at 0 iteration loss is 1.41648617457002\n",
      "at 0 iteration loss is 1.1945263225784433\n",
      "at 0 iteration loss is 0.9179149229680575\n",
      "at 0 iteration loss is 1.547463203143402\n",
      "at 0 iteration loss is 1.1511934347009576\n",
      "at 0 iteration loss is 1.1620631216362036\n",
      "at 0 iteration loss is 1.3206007534620814\n",
      "at 0 iteration loss is 1.0364947271553795\n",
      "at 0 iteration loss is 1.1735147773950239\n",
      "at 0 iteration loss is 0.901841610935026\n",
      "at 0 iteration loss is 1.0668545483960492\n",
      "at 0 iteration loss is 1.0578214748887622\n",
      "at 0 iteration loss is 1.0968861140791621\n",
      "at 100 iteration loss is 0.9573396426435095\n",
      "at 100 iteration loss is 0.8792790142027019\n",
      "at 100 iteration loss is 0.9070479850053259\n",
      "at 100 iteration loss is 0.9248058023766206\n",
      "at 100 iteration loss is 0.8348325001849691\n",
      "at 100 iteration loss is 0.9656439198750137\n",
      "at 100 iteration loss is 0.9443626492019259\n",
      "at 100 iteration loss is 0.7981841215276798\n",
      "at 100 iteration loss is 0.9940543107802864\n",
      "at 100 iteration loss is 1.0793029255559397\n",
      "at 100 iteration loss is 1.0133247432398194\n",
      "at 100 iteration loss is 1.0857642315470253\n",
      "at 100 iteration loss is 0.8644658204062852\n",
      "at 100 iteration loss is 1.034319804038052\n",
      "at 100 iteration loss is 0.7788791630928221\n",
      "at 100 iteration loss is 0.8871601142570142\n",
      "at 100 iteration loss is 0.9541515293591992\n",
      "at 100 iteration loss is 0.961808590753505\n",
      "at 200 iteration loss is 0.9707155139825204\n",
      "at 200 iteration loss is 0.8697112893323\n",
      "at 200 iteration loss is 0.890075728109592\n",
      "at 200 iteration loss is 0.9091086401235536\n",
      "at 200 iteration loss is 0.8365140765648666\n",
      "at 200 iteration loss is 0.9610904775069009\n",
      "at 200 iteration loss is 0.935850833009831\n",
      "at 200 iteration loss is 0.7946297880335237\n",
      "at 200 iteration loss is 0.9947257646788588\n",
      "at 200 iteration loss is 1.0684544081367833\n",
      "at 200 iteration loss is 0.9906127070813907\n",
      "at 200 iteration loss is 1.0748192759080102\n",
      "at 200 iteration loss is 0.8640526693515629\n",
      "at 200 iteration loss is 1.0223210650088632\n",
      "at 200 iteration loss is 0.7758846087542922\n",
      "at 200 iteration loss is 0.8714462002905444\n",
      "at 200 iteration loss is 0.9586429604073203\n",
      "at 200 iteration loss is 0.9550659175877974\n",
      "at 300 iteration loss is 0.980876723868343\n",
      "at 300 iteration loss is 0.8639127450684768\n",
      "at 300 iteration loss is 0.8805751354747452\n",
      "at 300 iteration loss is 0.9002210136914812\n",
      "at 300 iteration loss is 0.8387429240890537\n",
      "at 300 iteration loss is 0.9576335039775088\n",
      "at 300 iteration loss is 0.930061398524624\n",
      "at 300 iteration loss is 0.7935230432573441\n",
      "at 300 iteration loss is 0.9970199842908547\n",
      "at 300 iteration loss is 1.0600630100010122\n",
      "at 300 iteration loss is 0.978281168634014\n",
      "at 300 iteration loss is 1.0686810988627402\n",
      "at 300 iteration loss is 0.864073174770918\n",
      "at 300 iteration loss is 1.0154736809146367\n",
      "at 300 iteration loss is 0.7742469277746618\n",
      "at 300 iteration loss is 0.861868501784199\n",
      "at 300 iteration loss is 0.9617411653149441\n",
      "at 300 iteration loss is 0.9521120831543881\n",
      "at 400 iteration loss is 0.9888598935902753\n",
      "at 400 iteration loss is 0.8601180697116882\n",
      "at 400 iteration loss is 0.875011956545562\n",
      "at 400 iteration loss is 0.8949292518694809\n",
      "at 400 iteration loss is 0.841060443867247\n",
      "at 400 iteration loss is 0.9549213264238425\n",
      "at 400 iteration loss is 0.9259338938292228\n",
      "at 400 iteration loss is 0.7935819778427898\n",
      "at 400 iteration loss is 0.9995984140320182\n",
      "at 400 iteration loss is 1.0533532045303664\n",
      "at 400 iteration loss is 0.9715678538047083\n",
      "at 400 iteration loss is 1.0652631619789956\n",
      "at 400 iteration loss is 0.864340291689318\n",
      "at 400 iteration loss is 1.0110971488693472\n",
      "at 400 iteration loss is 0.7733430041766163\n",
      "at 400 iteration loss is 0.8555695711185354\n",
      "at 400 iteration loss is 0.9639349869393092\n",
      "at 400 iteration loss is 0.950848611986056\n",
      "at 500 iteration loss is 0.9952850322718547\n",
      "at 500 iteration loss is 0.8574552265165039\n",
      "at 500 iteration loss is 0.8715973253045733\n",
      "at 500 iteration loss is 0.891616255127928\n",
      "at 500 iteration loss is 0.8432450248889072\n",
      "at 500 iteration loss is 0.9527580195072078\n",
      "at 500 iteration loss is 0.9228666585641175\n",
      "at 500 iteration loss is 0.7941672690312169\n",
      "at 500 iteration loss is 1.001982847766082\n",
      "at 500 iteration loss is 1.0478829646042052\n",
      "at 500 iteration loss is 0.9679394898473879\n",
      "at 500 iteration loss is 1.063410830469854\n",
      "at 500 iteration loss is 0.8647378495376493\n",
      "at 500 iteration loss is 1.0080021318431773\n",
      "at 500 iteration loss is 0.77284930636517\n",
      "at 500 iteration loss is 0.851138621441535\n",
      "at 500 iteration loss is 0.9655447951821504\n",
      "at 500 iteration loss is 0.950352995233577\n",
      "at 600 iteration loss is 1.0005456153662053\n",
      "at 600 iteration loss is 0.8554745912505801\n",
      "at 600 iteration loss is 0.8693937878864023\n",
      "at 600 iteration loss is 0.8894328964869482\n",
      "at 600 iteration loss is 0.8452068764521858\n",
      "at 600 iteration loss is 0.9510124062950321\n",
      "at 600 iteration loss is 0.9205069823870445\n",
      "at 600 iteration loss is 0.79495670102277\n",
      "at 600 iteration loss is 1.0040372756856657\n",
      "at 600 iteration loss is 1.0433697487678306\n",
      "at 600 iteration loss is 0.9660174721953367\n",
      "at 600 iteration loss is 1.062461406153659\n",
      "at 600 iteration loss is 0.8651905234645728\n",
      "at 600 iteration loss is 1.005637679794161\n",
      "at 600 iteration loss is 0.7725881309536181\n",
      "at 600 iteration loss is 0.847844169145478\n",
      "at 600 iteration loss is 0.9667682847447926\n",
      "at 600 iteration loss is 0.9502050519025268\n",
      "at 700 iteration loss is 1.004904964551184\n",
      "at 700 iteration loss is 0.8539342013186724\n",
      "at 700 iteration loss is 0.8678966663478563\n",
      "at 700 iteration loss is 0.8879192104401138\n",
      "at 700 iteration loss is 0.8469240239592629\n",
      "at 700 iteration loss is 0.9495899636163369\n",
      "at 700 iteration loss is 0.9186411077324463\n",
      "at 700 iteration loss is 0.7957894723136405\n",
      "at 700 iteration loss is 1.0057569254601306\n",
      "at 700 iteration loss is 1.0396173335820218\n",
      "at 700 iteration loss is 0.9650404637550937\n",
      "at 700 iteration loss is 1.0620280491564835\n",
      "at 700 iteration loss is 0.8656509791747403\n",
      "at 700 iteration loss is 1.0037365213402236\n",
      "at 700 iteration loss is 0.7724586780967582\n",
      "at 700 iteration loss is 0.8452888087540666\n",
      "at 700 iteration loss is 0.9677264690602005\n",
      "at 700 iteration loss is 0.9502098141529933\n",
      "at 800 iteration loss is 1.0085478924189542\n",
      "at 800 iteration loss is 0.8526975221169849\n",
      "at 800 iteration loss is 0.8668278272351155\n",
      "at 800 iteration loss is 0.8868193828321228\n",
      "at 800 iteration loss is 0.8484062706138946\n",
      "at 800 iteration loss is 0.9484207912587023\n",
      "at 800 iteration loss is 0.9171346776925894\n",
      "at 800 iteration loss is 0.7965883300397565\n",
      "at 800 iteration loss is 1.0071812300973222\n",
      "at 800 iteration loss is 1.0364813709821217\n",
      "at 800 iteration loss is 0.9645842615213491\n",
      "at 800 iteration loss is 1.0618837446422726\n",
      "at 800 iteration loss is 0.866091339660743\n",
      "at 800 iteration loss is 1.0021609170114083\n",
      "at 800 iteration loss is 0.7724029015715522\n",
      "at 800 iteration loss is 0.8432456488621666\n",
      "at 800 iteration loss is 0.9684946703918413\n",
      "at 800 iteration loss is 0.950276591803482\n",
      "at 900 iteration loss is 1.0116097242695266\n",
      "at 900 iteration loss is 0.8516831472617634\n",
      "at 900 iteration loss is 0.8660303024074922\n",
      "at 900 iteration loss is 0.885987309052717\n",
      "at 900 iteration loss is 0.8496762651554561\n",
      "at 900 iteration loss is 0.947452555876018\n",
      "at 900 iteration loss is 0.915899778563354\n",
      "at 900 iteration loss is 0.797319434274867\n",
      "at 900 iteration loss is 1.0083588700733326\n",
      "at 900 iteration loss is 1.0338513363219786\n",
      "at 900 iteration loss is 0.9644114075530617\n",
      "at 900 iteration loss is 1.0618955547087952\n",
      "at 900 iteration loss is 0.8664968048515821\n",
      "at 900 iteration loss is 1.0008336328615426\n",
      "at 900 iteration loss is 0.7723872480501723\n",
      "at 900 iteration loss is 0.8415777706125038\n",
      "at 900 iteration loss is 0.9691212738776906\n",
      "at 900 iteration loss is 0.9503637859435627\n",
      "at 1000 iteration loss is 1.0141932395934177\n",
      "at 1000 iteration loss is 0.8508394257246705\n",
      "at 1000 iteration loss is 0.8654130728147843\n",
      "at 1000 iteration loss is 0.8853369886800506\n",
      "at 1000 iteration loss is 0.8507601881398358\n",
      "at 1000 iteration loss is 0.9466456477100976\n",
      "at 1000 iteration loss is 0.914876387247588\n",
      "at 1000 iteration loss is 0.7979712918529301\n",
      "at 1000 iteration loss is 1.0093349324448417\n",
      "at 1000 iteration loss is 1.0316401804873387\n",
      "at 1000 iteration loss is 0.9643888436441778\n",
      "at 1000 iteration loss is 1.0619862677149972\n",
      "at 1000 iteration loss is 0.8668609760252364\n",
      "at 1000 iteration loss is 0.9997064965980977\n",
      "at 1000 iteration loss is 0.7723924062148606\n",
      "at 1000 iteration loss is 0.8401974049112789\n",
      "at 1000 iteration loss is 0.9696386469146514\n",
      "at 1000 iteration loss is 0.9504529855718247\n",
      "at 1100 iteration loss is 1.0163788915541123\n",
      "at 1100 iteration loss is 0.8501313949925902\n",
      "at 1100 iteration loss is 0.8649216197284664\n",
      "at 1100 iteration loss is 0.8848159653952299\n",
      "at 1100 iteration loss is 0.8516835203644089\n",
      "at 1100 iteration loss is 0.9459697107209737\n",
      "at 1100 iteration loss is 0.9140217577040735\n",
      "at 1100 iteration loss is 0.7985436021198915\n",
      "at 1100 iteration loss is 1.010147255061085\n",
      "at 1100 iteration loss is 1.0297779544547545\n",
      "at 1100 iteration loss is 0.9644422253516087\n",
      "at 1100 iteration loss is 1.0621117041923467\n",
      "at 1100 iteration loss is 0.8671825823369762\n",
      "at 1100 iteration loss is 0.9987459545224532\n",
      "at 1100 iteration loss is 0.772407392395887\n",
      "at 1100 iteration loss is 0.8390447385037498\n",
      "at 1100 iteration loss is 0.9700694226563653\n",
      "at 1100 iteration loss is 0.9505366377091082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at 1200 iteration loss is 1.0182311725390005\n",
      "at 1200 iteration loss is 0.8495339118183427\n",
      "at 1200 iteration loss is 0.8645220018202642\n",
      "at 1200 iteration loss is 0.8843908970164863\n",
      "at 1200 iteration loss is 0.8524693590868748\n",
      "at 1200 iteration loss is 0.9454011532106102\n",
      "at 1200 iteration loss is 0.9133042387257937\n",
      "at 1200 iteration loss is 0.7990413463639056\n",
      "at 1200 iteration loss is 1.0108263314283732\n",
      "at 1200 iteration loss is 1.028207640496607\n",
      "at 1200 iteration loss is 0.9645303452046651\n",
      "at 1200 iteration loss is 1.0622472024165037\n",
      "at 1200 iteration loss is 0.867463287858105\n",
      "at 1200 iteration loss is 0.997926402599863\n",
      "at 1200 iteration loss is 0.7724260902530675\n",
      "at 1200 iteration loss is 0.8380766475379087\n",
      "at 1200 iteration loss is 0.970430125181986\n",
      "at 1200 iteration loss is 0.950612163209582\n",
      "at 1300 iteration loss is 1.019802717533291\n",
      "at 1300 iteration loss is 0.8490279517155166\n",
      "at 1300 iteration loss is 0.8641921391242391\n",
      "at 1300 iteration loss is 0.8840396110166271\n",
      "at 1300 iteration loss is 0.853137943486933\n",
      "at 1300 iteration loss is 0.9449213732791562\n",
      "at 1300 iteration loss is 0.9126995934972726\n",
      "at 1300 iteration loss is 0.7994716799550657\n",
      "at 1300 iteration loss is 1.011396379297181\n",
      "at 1300 iteration loss is 1.0268822847754027\n",
      "at 1300 iteration loss is 0.9646307219770343\n",
      "at 1300 iteration loss is 1.0623795558604983\n",
      "at 1300 iteration loss is 0.8677062802602846\n",
      "at 1300 iteration loss is 0.9972270730592919\n",
      "at 1300 iteration loss is 0.7724452139028994\n",
      "at 1300 iteration loss is 0.8372605428073937\n",
      "at 1300 iteration loss is 0.9707332878286318\n",
      "at 1300 iteration loss is 0.9506791685233462\n",
      "at 1400 iteration loss is 1.0211370503406128\n",
      "at 1400 iteration loss is 0.8485985506250223\n",
      "at 1400 iteration loss is 0.8639169802719747\n",
      "at 1400 iteration loss is 0.8837466675120632\n",
      "at 1400 iteration loss is 0.8537067134291186\n",
      "at 1400 iteration loss is 0.9445154980174149\n",
      "at 1400 iteration loss is 0.9121887491135501\n",
      "at 1400 iteration loss is 0.7998423296943762\n",
      "at 1400 iteration loss is 1.0118766078479955\n",
      "at 1400 iteration loss is 1.0257629377210022\n",
      "at 1400 iteration loss is 0.9647314438665215\n",
      "at 1400 iteration loss is 1.062502207772122\n",
      "at 1400 iteration loss is 0.8679153976761856\n",
      "at 1400 iteration loss is 0.9966305346651805\n",
      "at 1400 iteration loss is 0.772463107265674\n",
      "at 1400 iteration loss is 0.8365708903323992\n",
      "at 1400 iteration loss is 0.9709887181732139\n",
      "at 1400 iteration loss is 0.9507381466115976\n",
      "at 1500 iteration loss is 1.0222704960865296\n",
      "at 1500 iteration loss is 0.8482336104646235\n",
      "at 1500 iteration loss is 0.8636857822752436\n",
      "at 1500 iteration loss is 0.8835008380594281\n",
      "at 1500 iteration loss is 0.8541905745575689\n",
      "at 1500 iteration loss is 0.9441714854355798\n",
      "at 1500 iteration loss is 0.9117563756590961\n",
      "at 1500 iteration loss is 0.8001607994585198\n",
      "at 1500 iteration loss is 1.0122823414544142\n",
      "at 1500 iteration loss is 1.0248171196932536\n",
      "at 1500 iteration loss is 0.9648265369635262\n",
      "at 1500 iteration loss is 1.0626123958598388\n",
      "at 1500 iteration loss is 0.8680946119759593\n",
      "at 1500 iteration loss is 0.996121916570937\n",
      "at 1500 iteration loss is 0.7724790375899755\n",
      "at 1500 iteration loss is 0.8359871575191573\n",
      "at 1500 iteration loss is 0.9712042766010456\n",
      "at 1500 iteration loss is 0.9507898892823654\n",
      "at 1600 iteration loss is 1.0232335670951005\n",
      "at 1600 iteration loss is 0.847923168107004\n",
      "at 1600 iteration loss is 0.8634905504811965\n",
      "at 1600 iteration loss is 0.8832936416293042\n",
      "at 1600 iteration loss is 0.8546022193997936\n",
      "at 1600 iteration loss is 0.9438794793682822\n",
      "at 1600 iteration loss is 0.9113899555465176\n",
      "at 1600 iteration loss is 0.8004340074467041\n",
      "at 1600 iteration loss is 1.0126259162895468\n",
      "at 1600 iteration loss is 1.0240176434102763\n",
      "at 1600 iteration loss is 0.9649133308775589\n",
      "at 1600 iteration loss is 1.0627094645706587\n",
      "at 1600 iteration loss is 0.868247740485295\n",
      "at 1600 iteration loss is 0.9956884534792104\n",
      "at 1600 iteration loss is 0.77249278164682\n",
      "at 1600 iteration loss is 0.8354925362942428\n",
      "at 1600 iteration loss is 0.971386373970153\n",
      "at 1600 iteration loss is 0.9508352344013385\n",
      "at 1700 iteration loss is 1.0240520049750248\n",
      "at 1700 iteration loss is 0.8476589198449913\n",
      "at 1700 iteration loss is 0.8633251224328804\n",
      "at 1700 iteration loss is 0.8831184709656517\n",
      "at 1700 iteration loss is 0.8549524403764062\n",
      "at 1700 iteration loss is 0.9436313398753388\n",
      "at 1700 iteration loss is 0.9110791493810517\n",
      "at 1700 iteration loss is 0.800668150783757\n",
      "at 1700 iteration loss is 1.0129173627598491\n",
      "at 1700 iteration loss is 1.0233416886177908\n",
      "at 1700 iteration loss is 0.9649909603053327\n",
      "at 1700 iteration loss is 1.062793875468786\n",
      "at 1700 iteration loss is 0.8683782997146574\n",
      "at 1700 iteration loss is 0.9953191746158986\n",
      "at 1700 iteration loss is 0.7725043852233854\n",
      "at 1700 iteration loss is 0.8350731025624458\n",
      "at 1700 iteration loss is 0.9715403037915606\n",
      "at 1700 iteration loss is 0.950874966925008\n",
      "at 1800 iteration loss is 1.0247475897116467\n",
      "at 1800 iteration loss is 0.8474338921328292\n",
      "at 1800 iteration loss is 0.863184613691162\n",
      "at 1800 iteration loss is 0.8829700536139475\n",
      "at 1800 iteration loss is 0.855250411043816\n",
      "at 1800 iteration loss is 0.9434202955796052\n",
      "at 1800 iteration loss is 0.9108153463139788\n",
      "at 1800 iteration loss is 0.800868686729781\n",
      "at 1800 iteration loss is 1.0131649149046518\n",
      "at 1800 iteration loss is 1.0227700616111122\n",
      "at 1800 iteration loss is 0.9650595146881862\n",
      "at 1800 iteration loss is 1.0628666339236026\n",
      "at 1800 iteration loss is 0.8684894445509606\n",
      "at 1800 iteration loss is 0.9950046608747541\n",
      "at 1800 iteration loss is 0.7725140250370067\n",
      "at 1800 iteration loss is 0.8347172304639644\n",
      "at 1800 iteration loss is 0.9716704742276796\n",
      "at 1800 iteration loss is 0.9509097878942825\n",
      "at 1900 iteration loss is 1.025338784426776\n",
      "at 1900 iteration loss is 0.8472422003152712\n",
      "at 1900 iteration loss is 0.8630650704246372\n",
      "at 1900 iteration loss is 0.8828441063175454\n",
      "at 1900 iteration loss is 0.8555039298725484\n",
      "at 1900 iteration loss is 0.943240681389099\n",
      "at 1900 iteration loss is 0.9105913330483322\n",
      "at 1900 iteration loss is 0.8010403706644975\n",
      "at 1900 iteration loss is 1.0133753893014146\n",
      "at 1900 iteration loss is 1.022286594453293\n",
      "at 1900 iteration loss is 0.9651195584095286\n",
      "at 1900 iteration loss is 1.0629289630815557\n",
      "at 1900 iteration loss is 0.8685839568733174\n",
      "at 1900 iteration loss is 0.9947368393247737\n",
      "at 1900 iteration loss is 0.7725219309587347\n",
      "at 1900 iteration loss is 0.8344151628042592\n",
      "at 1900 iteration loss is 0.9717805773052819\n",
      "at 1900 iteration loss is 0.9509403115515163\n",
      "at 2000 iteration loss is 1.0258412595760047\n",
      "at 2000 iteration loss is 0.8470788634907442\n",
      "at 2000 iteration loss is 0.862963242559889\n",
      "at 2000 iteration loss is 0.8827371038768858\n",
      "at 2000 iteration loss is 0.8557196281971118\n",
      "at 2000 iteration loss is 0.9430877367925026\n",
      "at 2000 iteration loss is 0.9104010420253708\n",
      "at 2000 iteration loss is 0.8011873188161335\n",
      "at 2000 iteration loss is 1.0135544687608806\n",
      "at 2000 iteration loss is 1.0218776524723545\n",
      "at 2000 iteration loss is 0.9651718630451814\n",
      "at 2000 iteration loss is 1.062982123874325\n",
      "at 2000 iteration loss is 0.8686642611705754\n",
      "at 2000 iteration loss is 0.9945088031266479\n",
      "at 2000 iteration loss is 0.7725283435424795\n",
      "at 2000 iteration loss is 0.8341586826206546\n",
      "at 2000 iteration loss is 0.9718737171390206\n",
      "at 2000 iteration loss is 0.9509670727060827\n",
      "at 2100 iteration loss is 1.0262683254534009\n",
      "at 2100 iteration loss is 0.8469396574999587\n",
      "at 2100 iteration loss is 0.8628764290677673\n",
      "at 2100 iteration loss is 0.882646117816012\n",
      "at 2100 iteration loss is 0.8559031464728859\n",
      "at 2100 iteration loss is 0.9429574478695045\n",
      "at 2100 iteration loss is 0.9102393545354296\n",
      "at 2100 iteration loss is 0.8013130788939407\n",
      "at 2100 iteration loss is 1.0137069174764324\n",
      "at 2100 iteration loss is 1.0215317273999727\n",
      "at 2100 iteration loss is 0.9652172608861298\n",
      "at 2100 iteration loss is 1.0630273205395195\n",
      "at 2100 iteration loss is 0.8687324535489772\n",
      "at 2100 iteration loss is 0.9943146522681359\n",
      "at 2100 iteration loss is 0.7725334920367345\n",
      "at 2100 iteration loss is 0.8339408540551808\n",
      "at 2100 iteration loss is 0.9719525101773094\n",
      "at 2100 iteration loss is 0.9509905367434305\n",
      "at 2200 iteration loss is 1.0266312927961596\n",
      "at 2200 iteration loss is 0.8468209953813941\n",
      "at 2200 iteration loss is 0.8628023678000725\n",
      "at 2200 iteration loss is 0.8825686991481595\n",
      "at 2200 iteration loss is 0.8560592834127378\n",
      "at 2200 iteration loss is 0.9428464214815317\n",
      "at 2200 iteration loss is 0.9101019434006206\n",
      "at 2200 iteration loss is 0.8014207000657466\n",
      "at 2200 iteration loss is 1.0138367468482568\n",
      "at 2200 iteration loss is 1.0212390993223242\n",
      "at 2200 iteration loss is 0.9652565676082949\n",
      "at 2200 iteration loss is 1.0630656555790972\n",
      "at 2200 iteration loss is 0.8687903360998981\n",
      "at 2200 iteration loss is 0.9941493530507419\n",
      "at 2200 iteration loss is 0.7725375841153157\n",
      "at 2200 iteration loss is 0.8337558132712403\n",
      "at 2200 iteration loss is 0.9720191654827083\n",
      "at 2200 iteration loss is 0.9510111093321256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at 2300 iteration loss is 1.0269397756204797\n",
      "at 2300 iteration loss is 0.8467198286185976\n",
      "at 2300 iteration loss is 0.8627391538787073\n",
      "at 2300 iteration loss is 0.8825027901159549\n",
      "at 2300 iteration loss is 0.8561921222259684\n",
      "at 2300 iteration loss is 0.9427517836548256\n",
      "at 2300 iteration loss is 0.9099851451786927\n",
      "at 2300 iteration loss is 0.8015127982119535\n",
      "at 2300 iteration loss is 1.0139473455076409\n",
      "at 2300 iteration loss is 1.0209915545931811\n",
      "at 2300 iteration loss is 0.9652905441112509\n",
      "at 2300 iteration loss is 1.063098112741786\n",
      "at 2300 iteration loss is 0.8688394520664942\n",
      "at 2300 iteration loss is 0.9940086149050609\n",
      "at 2300 iteration loss is 0.772540802167974\n",
      "at 2300 iteration loss is 0.8335985971258936\n",
      "at 2300 iteration loss is 0.9720755501694663\n",
      "at 2300 iteration loss is 0.9510291449015934\n",
      "at 2400 iteration loss is 1.0272019467819056\n",
      "at 2400 iteration loss is 0.8466335647303861\n",
      "at 2400 iteration loss is 0.862685177147647\n",
      "at 2400 iteration loss is 0.8824466557666659\n",
      "at 2400 iteration loss is 0.8563051376021296\n",
      "at 2400 iteration loss is 0.9426710965316605\n",
      "at 2400 iteration loss is 0.9098858550628611\n",
      "at 2400 iteration loss is 0.8015916147927571\n",
      "at 2400 iteration loss is 1.0140415829683629\n",
      "at 2400 iteration loss is 1.0207821496794331\n",
      "at 2400 iteration loss is 0.9653198802768441\n",
      "at 2400 iteration loss is 1.0631255553938477\n",
      "at 2400 iteration loss is 0.8688811193630833\n",
      "at 2400 iteration loss is 0.9938887831396126\n",
      "at 2400 iteration loss is 0.7725433031334208\n",
      "at 2400 iteration loss is 0.8334650013098905\n",
      "at 2400 iteration loss is 0.9721232434159612\n",
      "at 2400 iteration loss is 0.9510449537719758\n",
      "at 2500 iteration loss is 1.0274247543299837\n",
      "at 2500 iteration loss is 0.8465599980531395\n",
      "at 2500 iteration loss is 0.8626390728993675\n",
      "at 2500 iteration loss is 0.8823988296603756\n",
      "at 2500 iteration loss is 0.8564012864965338\n",
      "at 2500 iteration loss is 0.942602289850368\n",
      "at 2500 iteration loss is 0.9098014396662322\n",
      "at 2500 iteration loss is 0.8016590689252986\n",
      "at 2500 iteration loss is 1.0141218934816996\n",
      "at 2500 iteration loss is 1.0206050129707833\n",
      "at 2500 iteration loss is 0.9653451907341285\n",
      "at 2500 iteration loss is 1.063148732887443\n",
      "at 2500 iteration loss is 0.8689164612633095\n",
      "at 2500 iteration loss is 0.9937867461317659\n",
      "at 2500 iteration loss is 0.7725452201273886\n",
      "at 2500 iteration loss is 0.8333514620618446\n",
      "at 2500 iteration loss is 0.9721635814360274\n",
      "at 2500 iteration loss is 0.9510588080949128\n",
      "at 2600 iteration loss is 1.0276141050465806\n",
      "at 2600 iteration loss is 0.8464972513634448\n",
      "at 2600 iteration loss is 0.8625996822257231\n",
      "at 2600 iteration loss is 0.8823580700224587\n",
      "at 2600 iteration loss is 0.8564830852594932\n",
      "at 2600 iteration loss is 0.9425436039889814\n",
      "at 2600 iteration loss is 0.9097296641754868\n",
      "at 2600 iteration loss is 0.8017168029001318\n",
      "at 2600 iteration loss is 1.0141903447252045\n",
      "at 2600 iteration loss is 1.0204551781346374\n",
      "at 2600 iteration loss is 0.9653670169530489\n",
      "at 2600 iteration loss is 1.063168290660668\n",
      "at 2600 iteration loss is 0.8689464338064935\n",
      "at 2600 iteration loss is 0.993699855413902\n",
      "at 2600 iteration loss is 0.772546664869407\n",
      "at 2600 iteration loss is 0.8332549570702084\n",
      "at 2600 iteration loss is 0.9721976951448401\n",
      "at 2600 iteration loss is 0.9510709468234856\n",
      "at 2700 iteration loss is 1.0277750203427103\n",
      "at 2700 iteration loss is 0.8464437265123681\n",
      "at 2700 iteration loss is 0.8625660196033366\n",
      "at 2700 iteration loss is 0.882323323859873\n",
      "at 2700 iteration loss is 0.8565526752224027\n",
      "at 2700 iteration loss is 0.9424935423465026\n",
      "at 2700 iteration loss is 0.9096686312212636\n",
      "at 2700 iteration loss is 0.8017662216581037\n",
      "at 2700 iteration loss is 1.0142486946361944\n",
      "at 2700 iteration loss is 1.0203284437890061\n",
      "at 2700 iteration loss is 0.9653858324386064\n",
      "at 2700 iteration loss is 1.063184781657573\n",
      "at 2700 iteration loss is 0.8689718498818566\n",
      "at 2700 iteration loss is 0.9936258571260232\n",
      "at 2700 iteration loss is 0.7725477303539744\n",
      "at 2700 iteration loss is 0.8331729221785521\n",
      "at 2700 iteration loss is 0.9722265418318438\n",
      "at 2700 iteration loss is 0.9510815799100453\n",
      "at 2800 iteration loss is 1.0279117687759807\n",
      "at 2800 iteration loss is 0.8463980626069386\n",
      "at 2800 iteration loss is 0.862537246084554\n",
      "at 2800 iteration loss is 0.8822936973070998\n",
      "at 2800 iteration loss is 0.8566118785034984\n",
      "at 2800 iteration loss is 0.9424508313542294\n",
      "at 2800 iteration loss is 0.9096167294080463\n",
      "at 2800 iteration loss is 0.801808526857919\n",
      "at 2800 iteration loss is 1.0142984388057652\n",
      "at 2800 iteration loss is 1.020221255201025\n",
      "at 2800 iteration loss is 0.965402049213686\n",
      "at 2800 iteration loss is 1.0631986777501317\n",
      "at 2800 iteration loss is 0.8689934001665398\n",
      "at 2800 iteration loss is 0.9935628333852604\n",
      "at 2800 iteration loss is 0.7725484934702209\n",
      "at 2800 iteration loss is 0.8331031812118548\n",
      "at 2800 iteration loss is 0.9722509318648909\n",
      "at 2800 iteration loss is 0.9510908918907655\n",
      "at 2900 iteration loss is 1.0280279787409632\n",
      "at 2900 iteration loss is 0.8463591005424357\n",
      "at 2900 iteration loss is 0.862512646938342\n",
      "at 2900 iteration loss is 0.8822684309439508\n",
      "at 2900 iteration loss is 0.8566622455108248\n",
      "at 2900 iteration loss is 0.9424143867811464\n",
      "at 2900 iteration loss is 0.9095725898720939\n",
      "at 2900 iteration loss is 0.80184474617859\n",
      "at 2900 iteration loss is 1.014340850236572\n",
      "at 2900 iteration loss is 1.020130604463463\n",
      "at 2900 iteration loss is 0.9654160245966054\n",
      "at 2900 iteration loss is 1.0632103804834923\n",
      "at 2900 iteration loss is 0.8690116711951543\n",
      "at 2900 iteration loss is 0.9935091522404662\n",
      "at 2900 iteration loss is 0.7725490174235179\n",
      "at 2900 iteration loss is 0.8330438867570571\n",
      "at 2900 iteration loss is 0.9722715512443909\n",
      "at 2900 iteration loss is 0.9510990449770723\n",
      "at 3000 iteration loss is 1.0281267343174614\n",
      "at 3000 iteration loss is 0.8463258528952504\n",
      "at 3000 iteration loss is 0.8624916128901685\n",
      "at 3000 iteration loss is 0.8822468791428826\n",
      "at 3000 iteration loss is 0.8567050953866551\n",
      "at 3000 iteration loss is 0.9423832852700059\n",
      "at 3000 iteration loss is 0.9095350495508457\n",
      "at 3000 iteration loss is 0.8018757584679097\n",
      "at 3000 iteration loss is 1.014377012842084\n",
      "at 3000 iteration loss is 1.0200539462023894\n",
      "at 3000 iteration loss is 0.9654280677499172\n",
      "at 3000 iteration loss is 1.0632202308345233\n",
      "at 3000 iteration loss is 0.8690271608748865\n",
      "at 3000 iteration loss is 0.9934634250162981\n",
      "at 3000 iteration loss is 0.7725493538974304\n",
      "at 3000 iteration loss is 0.8329934701243321\n",
      "at 3000 iteration loss is 0.9722889806741067\n",
      "at 3000 iteration loss is 0.9511061817433355\n",
      "at 3100 iteration loss is 1.028210656798416\n",
      "at 3100 iteration loss is 0.8462974783497133\n",
      "at 3100 iteration loss is 0.8624736243134503\n",
      "at 3100 iteration loss is 0.882228492720032\n",
      "at 3100 iteration loss is 0.8567415504452465\n",
      "at 3100 iteration loss is 0.9423567402453017\n",
      "at 3100 iteration loss is 0.9095031200870848\n",
      "at 3100 iteration loss is 0.8019023152940232\n",
      "at 3100 iteration loss is 1.014407849763416\n",
      "at 3100 iteration loss is 1.019989126358676\n",
      "at 3100 iteration loss is 0.9654384457454931\n",
      "at 3100 iteration loss is 1.0632285178816698\n",
      "at 3100 iteration loss is 0.8690402917601858\n",
      "at 3100 iteration loss is 0.9934244699912129\n",
      "at 3100 iteration loss is 0.772549544941366\n",
      "at 3100 iteration loss is 0.8329505990239806\n",
      "at 3100 iteration loss is 0.9723037116983602\n",
      "at 3100 iteration loss is 0.9511124274775383\n",
      "at 3200 iteration loss is 1.0282819740352775\n",
      "at 3200 iteration loss is 0.846273259965189\n",
      "at 3200 iteration loss is 0.8624582378665198\n",
      "at 3200 iteration loss is 0.8822128043184831\n",
      "at 3200 iteration loss is 0.8567725654959167\n",
      "at 3200 iteration loss is 0.9423340814914345\n",
      "at 3200 iteration loss is 0.9094759614785589\n",
      "at 3200 iteration loss is 0.801925059396299\n",
      "at 3200 iteration loss is 1.0144341473608898\n",
      "at 3200 iteration loss is 1.019934321987908\n",
      "at 3200 iteration loss is 0.9654473890421151\n",
      "at 3200 iteration loss is 1.0632354863974256\n",
      "at 3200 iteration loss is 0.8690514223823786\n",
      "at 3200 iteration loss is 0.9933912814885882\n",
      "at 3200 iteration loss is 0.7725496245940628\n",
      "at 3200 iteration loss is 0.8329141417409666\n",
      "at 3200 iteration loss is 0.9723161603631867\n",
      "at 3200 iteration loss is 0.9511178922456718\n",
      "at 3300 iteration loss is 1.0283425794170362\n",
      "at 3300 iteration loss is 0.8462525866991852\n",
      "at 3300 iteration loss is 0.8624450751710153\n",
      "at 3300 iteration loss is 0.8821994160658038\n",
      "at 3300 iteration loss is 0.8567989528095078\n",
      "at 3300 iteration loss is 0.942314737822279\n",
      "at 3300 iteration loss is 0.9094528597331204\n",
      "at 3300 iteration loss is 0.8019445404711518\n",
      "at 3300 iteration loss is 1.0144565755745019\n",
      "at 3300 iteration loss is 1.0198879903552596\n",
      "at 3300 iteration loss is 0.965455096354898\n",
      "at 3300 iteration loss is 1.063241343432554\n",
      "at 3300 iteration loss is 0.869060856902272\n",
      "at 3300 iteration loss is 0.9933630035845693\n",
      "at 3300 iteration loss is 0.7725496202650575\n",
      "at 3300 iteration loss is 0.8328831367899536\n",
      "at 3300 iteration loss is 0.9723266787845549\n",
      "at 3300 iteration loss is 0.9511226727094846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at 3400 iteration loss is 1.0283940820278328\n",
      "at 3400 iteration loss is 0.8462349376932226\n",
      "at 3400 iteration loss is 0.8624338132036229\n",
      "at 3400 iteration loss is 0.8821879891338844\n",
      "at 3400 iteration loss is 0.8568214033734234\n",
      "at 3400 iteration loss is 0.9422982223612604\n",
      "at 3400 iteration loss is 0.9094332079104206\n",
      "at 3400 iteration loss is 0.8019612286718243\n",
      "at 3400 iteration loss is 1.0144757052228783\n",
      "at 3400 iteration loss is 1.0198488258775176\n",
      "at 3400 iteration loss is 0.9654617389396607\n",
      "at 3400 iteration loss is 1.063246263987112\n",
      "at 3400 iteration loss is 0.869068853323778\n",
      "at 3400 iteration loss is 0.9933389077479566\n",
      "at 3400 iteration loss is 0.7725495539009828\n",
      "at 3400 iteration loss is 0.8328567671986271\n",
      "at 3400 iteration loss is 0.9723355649458378\n",
      "at 3400 iteration loss is 0.9511268537295002\n",
      "at 3500 iteration loss is 1.0284378492981354\n",
      "at 3500 iteration loss is 0.846219868904382\n",
      "at 3500 iteration loss is 0.8624241761315303\n",
      "at 3500 iteration loss is 0.8821782348958449\n",
      "at 3500 iteration loss is 0.8568405049848973\n",
      "at 3500 iteration loss is 0.9422841200301344\n",
      "at 3500 iteration loss is 0.9094164900303421\n",
      "at 3500 iteration loss is 0.801975526149884\n",
      "at 3500 iteration loss is 1.014492022713039\n",
      "at 3500 iteration loss is 1.019815723694029\n",
      "at 3500 iteration loss is 0.9654674643366163\n",
      "at 3500 iteration loss is 1.0632503958712127\n",
      "at 3500 iteration loss is 0.8690756304769016\n",
      "at 3500 iteration loss is 0.9933183738259921\n",
      "at 3500 iteration loss is 0.772549442964263\n",
      "at 3500 iteration loss is 0.8328343387034909\n",
      "at 3500 iteration loss is 0.9723430709962088\n",
      "at 3500 iteration loss is 0.9511305097796882\n",
      "at 3600 iteration loss is 1.0284750432691268\n",
      "at 3600 iteration loss is 0.8462070017293708\n",
      "at 3600 iteration loss is 0.8624159283679281\n",
      "at 3600 iteration loss is 0.8821699074275579\n",
      "at 3600 iteration loss is 0.8568567576509368\n",
      "at 3600 iteration loss is 0.9422720769092588\n",
      "at 3600 iteration loss is 0.9094022674103481\n",
      "at 3600 iteration loss is 0.8019877769207451\n",
      "at 3600 iteration loss is 1.014505942555561\n",
      "at 3600 iteration loss is 1.0197877488403213\n",
      "at 3600 iteration loss is 0.9654723996262435\n",
      "at 3600 iteration loss is 1.0632538638565685\n",
      "at 3600 iteration loss is 0.869081373950708\n",
      "at 3600 iteration loss is 0.9933008738756491\n",
      "at 3600 iteration loss is 0.7725493012504218\n",
      "at 3600 iteration loss is 0.832815261255756\n",
      "at 3600 iteration loss is 0.9723494102794815\n",
      "at 3600 iteration loss is 0.9511337061961568\n",
      "at 3700 iteration loss is 1.0285066514236803\n",
      "at 3700 iteration loss is 0.8461960133218864\n",
      "at 3700 iteration loss is 0.8624088686607825\n",
      "at 3700 iteration loss is 0.8821627971437559\n",
      "at 3700 iteration loss is 0.8568705866943367\n",
      "at 3700 iteration loss is 0.9422617911854749\n",
      "at 3700 iteration loss is 0.9093901670622332\n",
      "at 3700 iteration loss is 0.801998275295713\n",
      "at 3700 iteration loss is 1.0145178180167709\n",
      "at 3700 iteration loss is 1.0197641101589336\n",
      "at 3700 iteration loss is 0.9654766542517261\n",
      "at 3700 iteration loss is 1.06325677321304\n",
      "at 3700 iteration loss is 0.8690862411318951\n",
      "at 3700 iteration loss is 0.9932859584141314\n",
      "at 3700 iteration loss is 0.7725491395678757\n",
      "at 3700 iteration loss is 0.8327990333296231\n",
      "at 3700 iteration loss is 0.9723547632875456\n",
      "at 3700 iteration loss is 0.9511365002791867\n",
      "at 3800 iteration loss is 1.028533512895626\n",
      "at 3800 iteration loss is 0.8461866283494629\n",
      "at 3800 iteration loss is 0.8624028250581064\n",
      "at 3800 iteration loss is 0.8821567253931422\n",
      "at 3800 iteration loss is 0.856882353906216\n",
      "at 3800 iteration loss is 0.9422530054479324\n",
      "at 3800 iteration loss is 0.9093798718358727\n",
      "at 3800 iteration loss is 0.8020072730884846\n",
      "at 3800 iteration loss is 1.014527950187752\n",
      "at 3800 iteration loss is 1.0197441382170414\n",
      "at 3800 iteration loss is 0.9654803224601164\n",
      "at 3800 iteration loss is 1.0632592127153262\n",
      "at 3800 iteration loss is 0.8690903654823499\n",
      "at 3800 iteration loss is 0.9932732447257896\n",
      "at 3800 iteration loss is 0.772548966301349\n",
      "at 3800 iteration loss is 0.8327852286044927\n",
      "at 3800 iteration loss is 0.9723592827027303\n",
      "at 3800 iteration loss is 0.9511389422654564\n",
      "at 3900 iteration loss is 1.0285563407483518\n",
      "at 3900 iteration loss is 0.8461786119744625\n",
      "at 3900 iteration loss is 0.8623976506176761\n",
      "at 3900 iteration loss is 0.8821515398652512\n",
      "at 3900 iteration loss is 0.8568923670352963\n",
      "at 3900 iteration loss is 0.9422455001292119\n",
      "at 3900 iteration loss is 0.9093711120455812\n",
      "at 3900 iteration loss is 0.802014985774159\n",
      "at 3900 iteration loss is 1.0145365957069696\n",
      "at 3900 iteration loss is 1.0197272666139492\n",
      "at 3900 iteration loss is 0.9654834854103456\n",
      "at 3900 iteration loss is 1.0632612571953213\n",
      "at 3900 iteration loss is 0.8690938601697779\n",
      "at 3900 iteration loss is 0.993262406917027\n",
      "at 3900 iteration loss is 0.7725487878773637\n",
      "at 3900 iteration loss is 0.8327734846591671\n",
      "at 3900 iteration loss is 0.9723630976683012\n",
      "at 3900 iteration loss is 0.9511410761853505\n",
      "at 4000 iteration loss is 1.0285757409108685\n",
      "at 4000 iteration loss is 0.846171763876361\n",
      "at 4000 iteration loss is 0.8623932197496498\n",
      "at 4000 iteration loss is 0.8821471106851702\n",
      "at 4000 iteration loss is 0.8569008878612653\n",
      "at 4000 iteration loss is 0.9422390879200748\n",
      "at 4000 iteration loss is 0.9093636583550971\n",
      "at 4000 iteration loss is 0.8020215977530999\n",
      "at 4000 iteration loss is 1.0145439733372945\n",
      "at 4000 iteration loss is 1.019713016157176\n",
      "at 4000 iteration loss is 0.965486212991523\n",
      "at 4000 iteration loss is 1.0632629697062055\n",
      "at 4000 iteration loss is 0.8690968211486675\n",
      "at 4000 iteration loss is 0.9932531674570342\n",
      "at 4000 iteration loss is 0.7725486091476494\n",
      "at 4000 iteration loss is 0.8327634933720084\n",
      "at 4000 iteration loss is 0.9723663174049981\n",
      "at 4000 iteration loss is 0.9511429406185007\n",
      "at 4100 iteration loss is 1.0285922282718638\n",
      "at 4100 iteration loss is 0.8461659131600255\n",
      "at 4100 iteration loss is 0.8623894250976493\n",
      "at 4100 iteration loss is 0.8821433270916893\n",
      "at 4100 iteration loss is 0.8569081390629651\n",
      "at 4100 iteration loss is 0.9422336090122915\n",
      "at 4100 iteration loss is 0.9093573157313269\n",
      "at 4100 iteration loss is 0.8020272668499346\n",
      "at 4100 iteration loss is 1.0145502695679431\n",
      "at 4100 iteration loss is 1.0197009814663924\n",
      "at 4100 iteration loss is 0.9654885653900862\n",
      "at 4100 iteration loss is 1.0632644033555978\n",
      "at 4100 iteration loss is 0.8690993297744608\n",
      "at 4100 iteration loss is 0.9932452899816269\n",
      "at 4100 iteration loss is 0.7725484337040219\n",
      "at 4100 iteration loss is 0.8327549927681085\n",
      "at 4100 iteration loss is 0.9723690342735395\n",
      "at 4100 iteration loss is 0.9511445693592846\n",
      "at 4200 iteration loss is 1.0286062403575582\n",
      "at 4200 iteration loss is 0.846160914018018\n",
      "at 4200 iteration loss is 0.8623861748782693\n",
      "at 4200 iteration loss is 0.8821400946106873\n",
      "at 4200 iteration loss is 0.856914310060948\n",
      "at 4200 iteration loss is 0.9422289270460154\n",
      "at 4200 iteration loss is 0.9093519183058103\n",
      "at 4200 iteration loss is 0.8020321281590306\n",
      "at 4200 iteration loss is 1.0145556433862706\n",
      "at 4200 iteration loss is 1.01969081963249\n",
      "at 4200 iteration loss is 0.9654905944397388\n",
      "at 4200 iteration loss is 1.0632656028571643\n",
      "at 4200 iteration loss is 0.8691014550214081\n",
      "at 4200 iteration loss is 0.9932385731709481\n",
      "at 4200 iteration loss is 0.7725482641362003\n",
      "at 4200 iteration loss is 0.832747760094219\n",
      "at 4200 iteration loss is 0.9723713263677656\n",
      "at 4200 iteration loss is 0.9511459920026685\n",
      "at 4300 iteration loss is 1.0286181489555941\n",
      "at 4300 iteration loss is 0.8461566420347312\n",
      "at 4300 iteration loss is 0.8623833906110354\n",
      "at 4300 iteration loss is 0.882137332649134\n",
      "at 4300 iteration loss is 0.8569195619872758\n",
      "at 4300 iteration loss is 0.9422249256567701\n",
      "at 4300 iteration loss is 0.9093473250072617\n",
      "at 4300 iteration loss is 0.8020362973315898\n",
      "at 4300 iteration loss is 1.0145602303426906\n",
      "at 4300 iteration loss is 1.019682240616448\n",
      "at 4300 iteration loss is 0.9654923447838325\n",
      "at 4300 iteration loss is 1.0632666058430669\n",
      "at 4300 iteration loss is 0.8691032553640309\n",
      "at 4300 iteration loss is 0.9932328455402312\n",
      "at 4300 iteration loss is 0.7725481022422516\n",
      "at 4300 iteration loss is 0.8327416059356931\n",
      "at 4300 iteration loss is 0.9723732597101689\n",
      "at 4300 iteration loss is 0.9511472344596564\n",
      "at 4400 iteration loss is 1.0286282699930394\n",
      "at 4400 iteration loss is 0.8461529910369905\n",
      "at 4400 iteration loss is 0.8623810051810838\n",
      "at 4400 iteration loss is 0.8821349724465716\n",
      "at 4400 iteration loss is 0.8569240319127689\n",
      "at 4400 iteration loss is 0.9422215055328996\n",
      "at 4400 iteration loss is 0.9093434158492085\n",
      "at 4400 iteration loss is 0.8020398733856726\n",
      "at 4400 iteration loss is 1.0145641460136279\n",
      "at 4400 iteration loss is 1.019674999121173\n",
      "at 4400 iteration loss is 0.9654938548759965\n",
      "at 4400 iteration loss is 1.0632674439735084\n",
      "at 4400 iteration loss is 0.8691047803731085\n",
      "at 4400 iteration loss is 0.9932279610070346\n",
      "at 4400 iteration loss is 0.7725479491998024\n",
      "at 4400 iteration loss is 0.8327363692180214\n",
      "at 4400 iteration loss is 0.9723748901106248\n",
      "at 4400 iteration loss is 0.9511483194105654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at 4500 iteration loss is 1.0286368719304668\n",
      "at 4500 iteration loss is 0.8461498704099698\n",
      "at 4500 iteration loss is 0.862378961185447\n",
      "at 4500 iteration loss is 0.8821329553305068\n",
      "at 4500 iteration loss is 0.8569278364425228\n",
      "at 4500 iteration loss is 0.9422185819076561\n",
      "at 4500 iteration loss is 0.9093400887742566\n",
      "at 4500 iteration loss is 0.8020429411085723\n",
      "at 4500 iteration loss is 1.0145674889518026\n",
      "at 4500 iteration loss is 1.019668887710458\n",
      "at 4500 iteration loss is 0.9654951578413631\n",
      "at 4500 iteration loss is 1.0632681438742768\n",
      "at 4500 iteration loss is 0.8691060720694074\n",
      "at 4500 iteration loss is 0.9932237951188219\n",
      "at 4500 iteration loss is 0.7725478057048268\n",
      "at 4500 iteration loss is 0.8327319129594624\n",
      "at 4500 iteration loss is 0.9723762647398437\n",
      "at 4500 iteration loss is 0.9511492667034316\n",
      "at 4600 iteration loss is 1.028644182894865\n",
      "at 4600 iteration loss is 0.8461472028094084\n",
      "at 4600 iteration loss is 0.8623772095211677\n",
      "at 4600 iteration loss is 0.8821312312303121\n",
      "at 4600 iteration loss is 0.8569310747740257\n",
      "at 4600 iteration loss is 0.9422160824214639\n",
      "at 4600 iteration loss is 0.9093372569713605\n",
      "at 4600 iteration loss is 0.8020455731108693\n",
      "at 4600 iteration loss is 1.014570343199863\n",
      "at 4600 iteration loss is 1.0196637309839072\n",
      "at 4600 iteration loss is 0.9654962822177392\n",
      "at 4600 iteration loss is 1.0632687279286102\n",
      "at 4600 iteration loss is 0.8691071660718819\n",
      "at 4600 iteration loss is 0.9932202418422383\n",
      "at 4600 iteration loss is 0.7725476720837208\n",
      "at 4600 iteration loss is 0.8327281206615457\n",
      "at 4600 iteration loss is 0.9723774234612114\n",
      "at 4600 iteration loss is 0.951150093704032\n",
      "at 4700 iteration loss is 1.0286503967407492\n",
      "at 4700 iteration loss is 0.8461449222114062\n",
      "at 4700 iteration loss is 0.8623757081796688\n",
      "at 4700 iteration loss is 0.8821297574110755\n",
      "at 4700 iteration loss is 0.8569338312981571\n",
      "at 4700 iteration loss is 0.942213945299492\n",
      "at 4700 iteration loss is 0.9093348465950797\n",
      "at 4700 iteration loss is 0.8020478315828434\n",
      "at 4700 iteration loss is 1.0145727804320992\n",
      "at 4700 iteration loss is 1.019659380645953\n",
      "at 4700 iteration loss is 0.9654972525934354\n",
      "at 4700 iteration loss is 1.0632692149457572\n",
      "at 4700 iteration loss is 0.8691080925715002\n",
      "at 4700 iteration loss is 0.9932172108301973\n",
      "at 4700 iteration loss is 0.7725475483834104\n",
      "at 4700 iteration loss is 0.8327248932413813\n",
      "at 4700 iteration loss is 0.9723783999580137\n",
      "at 4700 iteration loss is 0.9511508156032713\n",
      "at 4800 iteration loss is 1.0286556782004326\n",
      "at 4800 iteration loss is 0.8461429722497774\n",
      "at 4800 iteration loss is 0.8623744212170795\n",
      "at 4800 iteration loss is 0.8821284973946474\n",
      "at 4800 iteration loss is 0.8569361778113702\n",
      "at 4800 iteration loss is 0.9422121177978475\n",
      "at 4800 iteration loss is 0.9093327948264822\n",
      "at 4800 iteration loss is 0.8020497697965017\n",
      "at 4800 iteration loss is 1.0145748617793617\n",
      "at 4800 iteration loss is 1.0196557113319389\n",
      "at 4800 iteration loss is 0.9654980901561354\n",
      "at 4800 iteration loss is 1.063269620725218\n",
      "at 4800 iteration loss is 0.8691088771571247\n",
      "at 4800 iteration loss is 0.9932146250954746\n",
      "at 4800 iteration loss is 0.7725474344434298\n",
      "at 4800 iteration loss is 0.8327221464242218\n",
      "at 4800 iteration loss is 0.9723792226873847\n",
      "at 4800 iteration loss is 0.9511514456870028\n",
      "at 4900 iteration loss is 1.028660167260297\n",
      "at 4900 iteration loss is 0.8461413047984383\n",
      "at 4900 iteration loss is 0.8623733178747027\n",
      "at 4900 iteration loss is 0.882127420040062\n",
      "at 4900 iteration loss is 0.856938175397171\n",
      "at 4900 iteration loss is 0.9422105548786541\n",
      "at 4900 iteration loss is 0.909331048224445\n",
      "at 4900 iteration loss is 0.8020514333902173\n",
      "at 4900 iteration loss is 1.0145766393841202\n",
      "at 4900 iteration loss is 1.019652617075223\n",
      "at 4900 iteration loss is 0.9654988131652367\n",
      "at 4900 iteration loss is 1.0632699585327878\n",
      "at 4900 iteration loss is 0.8691095415159167\n",
      "at 4900 iteration loss is 0.993212419030184\n",
      "at 4900 iteration loss is 0.7725473299532679\n",
      "at 4900 iteration loss is 0.8327198085270776\n",
      "at 4900 iteration loss is 0.9723799156875395\n",
      "at 4900 iteration loss is 0.9511519955728064\n",
      "at 5000 iteration loss is 1.0286639828793536\n",
      "at 5000 iteration loss is 0.846139878762574\n",
      "at 5000 iteration loss is 0.8623723718276182\n",
      "at 5000 iteration loss is 0.8821264987596592\n",
      "at 5000 iteration loss is 0.8569398760263398\n",
      "at 5000 iteration loss is 0.9422092180801789\n",
      "at 5000 iteration loss is 0.9093295613237959\n",
      "at 5000 iteration loss is 0.8020528614675426\n",
      "at 5000 iteration loss is 1.0145781577256412\n",
      "at 5000 iteration loss is 1.019650008317038\n",
      "at 5000 iteration loss is 0.9654994373583399\n",
      "at 5000 iteration loss is 1.0632702395020424\n",
      "at 5000 iteration loss is 0.8691101040272893\n",
      "at 5000 iteration loss is 0.9932105367195685\n",
      "at 5000 iteration loss is 0.7725472344976902\n",
      "at 5000 iteration loss is 0.8327178185745954\n",
      "at 5000 iteration loss is 0.9723804992607874\n",
      "at 5000 iteration loss is 0.9511524754176847\n",
      "at 5100 iteration loss is 1.0286672261489138\n",
      "at 5100 iteration loss is 0.8461386590477409\n",
      "at 5100 iteration loss is 0.8623715605426682\n",
      "at 5100 iteration loss is 0.882125710850801\n",
      "at 5100 iteration loss is 0.856941323917941\n",
      "at 5100 iteration loss is 0.9422080745531854\n",
      "at 5100 iteration loss is 0.9093282954432871\n",
      "at 5100 iteration loss is 0.8020540875371902\n",
      "at 5100 iteration loss is 1.0145794547493376\n",
      "at 5100 iteration loss is 1.0196478093758974\n",
      "at 5100 iteration loss is 0.9654999763010951\n",
      "at 5100 iteration loss is 1.0632704729728466\n",
      "at 5100 iteration loss is 0.8691105802665691\n",
      "at 5100 iteration loss is 0.9932089305062703\n",
      "at 5100 iteration loss is 0.7725471475922753\n",
      "at 5100 iteration loss is 0.8327161246973024\n",
      "at 5100 iteration loss is 0.972380990551377\n",
      "at 5100 iteration loss is 0.9511528941001901\n",
      "at 5200 iteration loss is 1.0286699829773789\n",
      "at 5200 iteration loss is 0.8461376156806224\n",
      "at 5200 iteration loss is 0.8623708647298229\n",
      "at 5200 iteration loss is 0.8821250369260483\n",
      "at 5200 iteration loss is 0.8569425566968942\n",
      "at 5200 iteration loss is 0.9422070962389861\n",
      "at 5200 iteration loss is 0.9093272176719529\n",
      "at 5200 iteration loss is 0.8020551403172196\n",
      "at 5200 iteration loss is 1.014580562829274\n",
      "at 5200 iteration loss is 1.0196459563060714\n",
      "at 5200 iteration loss is 0.9655004416883125\n",
      "at 5200 iteration loss is 1.0632706667766627\n",
      "at 5200 iteration loss is 0.8691109834320783\n",
      "at 5200 iteration loss is 0.993207559767771\n",
      "at 5200 iteration loss is 0.7725470687110351\n",
      "at 5200 iteration loss is 0.8327146827698128\n",
      "at 5200 iteration loss is 0.9723814040343172\n",
      "at 5200 iteration loss is 0.9511532593800875\n",
      "at 5300 iteration loss is 1.0286723263715079\n",
      "at 5300 iteration loss is 0.8461367230590596\n",
      "at 5300 iteration loss is 0.8623702678732821\n",
      "at 5300 iteration loss is 0.8821244604272325\n",
      "at 5300 iteration loss is 0.8569436063785286\n",
      "at 5300 iteration loss is 0.9422062591682765\n",
      "at 5300 iteration loss is 0.9093263000071203\n",
      "at 5300 iteration loss is 0.8020560444231297\n",
      "at 5300 iteration loss is 1.0145815095885384\n",
      "at 5300 iteration loss is 1.0196443950854621\n",
      "at 5300 iteration loss is 0.9655008436031501\n",
      "at 5300 iteration loss is 1.0632708274769467\n",
      "at 5300 iteration loss is 0.8691113247072628\n",
      "at 5300 iteration loss is 0.9932063898752803\n",
      "at 5300 iteration loss is 0.7725469973076292\n",
      "at 5300 iteration loss is 0.8327134552529893\n",
      "at 5300 iteration loss is 0.9723817519288428\n",
      "at 5300 iteration loss is 0.9511535780382818\n",
      "at 5400 iteration loss is 1.0286743183748237\n",
      "at 5400 iteration loss is 0.8461359593122773\n",
      "at 5400 iteration loss is 0.8623697558306744\n",
      "at 5400 iteration loss is 0.8821239672110185\n",
      "at 5400 iteration loss is 0.8569445002059926\n",
      "at 5400 iteration loss is 0.9422055428629499\n",
      "at 5400 iteration loss is 0.9093255186213549\n",
      "at 5400 iteration loss is 0.8020568209566867\n",
      "at 5400 iteration loss is 1.0145823185985001\n",
      "at 5400 iteration loss is 1.0196430800823395\n",
      "at 5400 iteration loss is 0.9655011907402388\n",
      "at 5400 iteration loss is 1.063270960571643\n",
      "at 5400 iteration loss is 0.8691116135677379\n",
      "at 5400 iteration loss is 0.9932053913070729\n",
      "at 5400 iteration loss is 0.7725469328314392\n",
      "at 5400 iteration loss is 0.8327124102094622\n",
      "at 5400 iteration loss is 0.9723820445481077\n",
      "at 5400 iteration loss is 0.9511538559994059\n",
      "at 5500 iteration loss is 1.028676011714691\n",
      "at 5500 iteration loss is 0.8461353057550735\n",
      "at 5500 iteration loss is 0.8623693164904166\n",
      "at 5500 iteration loss is 0.8821235451954044\n",
      "at 5500 iteration loss is 0.8569452613625288\n",
      "at 5500 iteration loss is 0.9422049298257154\n",
      "at 5500 iteration loss is 0.9093248532390314\n",
      "at 5500 iteration loss is 0.8020574880098634\n",
      "at 5500 iteration loss is 1.0145830099748907\n",
      "at 5500 iteration loss is 1.0196419727581325\n",
      "at 5500 iteration loss is 0.9655014905977769\n",
      "at 5500 iteration loss is 1.0632710706636903\n",
      "at 5500 iteration loss is 0.8691118580416102\n",
      "at 5500 iteration loss is 0.9932045388933144\n",
      "at 5500 iteration loss is 0.7725468747395227\n",
      "at 5500 iteration loss is 0.8327115204665109\n",
      "at 5500 iteration loss is 0.9723822905948936\n",
      "at 5500 iteration loss is 0.9511540984392063\n",
      "at 5600 iteration loss is 1.0286774512018533\n",
      "at 5600 iteration loss is 0.8461347464221177\n",
      "at 5600 iteration loss is 0.862368939478759\n",
      "at 5600 iteration loss is 0.8821231840581525\n",
      "at 5600 iteration loss is 0.8569459095773206\n",
      "at 5600 iteration loss is 0.942204405104588\n",
      "at 5600 iteration loss is 0.909324286606115\n",
      "at 5600 iteration loss is 0.802058061096169\n",
      "at 5600 iteration loss is 1.0145836008859486\n",
      "at 5600 iteration loss is 1.0196410405700393\n",
      "at 5600 iteration loss is 0.9655017496429302\n",
      "at 5600 iteration loss is 1.0632711616045518\n",
      "at 5600 iteration loss is 0.8691120649301837\n",
      "at 5600 iteration loss is 0.993203811172825\n",
      "at 5600 iteration loss is 0.7725468225052909\n",
      "at 5600 iteration loss is 0.8327107629042132\n",
      "at 5600 iteration loss is 0.9723824974116541\n",
      "at 5600 iteration loss is 0.9511543098785756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at 5700 iteration loss is 1.0286786749196506\n",
      "at 5700 iteration loss is 0.8461342676705673\n",
      "at 5700 iteration loss is 0.8623686159092804\n",
      "at 5700 iteration loss is 0.8821228749795076\n",
      "at 5700 iteration loss is 0.8569464616408302\n",
      "at 5700 iteration loss is 0.9422039559212321\n",
      "at 5700 iteration loss is 0.9093238040392005\n",
      "at 5700 iteration loss is 0.8020585535198996\n",
      "at 5700 iteration loss is 1.014584105985641\n",
      "at 5700 iteration loss is 1.019640256042771\n",
      "at 5700 iteration loss is 0.9655019734542634\n",
      "at 5700 iteration loss is 1.0632712366149957\n",
      "at 5700 iteration loss is 0.8691122399950691\n",
      "at 5700 iteration loss is 0.993203189845153\n",
      "at 5700 iteration loss is 0.7725467756245976\n",
      "at 5700 iteration loss is 0.8327101178500961\n",
      "at 5700 iteration loss is 0.9723826711919117\n",
      "at 5700 iteration loss is 0.9511544942658784\n",
      "at 5800 iteration loss is 1.0286797152345184\n",
      "at 5800 iteration loss is 0.8461338578409443\n",
      "at 5800 iteration loss is 0.8623683381686525\n",
      "at 5800 iteration loss is 0.8821226104226619\n",
      "at 5800 iteration loss is 0.8569469318431582\n",
      "at 5800 iteration loss is 0.9422035713537665\n",
      "at 5800 iteration loss is 0.9093233930419407\n",
      "at 5800 iteration loss is 0.802058976692256\n",
      "at 5800 iteration loss is 1.0145845377830347\n",
      "at 5800 iteration loss is 1.0196395959834335\n",
      "at 5800 iteration loss is 0.9655021668443974\n",
      "at 5800 iteration loss is 1.0632712983866959\n",
      "at 5800 iteration loss is 0.8691123881167998\n",
      "at 5800 iteration loss is 0.9932026593038028\n",
      "at 5800 iteration loss is 0.7725467336197906\n",
      "at 5800 iteration loss is 0.8327095685643261\n",
      "at 5800 iteration loss is 0.9723828171589567\n",
      "at 5800 iteration loss is 0.9511546550490101\n",
      "at 5900 iteration loss is 1.0286805996546422\n",
      "at 5900 iteration loss is 0.8461335069677041\n",
      "at 5900 iteration loss is 0.8623680997334018\n",
      "at 5900 iteration loss is 0.8821223839464197\n",
      "at 5900 iteration loss is 0.8569473323469342\n",
      "at 5900 iteration loss is 0.9422032420660151\n",
      "at 5900 iteration loss is 0.9093230429787965\n",
      "at 5900 iteration loss is 0.8020593404020241\n",
      "at 5900 iteration loss is 1.0145849069572475\n",
      "at 5900 iteration loss is 1.0196390408175517\n",
      "at 5900 iteration loss is 0.9655023339656654\n",
      "at 5900 iteration loss is 1.0632713491676704\n",
      "at 5900 iteration loss is 0.8691125134292939\n",
      "at 5900 iteration loss is 0.9932022062385663\n",
      "at 5900 iteration loss is 0.7725466960421865\n",
      "at 5900 iteration loss is 0.8327091008018856\n",
      "at 5900 iteration loss is 0.9723829397168897\n",
      "at 5900 iteration loss is 0.9511547952384589\n",
      "at 6000 iteration loss is 1.0286813515595905\n",
      "at 6000 iteration loss is 0.8461332065321908\n",
      "at 6000 iteration loss is 0.8623678950131627\n",
      "at 6000 iteration loss is 0.8821221900453129\n",
      "at 6000 iteration loss is 0.8569476735045306\n",
      "at 6000 iteration loss is 0.9422029600763958\n",
      "at 6000 iteration loss is 0.9093227447975114\n",
      "at 6000 iteration loss is 0.8020596530473687\n",
      "at 6000 iteration loss is 1.0145852226260215\n",
      "at 6000 iteration loss is 1.0196385740276022\n",
      "at 6000 iteration loss is 0.9655024784011209\n",
      "at 6000 iteration loss is 1.0632713908341052\n",
      "at 6000 iteration loss is 0.8691126194338276\n",
      "at 6000 iteration loss is 0.9932018192967089\n",
      "at 6000 iteration loss is 0.7725466624733224\n",
      "at 6000 iteration loss is 0.8327087024401981\n",
      "at 6000 iteration loss is 0.9723830425782708\n",
      "at 6000 iteration loss is 0.9511549174624768\n",
      "at 6100 iteration loss is 1.0286819908203175\n",
      "at 6100 iteration loss is 0.8461329492517514\n",
      "at 6100 iteration loss is 0.8623677192165788\n",
      "at 6100 iteration loss is 0.882122024013136\n",
      "at 6100 iteration loss is 0.8569479641279096\n",
      "at 6100 iteration loss is 0.9422027185606072\n",
      "at 6100 iteration loss is 0.9093224907930411\n",
      "at 6100 iteration loss is 0.802059921834363\n",
      "at 6100 iteration loss is 1.0145854925747577\n",
      "at 6100 iteration loss is 1.0196381816782878\n",
      "at 6100 iteration loss is 0.9655026032429419\n",
      "at 6100 iteration loss is 1.0632714249507\n",
      "at 6100 iteration loss is 0.8691127090956454\n",
      "at 6100 iteration loss is 0.993201488794272\n",
      "at 6100 iteration loss is 0.7725466325252937\n",
      "at 6100 iteration loss is 0.8327083631624141\n",
      "at 6100 iteration loss is 0.972383128871982\n",
      "at 6100 iteration loss is 0.951155024015349\n",
      "at 6200 iteration loss is 1.0286825343260135\n",
      "at 6200 iteration loss is 0.8461327288996966\n",
      "at 6200 iteration loss is 0.8623675682365624\n",
      "at 6200 iteration loss is 0.8821218818264567\n",
      "at 6200 iteration loss is 0.8569482117182\n",
      "at 6200 iteration loss is 0.9422025116831667\n",
      "at 6200 iteration loss is 0.9093222744067304\n",
      "at 6200 iteration loss is 0.8020601529470307\n",
      "at 6200 iteration loss is 1.0145857234518616\n",
      "at 6200 iteration loss is 1.0196378520151943\n",
      "at 6200 iteration loss is 0.9655027111599935\n",
      "at 6200 iteration loss is 1.063271452821373\n",
      "at 6200 iteration loss is 0.8691127849258408\n",
      "at 6200 iteration loss is 0.993201206470067\n",
      "at 6200 iteration loss is 0.772546605840391\n",
      "at 6200 iteration loss is 0.8327080741880231\n",
      "at 6200 iteration loss is 0.9723832012343541\n",
      "at 6200 iteration loss is 0.9511551168995979\n",
      "at 6300 iteration loss is 1.0286829964318063\n",
      "at 6300 iteration loss is 0.8461325401515832\n",
      "at 6300 iteration loss is 0.8623674385521036\n",
      "at 6300 iteration loss is 0.882121760045167\n",
      "at 6300 iteration loss is 0.856948422661004\n",
      "at 6300 iteration loss is 0.9422023344535596\n",
      "at 6300 iteration loss is 0.9093220900554675\n",
      "at 6300 iteration loss is 0.8020603516930253\n",
      "at 6300 iteration loss is 1.0145859209353503\n",
      "at 6300 iteration loss is 1.0196375751255355\n",
      "at 6300 iteration loss is 0.9655028044560379\n",
      "at 6300 iteration loss is 1.0632714755318138\n",
      "at 6300 iteration loss is 0.8691128490507533\n",
      "at 6300 iteration loss is 0.993200965276032\n",
      "at 6300 iteration loss is 0.7725465820902475\n",
      "at 6300 iteration loss is 0.832707828043709\n",
      "at 6300 iteration loss is 0.9723832618861499\n",
      "at 6300 iteration loss is 0.9511551978628987\n",
      "at 6400 iteration loss is 1.0286833893392058\n",
      "at 6400 iteration loss is 0.8461323784539555\n",
      "at 6400 iteration loss is 0.8623673271442366\n",
      "at 6400 iteration loss is 0.8821216557275722\n",
      "at 6400 iteration loss is 0.856948602392569\n",
      "at 6400 iteration loss is 0.9422021826033937\n",
      "at 6400 iteration loss is 0.9093219329863382\n",
      "at 6400 iteration loss is 0.8020605226284413\n",
      "at 6400 iteration loss is 1.0145860898749794\n",
      "at 6400 iteration loss is 1.0196373426514125\n",
      "at 6400 iteration loss is 0.9655028851199099\n",
      "at 6400 iteration loss is 1.0632714939852188\n",
      "at 6400 iteration loss is 0.8691129032707826\n",
      "at 6400 iteration loss is 0.9932007591985557\n",
      "at 6400 iteration loss is 0.7725465609746243\n",
      "at 6400 iteration loss is 0.8327076183684319\n",
      "at 6400 iteration loss is 0.9723833126975816\n",
      "at 6400 iteration loss is 0.9511552684303506\n",
      "at 6500 iteration loss is 1.0286837234194057\n",
      "at 6500 iteration loss is 0.8461322399122564\n",
      "at 6500 iteration loss is 0.862367231424115\n",
      "at 6500 iteration loss is 0.8821215663578897\n",
      "at 6500 iteration loss is 0.8569487555411668\n",
      "at 6500 iteration loss is 0.9422020524814838\n",
      "at 6500 iteration loss is 0.909321799152967\n",
      "at 6500 iteration loss is 0.8020606696647692\n",
      "at 6500 iteration loss is 1.0145862344134848\n",
      "at 6500 iteration loss is 1.0196371475474948\n",
      "at 6500 iteration loss is 0.9655029548687606\n",
      "at 6500 iteration loss is 1.0632715089322544\n",
      "at 6500 iteration loss is 0.869112949110232\n",
      "at 6500 iteration loss is 0.9932005831061982\n",
      "at 6500 iteration loss is 0.7725465422199669\n",
      "at 6500 iteration loss is 0.83270743974762\n",
      "at 6500 iteration loss is 0.9723833552432201\n",
      "at 6500 iteration loss is 0.9511553299326886\n",
      "at 6600 iteration loss is 1.028684007488021\n",
      "at 6600 iteration loss is 0.8461321211950921\n",
      "at 6600 iteration loss is 0.8623671491714274\n",
      "at 6600 iteration loss is 0.8821214897843322\n",
      "at 6600 iteration loss is 0.8569488860473898\n",
      "at 6600 iteration loss is 0.9422019409642355\n",
      "at 6600 iteration loss is 0.9093216851103056\n",
      "at 6600 iteration loss is 0.8020607961605488\n",
      "at 6600 iteration loss is 1.014586358090017\n",
      "at 6600 iteration loss is 1.019636983876266\n",
      "at 6600 iteration loss is 0.9655030151853374\n",
      "at 6600 iteration loss is 1.0632715209961927\n",
      "at 6600 iteration loss is 0.8691129878595406\n",
      "at 6600 iteration loss is 0.9932004326198836\n",
      "at 6600 iteration loss is 0.7725465255778052\n",
      "at 6600 iteration loss is 0.8327072875721061\n",
      "at 6600 iteration loss is 0.9723833908483538\n",
      "at 6600 iteration loss is 0.9511553835309359\n",
      "at 6700 iteration loss is 1.0286842490385615\n",
      "at 6700 iteration loss is 0.8461320194524606\n",
      "at 6700 iteration loss is 0.8623670784816863\n",
      "at 6700 iteration loss is 0.8821214241662249\n",
      "at 6700 iteration loss is 0.8569489972665061\n",
      "at 6700 iteration loss is 0.9422018453790892\n",
      "at 6700 iteration loss is 0.9093215879251133\n",
      "at 6700 iteration loss is 0.8020609049999301\n",
      "at 6700 iteration loss is 1.0145864639283988\n",
      "at 6700 iteration loss is 1.0196368466350396\n",
      "at 6700 iteration loss is 0.9655030673501228\n",
      "at 6700 iteration loss is 1.063271530693974\n",
      "at 6700 iteration loss is 0.8691130206110722\n",
      "at 6700 iteration loss is 0.993200304002246\n",
      "at 6700 iteration loss is 0.7725465108230871\n",
      "at 6700 iteration loss is 0.8327071579181288\n",
      "at 6700 iteration loss is 0.9723834206281264\n",
      "at 6700 iteration loss is 0.9511554302379501\n",
      "at 6800 iteration loss is 1.0286844544408509\n",
      "at 6800 iteration loss is 0.8461319322459033\n",
      "at 6800 iteration loss is 0.8623670177210799\n",
      "at 6800 iteration loss is 0.88212136792884\n",
      "at 6800 iteration loss is 0.856949092055558\n",
      "at 6800 iteration loss is 0.9422017634391218\n",
      "at 6800 iteration loss is 0.9093215050997825\n",
      "at 6800 iteration loss is 0.8020609986600233\n",
      "at 6800 iteration loss is 1.0145865545124337\n",
      "at 6800 iteration loss is 1.019636731609833\n",
      "at 6800 iteration loss is 0.9655031124690494\n",
      "at 6800 iteration loss is 1.0632715384538525\n",
      "at 6800 iteration loss is 0.8691130482894401\n",
      "at 6800 iteration loss is 0.9932001940633011\n",
      "at 6800 iteration loss is 0.7725464977524805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at 6800 iteration loss is 0.832707047445235\n",
      "at 6800 iteration loss is 0.972383445520571\n",
      "at 6800 iteration loss is 0.9511554709372525\n",
      "at 6900 iteration loss is 1.0286846291096423\n",
      "at 6900 iteration loss is 0.8461318574888228\n",
      "at 6900 iteration loss is 0.8623669654878146\n",
      "at 6900 iteration loss is 0.8821213197248069\n",
      "at 6900 iteration loss is 0.8569491728474823\n",
      "at 6900 iteration loss is 0.9422016931871611\n",
      "at 6900 iteration loss is 0.9093214345075236\n",
      "at 6900 iteration loss is 0.8020610792686277\n",
      "at 6900 iteration loss is 1.0145866320501713\n",
      "at 6900 iteration loss is 1.0196366352519526\n",
      "at 6900 iteration loss is 0.9655031514973945\n",
      "at 6900 iteration loss is 1.063271544630173\n",
      "at 6900 iteration loss is 0.8691130716771944\n",
      "at 6900 iteration loss is 0.993200100080017\n",
      "at 6900 iteration loss is 0.7725464861826912\n",
      "at 6900 iteration loss is 0.8327069533094109\n",
      "at 6900 iteration loss is 0.9723834663144852\n",
      "at 6900 iteration loss is 0.9511555063994684\n",
      "at 7000 iteration loss is 1.0286847776479238\n",
      "at 7000 iteration loss is 0.8461317933955022\n",
      "at 7000 iteration loss is 0.8623669205790059\n",
      "at 7000 iteration loss is 0.8821212784011537\n",
      "at 7000 iteration loss is 0.8569492417141815\n",
      "at 7000 iteration loss is 0.9422016329480407\n",
      "at 7000 iteration loss is 0.9093213743372077\n",
      "at 7000 iteration loss is 0.802061148653749\n",
      "at 7000 iteration loss is 1.0145866984287553\n",
      "at 7000 iteration loss is 1.0196365545737727\n",
      "at 7000 iteration loss is 0.9655031852603981\n",
      "at 7000 iteration loss is 1.0632715495157328\n",
      "at 7000 iteration loss is 0.8691130914365951\n",
      "at 7000 iteration loss is 0.993200019727747\n",
      "at 7000 iteration loss is 0.7725464759488381\n",
      "at 7000 iteration loss is 0.8327068730891811\n",
      "at 7000 iteration loss is 0.9723834836729541\n",
      "at 7000 iteration loss is 0.9511555372967024\n",
      "at 7100 iteration loss is 1.0286849039687005\n",
      "at 7100 iteration loss is 0.8461317384375256\n",
      "at 7100 iteration loss is 0.8623668819623089\n",
      "at 7100 iteration loss is 0.8821212429711338\n",
      "at 7100 iteration loss is 0.8569493004201998\n",
      "at 7100 iteration loss is 0.942201581287784\n",
      "at 7100 iteration loss is 0.909321323046424\n",
      "at 7100 iteration loss is 0.8020612083860424\n",
      "at 7100 iteration loss is 1.0145867552612402\n",
      "at 7100 iteration loss is 1.0196364870607408\n",
      "at 7100 iteration loss is 0.9655032144710327\n",
      "at 7100 iteration loss is 1.0632715533521222\n",
      "at 7100 iteration loss is 0.8691131081280414\n",
      "at 7100 iteration loss is 0.993199951021747\n",
      "at 7100 iteration loss is 0.7725464669028724\n",
      "at 7100 iteration loss is 0.8327068047227119\n",
      "at 7100 iteration loss is 0.9723834981531884\n",
      "at 7100 iteration loss is 0.9511555642150752\n",
      "at 7200 iteration loss is 1.0286850113985024\n",
      "at 7200 iteration loss is 0.8461316913065495\n",
      "at 7200 iteration loss is 0.8623668487516232\n",
      "at 7200 iteration loss is 0.8821212125901614\n",
      "at 7200 iteration loss is 0.8569493504684097\n",
      "at 7200 iteration loss is 0.9422015369787312\n",
      "at 7200 iteration loss is 0.9093212793215362\n",
      "at 7200 iteration loss is 0.8020612598152367\n",
      "at 7200 iteration loss is 1.0145868039265467\n",
      "at 7200 iteration loss is 1.0196364305970966\n",
      "at 7200 iteration loss is 0.9655032397453465\n",
      "at 7200 iteration loss is 1.0632715563383683\n",
      "at 7200 iteration loss is 0.8691131222256976\n",
      "at 7200 iteration loss is 0.9931998922673152\n",
      "at 7200 iteration loss is 0.7725464589120941\n",
      "at 7200 iteration loss is 0.8327067464543008\n",
      "at 7200 iteration loss is 0.9723835102232592\n",
      "at 7200 iteration loss is 0.9511555876656852\n",
      "at 7300 iteration loss is 1.0286851027653503\n",
      "at 7300 iteration loss is 0.8461316508824739\n",
      "at 7300 iteration loss is 0.8623668201862721\n",
      "at 7300 iteration loss is 0.8821211865352406\n",
      "at 7300 iteration loss is 0.856949393138892\n",
      "at 7300 iteration loss is 0.9422014989697216\n",
      "at 7300 iteration loss is 0.9093212420436808\n",
      "at 7300 iteration loss is 0.8020613041013629\n",
      "at 7300 iteration loss is 1.0145868456035845\n",
      "at 7300 iteration loss is 1.019636383403172\n",
      "at 7300 iteration loss is 0.9655032616156956\n",
      "at 7300 iteration loss is 1.0632715586381547\n",
      "at 7300 iteration loss is 0.8691131341307216\n",
      "at 7300 iteration loss is 0.993199842017264\n",
      "at 7300 iteration loss is 0.772546451857747\n",
      "at 7300 iteration loss is 0.8327066967888405\n",
      "at 7300 iteration loss is 0.9723835202762074\n",
      "at 7300 iteration loss is 0.9511556080941777\n",
      "at 7400 iteration loss is 1.0286851804735178\n",
      "at 7400 iteration loss is 0.8461316162062396\n",
      "at 7400 iteration loss is 0.8623667956131589\n",
      "at 7400 iteration loss is 0.8821211641873848\n",
      "at 7400 iteration loss is 0.856949429522029\n",
      "at 7400 iteration loss is 0.9422014663606081\n",
      "at 7400 iteration loss is 0.9093212102598323\n",
      "at 7400 iteration loss is 0.802061342241555\n",
      "at 7400 iteration loss is 1.0145868813003711\n",
      "at 7400 iteration loss is 1.0196363439824867\n",
      "at 7400 iteration loss is 0.9655032805421584\n",
      "at 7400 iteration loss is 1.063271560385847\n",
      "at 7400 iteration loss is 0.8691131441824694\n",
      "at 7400 iteration loss is 0.9931997990356443\n",
      "at 7400 iteration loss is 0.7725464456337103\n",
      "at 7400 iteration loss is 0.8327066544530647\n",
      "at 7400 iteration loss is 0.9723835286419412\n",
      "at 7400 iteration loss is 0.9511556258890929\n",
      "at 7500 iteration loss is 1.028685246567081\n",
      "at 7500 iteration loss is 0.8461315864565728\n",
      "at 7500 iteration loss is 0.8623667744714772\n",
      "at 7500 iteration loss is 0.8821211450165878\n",
      "at 7500 iteration loss is 0.856949460546678\n",
      "at 7500 iteration loss is 0.9422014383804616\n",
      "at 7500 iteration loss is 0.9093211831581703\n",
      "at 7500 iteration loss is 0.8020613750930385\n",
      "at 7500 iteration loss is 1.0145869118789064\n",
      "at 7500 iteration loss is 1.0196363110771065\n",
      "at 7500 iteration loss is 0.9655032969223913\n",
      "at 7500 iteration loss is 1.0632715616915176\n",
      "at 7500 iteration loss is 0.8691131526679859\n",
      "at 7500 iteration loss is 0.99319976226681\n",
      "at 7500 iteration loss is 0.7725464401452801\n",
      "at 7500 iteration loss is 0.8327066183625693\n",
      "at 7500 iteration loss is 0.9723835355972563\n",
      "at 7500 iteration loss is 0.9511556413891606\n",
      "at 7600 iteration loss is 1.0286853027839176\n",
      "at 7600 iteration loss is 0.846131560930098\n",
      "at 7600 iteration loss is 0.8623667562796011\n",
      "at 7600 iteration loss is 0.8821211285689727\n",
      "at 7600 iteration loss is 0.8569494870041424\n",
      "at 7600 iteration loss is 0.9422014143689406\n",
      "at 7600 iteration loss is 0.9093211600471157\n",
      "at 7600 iteration loss is 0.8020614033928621\n",
      "at 7600 iteration loss is 1.0145869380764028\n",
      "at 7600 iteration loss is 1.0196362836299886\n",
      "at 7600 iteration loss is 0.9655033111001327\n",
      "at 7600 iteration loss is 1.063271562645138\n",
      "at 7600 iteration loss is 0.8691131598300406\n",
      "at 7600 iteration loss is 0.9931997308090157\n",
      "at 7600 iteration loss is 0.7725464353080478\n",
      "at 7600 iteration loss is 0.8327065875937396\n",
      "at 7600 iteration loss is 0.9723835413742872\n",
      "at 7600 iteration loss is 0.9511556548896607\n",
      "at 7700 iteration loss is 1.0286853506016207\n",
      "at 7700 iteration loss is 0.8461315390243422\n",
      "at 7700 iteration loss is 0.8623667406238527\n",
      "at 7700 iteration loss is 0.882121114455814\n",
      "at 7700 iteration loss is 0.8569495095685923\n",
      "at 7700 iteration loss is 0.9422013937603548\n",
      "at 7700 iteration loss is 0.9093211403374843\n",
      "at 7700 iteration loss is 0.8020614277748358\n",
      "at 7700 iteration loss is 1.0145869605234321\n",
      "at 7700 iteration loss is 1.0196362607532299\n",
      "at 7700 iteration loss is 0.9655033233725423\n",
      "at 7700 iteration loss is 1.063271563320067\n",
      "at 7700 iteration loss is 0.8691131658739355\n",
      "at 7700 iteration loss is 0.9931997038919114\n",
      "at 7700 iteration loss is 0.7725464310468687\n",
      "at 7700 iteration loss is 0.832706561359869\n",
      "at 7700 iteration loss is 0.9723835461676241\n",
      "at 7700 iteration loss is 0.9511556666479837\n",
      "at 7800 iteration loss is 1.0286853912765104\n",
      "at 7800 iteration loss is 0.8461315202231894\n",
      "at 7800 iteration loss is 0.8623667271488638\n",
      "at 7800 iteration loss is 0.8821211023441373\n",
      "at 7800 iteration loss is 0.8569495288144378\n",
      "at 7800 iteration loss is 0.9422013760700343\n",
      "at 7800 iteration loss is 0.9093211235272914\n",
      "at 7800 iteration loss is 0.8020614487840602\n",
      "at 7800 iteration loss is 1.0145869797594051\n",
      "at 7800 iteration loss is 1.0196362417012819\n",
      "at 7800 iteration loss is 0.9655033339965391\n",
      "at 7800 iteration loss is 1.0632715637759513\n",
      "at 7800 iteration loss is 0.8691131709732656\n",
      "at 7800 iteration loss is 0.9931996808573157\n",
      "at 7800 iteration loss is 0.7725464272949182\n",
      "at 7800 iteration loss is 0.832706538990816\n",
      "at 7800 iteration loss is 0.9723835501403049\n",
      "at 7800 iteration loss is 0.9511556768884729\n",
      "at 7900 iteration loss is 1.0286854258768\n",
      "at 7900 iteration loss is 0.8461315040844465\n",
      "at 7900 iteration loss is 0.8623667155493158\n",
      "at 7900 iteration loss is 0.8821210919486902\n",
      "at 7900 iteration loss is 0.8569495452311218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at 7900 iteration loss is 0.942201360882675\n",
      "at 7900 iteration loss is 0.9093211091888195\n",
      "at 7900 iteration loss is 0.8020614668894106\n",
      "at 7900 iteration loss is 1.01458699624581\n",
      "at 7900 iteration loss is 1.0196362258483846\n",
      "at 7900 iteration loss is 0.9655033431942724\n",
      "at 7900 iteration loss is 1.0632715640611439\n",
      "at 7900 iteration loss is 0.8691131752747981\n",
      "at 7900 iteration loss is 0.9931996611428311\n",
      "at 7900 iteration loss is 0.7725464239928284\n",
      "at 7900 iteration loss is 0.8327065199157003\n",
      "at 7900 iteration loss is 0.9723835534288614\n",
      "at 7900 iteration loss is 0.9511556858066538\n",
      "at 8000 iteration loss is 1.0286854553107865\n",
      "at 8000 iteration loss is 0.8461314902292087\n",
      "at 8000 iteration loss is 0.8623667055628579\n",
      "at 8000 iteration loss is 0.8821210830250694\n",
      "at 8000 iteration loss is 0.8569495592357195\n",
      "at 8000 iteration loss is 0.9422013478423616\n",
      "at 8000 iteration loss is 0.909321096957607\n",
      "at 8000 iteration loss is 0.8020614824942485\n",
      "at 8000 iteration loss is 1.0145870103775159\n",
      "at 8000 iteration loss is 1.0196362126695397\n",
      "at 8000 iteration loss is 0.9655033511578445\n",
      "at 8000 iteration loss is 1.0632715642147024\n",
      "at 8000 iteration loss is 0.8691131789026036\n",
      "at 8000 iteration loss is 0.993199644267853\n",
      "at 8000 iteration loss is 0.7725464210879092\n",
      "at 8000 iteration loss is 0.832706503648172\n",
      "at 8000 iteration loss is 0.9723835561475687\n",
      "at 8000 iteration loss is 0.9511556935729282\n",
      "at 8100 iteration loss is 1.0286854803508114\n",
      "at 8100 iteration loss is 0.8461314783327574\n",
      "at 8100 iteration loss is 0.8623666969640255\n",
      "at 8100 iteration loss is 0.8821210753638462\n",
      "at 8100 iteration loss is 0.8569495711836618\n",
      "at 8100 iteration loss is 0.9422013366440376\n",
      "at 8100 iteration loss is 0.9093210865230696\n",
      "at 8100 iteration loss is 0.8020614959456219\n",
      "at 8100 iteration loss is 1.0145870224924292\n",
      "at 8100 iteration loss is 1.019636201724479\n",
      "at 8100 iteration loss is 0.9655033580533923\n",
      "at 8100 iteration loss is 1.063271564268055\n",
      "at 8100 iteration loss is 0.869113181961551\n",
      "at 8100 iteration loss is 0.9931996298216257\n",
      "at 8100 iteration loss is 0.7725464185334356\n",
      "at 8100 iteration loss is 0.8327064897738626\n",
      "at 8100 iteration loss is 0.9723835583920163\n",
      "at 8100 iteration loss is 0.95115570033579\n",
      "at 8200 iteration loss is 1.0286855016536303\n",
      "at 8200 iteration loss is 0.8461314681167742\n",
      "at 8200 iteration loss is 0.862366689559029\n",
      "at 8200 iteration loss is 0.8821210687855363\n",
      "at 8200 iteration loss is 0.8569495813778696\n",
      "at 8200 iteration loss is 0.9422013270262012\n",
      "at 8200 iteration loss is 0.9093210776205192\n",
      "at 8200 iteration loss is 0.8020615075421691\n",
      "at 8200 iteration loss is 1.0145870328797453\n",
      "at 8200 iteration loss is 1.0196361926441626\n",
      "at 8200 iteration loss is 0.9655033640246092\n",
      "at 8200 iteration loss is 1.0632715642463801\n",
      "at 8200 iteration loss is 0.869113184540268\n",
      "at 8200 iteration loss is 0.9931996174530578\n",
      "at 8200 iteration loss is 0.7725464162880086\n",
      "at 8200 iteration loss is 0.832706477939712\n",
      "at 8200 iteration loss is 0.9723835602421197\n",
      "at 8200 iteration loss is 0.951155706224635\n",
      "at 8300 iteration loss is 1.0286855197777272\n",
      "at 8300 iteration loss is 0.8461314593426819\n",
      "at 8300 iteration loss is 0.8623666831812817\n",
      "at 8300 iteration loss is 0.8821210631362986\n",
      "at 8300 iteration loss is 0.8569495900765247\n",
      "at 8300 iteration loss is 0.9422013187646595\n",
      "at 8300 iteration loss is 0.9093210700243649\n",
      "at 8300 iteration loss is 0.8020615175409063\n",
      "at 8300 iteration loss is 1.0145870417870033\n",
      "at 8300 iteration loss is 1.0196361851194051\n",
      "at 8300 iteration loss is 0.9655033691957889\n",
      "at 8300 iteration loss is 1.063271564169741\n",
      "at 8300 iteration loss is 0.8691131867136459\n",
      "at 8300 iteration loss is 0.9931996068620194\n",
      "at 8300 iteration loss is 0.772546414314976\n",
      "at 8300 iteration loss is 0.8327064678448771\n",
      "at 8300 iteration loss is 0.9723835617646437\n",
      "at 8300 iteration loss is 0.9511557113522106\n",
      "at 8400 iteration loss is 1.0286855351980333\n",
      "at 8400 iteration loss is 0.8461314518059402\n",
      "at 8400 iteration loss is 0.8623666776875625\n",
      "at 8400 iteration loss is 0.8821210582842556\n",
      "at 8400 iteration loss is 0.8569495974996997\n",
      "at 8400 iteration loss is 0.9422013116671788\n",
      "at 8400 iteration loss is 0.9093210635423242\n",
      "at 8400 iteration loss is 0.8020615261630558\n",
      "at 8400 iteration loss is 1.0145870494261087\n",
      "at 8400 iteration loss is 1.0196361788913006\n",
      "at 8400 iteration loss is 0.9655033736744532\n",
      "at 8400 iteration loss is 1.0632715640540344\n",
      "at 8400 iteration loss is 0.8691131885449608\n",
      "at 8400 iteration loss is 0.9931995977919165\n",
      "at 8400 iteration loss is 0.7725464125819126\n",
      "at 8400 iteration loss is 0.8327064592329905\n",
      "at 8400 iteration loss is 0.9723835630153355\n",
      "at 8400 iteration loss is 0.9511557158167514\n",
      "at 8500 iteration loss is 1.02868554831844\n",
      "at 8500 iteration loss is 0.8461314453311692\n",
      "at 8500 iteration loss is 0.8623666729547175\n",
      "at 8500 iteration loss is 0.8821210541163402\n",
      "at 8500 iteration loss is 0.8569496038349934\n",
      "at 8500 iteration loss is 0.9422013055689069\n",
      "at 8500 iteration loss is 0.9093210580104936\n",
      "at 8500 iteration loss is 0.8020615335990581\n",
      "at 8500 iteration loss is 1.0145870559784875\n",
      "at 8500 iteration loss is 1.0196361737431645\n",
      "at 8500 iteration loss is 0.9655033775536269\n",
      "at 8500 iteration loss is 1.0632715639117656\n",
      "at 8500 iteration loss is 0.8691131900876645\n",
      "at 8500 iteration loss is 0.993199590023352\n",
      "at 8500 iteration loss is 0.7725464110601534\n",
      "at 8500 iteration loss is 0.8327064518855696\n",
      "at 8500 iteration loss is 0.9723835640407034\n",
      "at 8500 iteration loss is 0.9511557197038434\n",
      "at 8600 iteration loss is 1.0286855594824333\n",
      "at 8600 iteration loss is 0.8461314397679691\n",
      "at 8600 iteration loss is 0.8623666688768401\n",
      "at 8600 iteration loss is 0.8821210505356027\n",
      "at 8600 iteration loss is 0.856949609242333\n",
      "at 8600 iteration loss is 0.9422013003284547\n",
      "at 8600 iteration loss is 0.9093210532891487\n",
      "at 8600 iteration loss is 0.8020615400128761\n",
      "at 8600 iteration loss is 1.01458706159949\n",
      "at 8600 iteration loss is 1.0196361694937501\n",
      "at 8600 iteration loss is 0.9655033809137953\n",
      "at 8600 iteration loss is 1.0632715637526904\n",
      "at 8600 iteration loss is 0.8691131913869047\n",
      "at 8600 iteration loss is 0.9931995833687118\n",
      "at 8600 iteration loss is 0.7725464097243708\n",
      "at 8600 iteration loss is 0.832706445616407\n",
      "at 8600 iteration loss is 0.9723835648795225\n",
      "at 8600 iteration loss is 0.9511557230880463\n",
      "at 8700 iteration loss is 1.0286855689821421\n",
      "at 8700 iteration loss is 0.8461314349873478\n",
      "at 8700 iteration loss is 0.8623666653628375\n",
      "at 8700 iteration loss is 0.8821210474589003\n",
      "at 8700 iteration loss is 0.856949613858071\n",
      "at 8700 iteration loss is 0.9422012958245409\n",
      "at 8700 iteration loss is 0.9093210492591697\n",
      "at 8700 iteration loss is 0.802061545545697\n",
      "at 8700 iteration loss is 1.014587066422153\n",
      "at 8700 iteration loss is 1.019636165991544\n",
      "at 8700 iteration loss is 0.9655033838246029\n",
      "at 8700 iteration loss is 1.0632715635843415\n",
      "at 8700 iteration loss is 0.8691131924808093\n",
      "at 8700 iteration loss is 0.9931995776675416\n",
      "at 8700 iteration loss is 0.7725464085522051\n",
      "at 8700 iteration loss is 0.8327064402667895\n",
      "at 8700 iteration loss is 0.9723835655640949\n",
      "at 8700 iteration loss is 0.9511557260343132\n",
      "at 8800 iteration loss is 1.0286855770660186\n",
      "at 8800 iteration loss is 0.8461314308786573\n",
      "at 8800 iteration loss is 0.8623666623343513\n",
      "at 8800 iteration loss is 0.882121044814921\n",
      "at 8800 iteration loss is 0.856949617798465\n",
      "at 8800 iteration loss is 0.9422012919531152\n",
      "at 8800 iteration loss is 0.9093210458189944\n",
      "at 8800 iteration loss is 0.8020615503191092\n",
      "at 8800 iteration loss is 1.014587070560421\n",
      "at 8800 iteration loss is 1.0196361631099697\n",
      "at 8800 iteration loss is 0.9655033863463194\n",
      "at 8800 iteration loss is 1.063271563412463\n",
      "at 8800 iteration loss is 0.8691131934015722\n",
      "at 8800 iteration loss is 0.9931995727826013\n",
      "at 8800 iteration loss is 0.7725464075239242\n",
      "at 8800 iteration loss is 0.8327064357014298\n",
      "at 8800 iteration loss is 0.972383566121306\n",
      "at 8800 iteration loss is 0.9511557285992247\n",
      "at 8900 iteration loss is 1.0286855839453808\n",
      "at 8900 iteration loss is 0.8461314273469736\n",
      "at 8900 iteration loss is 0.8623666597239683\n",
      "at 8900 iteration loss is 0.8821210425424943\n",
      "at 8900 iteration loss is 0.856949621162649\n",
      "at 8900 iteration loss is 0.9422012886249039\n",
      "at 8900 iteration loss is 0.9093210428820229\n",
      "at 8900 iteration loss is 0.8020615544378366\n",
      "at 8900 iteration loss is 1.014587074111899\n",
      "at 8900 iteration loss is 1.0196361607433537\n",
      "at 8900 iteration loss is 0.9655033885311044\n",
      "at 8900 iteration loss is 1.0632715632413654\n",
      "at 8900 iteration loss is 0.8691131941763708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at 8900 iteration loss is 0.9931995685964896\n",
      "at 8900 iteration loss is 0.7725464066221266\n",
      "at 8900 iteration loss is 0.832706431804999\n",
      "at 8900 iteration loss is 0.9723835665735141\n",
      "at 8900 iteration loss is 0.9511557308320642\n",
      "at 9000 iteration loss is 1.0286855897999658\n",
      "at 9000 iteration loss is 0.8461314243108486\n",
      "at 9000 iteration loss is 0.8623666574736818\n",
      "at 9000 iteration loss is 0.8821210405891401\n",
      "at 9000 iteration loss is 0.8569496240351608\n",
      "at 9000 iteration loss is 0.9422012857632952\n",
      "at 9000 iteration loss is 0.9093210403744092\n",
      "at 9000 iteration loss is 0.802061557992093\n",
      "at 9000 iteration loss is 1.0145870771602048\n",
      "at 9000 iteration loss is 1.0196361588035352\n",
      "at 9000 iteration loss is 0.9655033904241019\n",
      "at 9000 iteration loss is 1.0632715630742144\n",
      "at 9000 iteration loss is 0.8691131948281449\n",
      "at 9000 iteration loss is 0.9931995650087677\n",
      "at 9000 iteration loss is 0.772546405831472\n",
      "at 9000 iteration loss is 0.8327064284791771\n",
      "at 9000 iteration loss is 0.972383566939293\n",
      "at 9000 iteration loss is 0.9511557327757583\n",
      "at 9100 iteration loss is 1.028685594782656\n",
      "at 9100 iteration loss is 0.846131421700391\n",
      "at 9100 iteration loss is 0.8623666555335735\n",
      "at 9100 iteration loss is 0.8821210389098271\n",
      "at 9100 iteration loss is 0.8569496264880995\n",
      "at 9100 iteration loss is 0.9422012833025379\n",
      "at 9100 iteration loss is 0.909321038233176\n",
      "at 9100 iteration loss is 0.8020615610595998\n",
      "at 9100 iteration loss is 1.014587079776983\n",
      "at 9100 iteration loss is 1.0196361572170214\n",
      "at 9100 iteration loss is 0.9655033920643916\n",
      "at 9100 iteration loss is 1.0632715629132707\n",
      "at 9100 iteration loss is 0.8691131953762543\n",
      "at 9100 iteration loss is 0.9931995619334953\n",
      "at 9100 iteration loss is 0.7725464051384481\n",
      "at 9100 iteration loss is 0.8327064256401349\n",
      "at 9100 iteration loss is 0.9723835672340588\n",
      "at 9100 iteration loss is 0.9511557344676952\n",
      "at 9200 iteration loss is 1.0286855990234967\n",
      "at 9200 iteration loss is 0.8461314194556152\n",
      "at 9200 iteration loss is 0.8623666538606802\n",
      "at 9200 iteration loss is 0.8821210374659124\n",
      "at 9200 iteration loss is 0.8569496285829569\n",
      "at 9200 iteration loss is 0.9422012811861931\n",
      "at 9200 iteration loss is 0.9093210364046114\n",
      "at 9200 iteration loss is 0.8020615637073247\n",
      "at 9200 iteration loss is 1.0145870820236276\n",
      "at 9200 iteration loss is 1.0196361559225937\n",
      "at 9200 iteration loss is 0.9655033934857998\n",
      "at 9200 iteration loss is 1.06327156276008\n",
      "at 9200 iteration loss is 0.8691131958370345\n",
      "at 9200 iteration loss is 0.9931995592971304\n",
      "at 9200 iteration loss is 0.7725464045311535\n",
      "at 9200 iteration loss is 0.8327064232163959\n",
      "at 9200 iteration loss is 0.9723835674705915\n",
      "at 9200 iteration loss is 0.9511557359404351\n",
      "at 9300 iteration loss is 1.0286856026331095\n",
      "at 9300 iteration loss is 0.8461314175250335\n",
      "at 9300 iteration loss is 0.8623666524180187\n",
      "at 9300 iteration loss is 0.8821210362242298\n",
      "at 9300 iteration loss is 0.8569496303721873\n",
      "at 9300 iteration loss is 0.9422012793658094\n",
      "at 9300 iteration loss is 0.9093210348429033\n",
      "at 9300 iteration loss is 0.8020615659929777\n",
      "at 9300 iteration loss is 1.0145870839527564\n",
      "at 9300 iteration loss is 1.0196361548693045\n",
      "at 9300 iteration loss is 0.9655033947176144\n",
      "at 9300 iteration loss is 1.0632715626156315\n",
      "at 9300 iteration loss is 0.8691131962242645\n",
      "at 9300 iteration loss is 0.9931995570367332\n",
      "at 9300 iteration loss is 0.7725464039991146\n",
      "at 9300 iteration loss is 0.8327064211470091\n",
      "at 9300 iteration loss is 0.9723835676594728\n",
      "at 9300 iteration loss is 0.951155737222337\n",
      "at 9400 iteration loss is 1.0286856057055975\n",
      "at 9400 iteration loss is 0.8461314158644428\n",
      "at 9400 iteration loss is 0.8623666511737509\n",
      "at 9400 iteration loss is 0.8821210351563101\n",
      "at 9400 iteration loss is 0.8569496319005347\n",
      "at 9400 iteration loss is 0.9422012777997857\n",
      "at 9400 iteration loss is 0.9093210335089715\n",
      "at 9400 iteration loss is 0.8020615679662979\n",
      "at 9400 iteration loss is 1.0145870856094674\n",
      "at 9400 iteration loss is 1.019636154014788\n",
      "at 9400 iteration loss is 0.9655033957851904\n",
      "at 9400 iteration loss is 1.063271562480483\n",
      "at 9400 iteration loss is 0.8691131965495668\n",
      "at 9400 iteration loss is 0.9931995550984306\n",
      "at 9400 iteration loss is 0.7725464035331157\n",
      "at 9400 iteration loss is 0.8327064193799956\n",
      "at 9400 iteration loss is 0.9723835678094537\n",
      "at 9400 iteration loss is 0.9511557383380953\n",
      "at 9500 iteration loss is 1.0286856083210163\n",
      "at 9500 iteration loss is 0.8461314144358925\n",
      "at 9500 iteration loss is 0.8623666501004624\n",
      "at 9500 iteration loss is 0.8821210342377117\n",
      "at 9500 iteration loss is 0.8569496332061723\n",
      "at 9500 iteration loss is 0.942201276452398\n",
      "at 9500 iteration loss is 0.9093210323694787\n",
      "at 9500 iteration loss is 0.8020615696701576\n",
      "at 9500 iteration loss is 1.014587087032427\n",
      "at 9500 iteration loss is 1.0196361533238523\n",
      "at 9500 iteration loss is 0.9655033967104831\n",
      "at 9500 iteration loss is 1.0632715623548628\n",
      "at 9500 iteration loss is 0.869113196822741\n",
      "at 9500 iteration loss is 0.9931995534361049\n",
      "at 9500 iteration loss is 0.7725464031250523\n",
      "at 9500 iteration loss is 0.8327064178710257\n",
      "at 9500 iteration loss is 0.9723835679277617\n",
      "at 9500 iteration loss is 0.9511557393092149\n",
      "at 9600 iteration loss is 1.0286856105474727\n",
      "at 9600 iteration loss is 0.8461314132067919\n",
      "at 9600 iteration loss is 0.8623666491745474\n",
      "at 9600 iteration loss is 0.8821210334474496\n",
      "at 9600 iteration loss is 0.8569496343216697\n",
      "at 9600 iteration loss is 0.942201275292966\n",
      "at 9600 iteration loss is 0.9093210313959819\n",
      "at 9600 iteration loss is 0.8020615711415168\n",
      "at 9600 iteration loss is 1.0145870882547816\n",
      "at 9600 iteration loss is 1.0196361527672948\n",
      "at 9600 iteration loss is 0.9655033975125041\n",
      "at 9600 iteration loss is 1.0632715622387514\n",
      "at 9600 iteration loss is 0.8691131970520491\n",
      "at 9600 iteration loss is 0.9931995520102715\n",
      "at 9600 iteration loss is 0.7725464027677993\n",
      "at 9600 iteration loss is 0.8327064165822865\n",
      "at 9600 iteration loss is 0.9723835680203552\n",
      "at 9600 iteration loss is 0.9511557401544204\n",
      "at 9700 iteration loss is 1.0286856124429091\n",
      "at 9700 iteration loss is 0.8461314121491517\n",
      "at 9700 iteration loss is 0.8623666483756729\n",
      "at 9700 iteration loss is 0.8821210327675013\n",
      "at 9700 iteration loss is 0.8569496352748164\n",
      "at 9700 iteration loss is 0.9422012742951378\n",
      "at 9700 iteration loss is 0.9093210305642122\n",
      "at 9700 iteration loss is 0.802061572412244\n",
      "at 9700 iteration loss is 1.0145870893049551\n",
      "at 9700 iteration loss is 1.0196361523209077\n",
      "at 9700 iteration loss is 0.9655033982077184\n",
      "at 9700 iteration loss is 1.0632715621319482\n",
      "at 9700 iteration loss is 0.8691131972444566\n",
      "at 9700 iteration loss is 0.9931995507871216\n",
      "at 9700 iteration loss is 0.7725464024550968\n",
      "at 9700 iteration loss is 0.8327064154815254\n",
      "at 9700 iteration loss is 0.9723835680921414\n",
      "at 9700 iteration loss is 0.9511557408900174\n",
      "at 9800 iteration loss is 1.028685614056624\n",
      "at 9800 iteration loss is 0.8461314112389318\n",
      "at 9800 iteration loss is 0.8623666476863268\n",
      "at 9800 iteration loss is 0.8821210321823901\n",
      "at 9800 iteration loss is 0.8569496360893302\n",
      "at 9800 iteration loss is 0.9422012734362719\n",
      "at 9800 iteration loss is 0.909321029853461\n",
      "at 9800 iteration loss is 0.8020615735098169\n",
      "at 9800 iteration loss is 1.0145870902073257\n",
      "at 9800 iteration loss is 1.0196361519646495\n",
      "at 9800 iteration loss is 0.9655033988103844\n",
      "at 9800 iteration loss is 1.063271562034121\n",
      "at 9800 iteration loss is 0.8691131974058294\n",
      "at 9800 iteration loss is 0.9931995497377033\n",
      "at 9800 iteration loss is 0.7725464021814441\n",
      "at 9800 iteration loss is 0.8327064145412273\n",
      "at 9800 iteration loss is 0.9723835681471522\n",
      "at 9800 iteration loss is 0.9511557415302028\n",
      "at 9900 iteration loss is 1.0286856154305635\n",
      "at 9900 iteration loss is 0.846131410455478\n",
      "at 9900 iteration loss is 0.8623666470914222\n",
      "at 9900 iteration loss is 0.88212103167882\n",
      "at 9900 iteration loss is 0.8569496367854479\n",
      "at 9900 iteration loss is 0.9422012726969179\n",
      "at 9900 iteration loss is 0.9093210292460553\n",
      "at 9900 iteration loss is 0.8020615744579324\n",
      "at 9900 iteration loss is 1.014587090982801\n",
      "at 9900 iteration loss is 1.0196361516819483\n",
      "at 9900 iteration loss is 0.9655033993328527\n",
      "at 9900 iteration loss is 1.0632715619448476\n",
      "at 9900 iteration loss is 0.8691131975411117\n",
      "at 9900 iteration loss is 0.9931995488372181\n",
      "at 9900 iteration loss is 0.7725464019420117\n",
      "at 9900 iteration loss is 0.8327064137379173\n",
      "at 9900 iteration loss is 0.9723835681886938\n",
      "at 9900 iteration loss is 0.9511557420873364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at 0 iteration loss is 3.289995291285206\n",
      "at 0 iteration loss is 2.3618707931981175\n",
      "at 0 iteration loss is 1.0672096867085474\n",
      "at 0 iteration loss is 1.697222474395393\n",
      "at 0 iteration loss is 1.1439888804245177\n",
      "at 0 iteration loss is 1.5627305580215691\n",
      "at 0 iteration loss is 1.4489227845755628\n",
      "at 0 iteration loss is 0.8230787350711676\n",
      "at 0 iteration loss is 1.0100061694547149\n",
      "at 0 iteration loss is 0.9180753872773554\n",
      "at 0 iteration loss is 0.9717430458808535\n",
      "at 0 iteration loss is 0.8081650703802344\n",
      "at 0 iteration loss is 0.8250959442688355\n",
      "at 0 iteration loss is 0.8968634613526077\n",
      "at 0 iteration loss is 0.7451200664952149\n",
      "at 0 iteration loss is 0.8788322507252861\n",
      "at 0 iteration loss is 0.8650825360797224\n",
      "at 0 iteration loss is 0.9320158697019444\n",
      "at 100 iteration loss is 1.1663353903072138\n",
      "at 100 iteration loss is 1.023411722808908\n",
      "at 100 iteration loss is 1.035318420654921\n",
      "at 100 iteration loss is 1.1692517527723836\n",
      "at 100 iteration loss is 1.0118187530734746\n",
      "at 100 iteration loss is 1.1621328206954147\n",
      "at 100 iteration loss is 1.1184678369224597\n",
      "at 100 iteration loss is 1.0773858594225285\n",
      "at 100 iteration loss is 0.9585985187196435\n",
      "at 100 iteration loss is 1.0276064121926152\n",
      "at 100 iteration loss is 1.1138315381098196\n",
      "at 100 iteration loss is 1.0721510669850378\n",
      "at 100 iteration loss is 0.9242339313002301\n",
      "at 100 iteration loss is 1.0832009271850018\n",
      "at 100 iteration loss is 1.0118462310855691\n",
      "at 100 iteration loss is 1.0858945360874448\n",
      "at 100 iteration loss is 1.0056549519401616\n",
      "at 100 iteration loss is 1.0659521484113408\n",
      "at 200 iteration loss is 1.1655717092819506\n",
      "at 200 iteration loss is 1.0467184156397598\n",
      "at 200 iteration loss is 1.069808793051845\n",
      "at 200 iteration loss is 1.2085638271135057\n",
      "at 200 iteration loss is 1.0361724346112575\n",
      "at 200 iteration loss is 1.1542971978788577\n",
      "at 200 iteration loss is 1.1125385555363352\n",
      "at 200 iteration loss is 1.1217232605101326\n",
      "at 200 iteration loss is 0.9560313808529017\n",
      "at 200 iteration loss is 1.0600789418652112\n",
      "at 200 iteration loss is 1.1059638432761756\n",
      "at 200 iteration loss is 1.1134243877908692\n",
      "at 200 iteration loss is 0.9413072368096381\n",
      "at 200 iteration loss is 1.091012183071925\n",
      "at 200 iteration loss is 1.0376413578760977\n",
      "at 200 iteration loss is 1.1034090887801282\n",
      "at 200 iteration loss is 1.033011347316267\n",
      "at 200 iteration loss is 1.0589223411046136\n",
      "at 300 iteration loss is 1.1655175116467231\n",
      "at 300 iteration loss is 1.0603729845222876\n",
      "at 300 iteration loss is 1.089241023253691\n",
      "at 300 iteration loss is 1.2317226879658398\n",
      "at 300 iteration loss is 1.051452877771639\n",
      "at 300 iteration loss is 1.1502515995762614\n",
      "at 300 iteration loss is 1.1094989519227285\n",
      "at 300 iteration loss is 1.1484501551898558\n",
      "at 300 iteration loss is 0.9540211726657173\n",
      "at 300 iteration loss is 1.080148399908412\n",
      "at 300 iteration loss is 1.101533138619858\n",
      "at 300 iteration loss is 1.1395054981847625\n",
      "at 300 iteration loss is 0.9529839729110983\n",
      "at 300 iteration loss is 1.0964266932132278\n",
      "at 300 iteration loss is 1.053641946039948\n",
      "at 300 iteration loss is 1.1130887248856256\n",
      "at 300 iteration loss is 1.0513501388584647\n",
      "at 300 iteration loss is 1.0555023477592234\n",
      "at 400 iteration loss is 1.165634111893238\n",
      "at 400 iteration loss is 1.0681203019217178\n",
      "at 400 iteration loss is 1.099684983575092\n",
      "at 400 iteration loss is 1.244584518435074\n",
      "at 400 iteration loss is 1.0605917064510093\n",
      "at 400 iteration loss is 1.1476781953178068\n",
      "at 400 iteration loss is 1.1077185077180673\n",
      "at 400 iteration loss is 1.1641462627809154\n",
      "at 400 iteration loss is 0.9523129751880429\n",
      "at 400 iteration loss is 1.0922022251061931\n",
      "at 400 iteration loss is 1.0987153901412137\n",
      "at 400 iteration loss is 1.1559336698881888\n",
      "at 400 iteration loss is 0.9610376964957938\n",
      "at 400 iteration loss is 1.1001195726380475\n",
      "at 400 iteration loss is 1.0634764296928794\n",
      "at 400 iteration loss is 1.1178853738157482\n",
      "at 400 iteration loss is 1.063872241634951\n",
      "at 400 iteration loss is 1.053661156121808\n",
      "at 500 iteration loss is 1.1657776651239422\n",
      "at 500 iteration loss is 1.0723839792820449\n",
      "at 500 iteration loss is 1.1049584908115648\n",
      "at 500 iteration loss is 1.251322621908643\n",
      "at 500 iteration loss is 1.0658938739317045\n",
      "at 500 iteration loss is 1.1457863649049536\n",
      "at 500 iteration loss is 1.1065640102545808\n",
      "at 500 iteration loss is 1.173210031865709\n",
      "at 500 iteration loss is 0.9508388119787707\n",
      "at 500 iteration loss is 1.0993568404185428\n",
      "at 500 iteration loss is 1.096759321064508\n",
      "at 500 iteration loss is 1.1664297593245054\n",
      "at 500 iteration loss is 0.9667417986999455\n",
      "at 500 iteration loss is 1.1026866728711222\n",
      "at 500 iteration loss is 1.069567120120981\n",
      "at 500 iteration loss is 1.1198482364720266\n",
      "at 500 iteration loss is 1.0726820657545977\n",
      "at 500 iteration loss is 1.0525888891708202\n",
      "at 600 iteration loss is 1.165919870832822\n",
      "at 600 iteration loss is 1.0746360922566773\n",
      "at 600 iteration loss is 1.1073341494200055\n",
      "at 600 iteration loss is 1.254555701062972\n",
      "at 600 iteration loss is 1.068892776162081\n",
      "at 600 iteration loss is 1.1442837351469044\n",
      "at 600 iteration loss is 1.105760225236891\n",
      "at 600 iteration loss is 1.1783660593252447\n",
      "at 600 iteration loss is 0.9495700250911749\n",
      "at 600 iteration loss is 1.1035899311785513\n",
      "at 600 iteration loss is 1.0953181217983112\n",
      "at 600 iteration loss is 1.173307446172188\n",
      "at 600 iteration loss is 0.9709176660477281\n",
      "at 600 iteration loss is 1.1045354981921427\n",
      "at 600 iteration loss is 1.073410076795037\n",
      "at 600 iteration loss is 1.1202507260586119\n",
      "at 600 iteration loss is 1.0790943214387534\n",
      "at 600 iteration loss is 1.0519283071964287\n",
      "at 700 iteration loss is 1.1660606057110172\n",
      "at 700 iteration loss is 1.0757458476661077\n",
      "at 700 iteration loss is 1.1081300513705823\n",
      "at 700 iteration loss is 1.255843089444704\n",
      "at 700 iteration loss is 1.0705411979451764\n",
      "at 700 iteration loss is 1.1430454257537614\n",
      "at 700 iteration loss is 1.1051725989257961\n",
      "at 700 iteration loss is 1.1812470094902472\n",
      "at 700 iteration loss is 0.9484837237950862\n",
      "at 700 iteration loss is 1.1060998679757814\n",
      "at 700 iteration loss is 1.0942125120173627\n",
      "at 700 iteration loss is 1.1779643921662717\n",
      "at 700 iteration loss is 0.9740780624840646\n",
      "at 700 iteration loss is 1.1059224085522934\n",
      "at 700 iteration loss is 1.075901632410917\n",
      "at 700 iteration loss is 1.119844343753918\n",
      "at 700 iteration loss is 1.08392027306157\n",
      "at 700 iteration loss is 1.0515050954075988\n",
      "at 800 iteration loss is 1.1662032196057726\n",
      "at 800 iteration loss is 1.0762185977449674\n",
      "at 800 iteration loss is 1.1080980420006297\n",
      "at 800 iteration loss is 1.2560878964470619\n",
      "at 800 iteration loss is 1.071411583013592\n",
      "at 800 iteration loss is 1.1420067760406083\n",
      "at 800 iteration loss is 1.1047280125434478\n",
      "at 800 iteration loss is 1.182815136061895\n",
      "at 800 iteration loss is 0.9475573964856533\n",
      "at 800 iteration loss is 1.1075973779397024\n",
      "at 800 iteration loss is 1.0933403044445087\n",
      "at 800 iteration loss is 1.1812368594434273\n",
      "at 800 iteration loss is 0.9765419744074577\n",
      "at 800 iteration loss is 1.1070039002163057\n",
      "at 800 iteration loss is 1.077572549337715\n",
      "at 800 iteration loss is 1.1190581810449791\n",
      "at 800 iteration loss is 1.0876628912123902\n",
      "at 800 iteration loss is 1.0512264632531136\n",
      "at 900 iteration loss is 1.166349092736892\n",
      "at 900 iteration loss is 1.0763449851547005\n",
      "at 900 iteration loss is 1.107660526992444\n",
      "at 900 iteration loss is 1.255803154038441\n",
      "at 900 iteration loss is 1.0718413326425755\n",
      "at 900 iteration loss is 1.1411275146941096\n",
      "at 900 iteration loss is 1.1043831790461134\n",
      "at 900 iteration loss is 1.183632257949157\n",
      "at 900 iteration loss is 0.9467693466352223\n",
      "at 900 iteration loss is 1.1084996406124006\n",
      "at 900 iteration loss is 1.0926384953503647\n",
      "at 900 iteration loss is 1.1836255043080801\n",
      "at 900 iteration loss is 0.9785103495594178\n",
      "at 900 iteration loss is 1.1078750954982541\n",
      "at 900 iteration loss is 1.0787363849946423\n",
      "at 900 iteration loss is 1.1181300012768953\n",
      "at 900 iteration loss is 1.0906388057735612\n",
      "at 900 iteration loss is 1.05103954075833\n",
      "at 1000 iteration loss is 1.1664974998946551\n",
      "at 1000 iteration loss is 1.0762905051300895\n",
      "at 1000 iteration loss is 1.107050507661028\n",
      "at 1000 iteration loss is 1.2552749807831804\n",
      "at 1000 iteration loss is 1.0720267465286688\n",
      "at 1000 iteration loss is 1.1403790916373708\n",
      "at 1000 iteration loss is 1.1041107295347916\n",
      "at 1000 iteration loss is 1.1840243659083398\n",
      "at 1000 iteration loss is 0.9460996435889608\n",
      "at 1000 iteration loss is 1.1090504373802335\n",
      "at 1000 iteration loss is 1.0920657471379045\n",
      "at 1000 iteration loss is 1.1854323914660745\n",
      "at 1000 iteration loss is 0.9801128170708117\n",
      "at 1000 iteration loss is 1.1085945685136567\n",
      "at 1000 iteration loss is 1.07957910219434\n",
      "at 1000 iteration loss is 1.117186711996064\n",
      "at 1000 iteration loss is 1.093052082056738\n",
      "at 1000 iteration loss is 1.0509126332285788\n",
      "at 1100 iteration loss is 1.1666465203230008\n",
      "at 1100 iteration loss is 1.0761482931631436\n",
      "at 1100 iteration loss is 1.1063931272361793\n",
      "at 1100 iteration loss is 1.2546593030228659\n",
      "at 1100 iteration loss is 1.0720807751195385\n",
      "at 1100 iteration loss is 1.1397397134709226\n",
      "at 1100 iteration loss is 1.1038924588539425\n",
      "at 1100 iteration loss is 1.1841796636712503\n",
      "at 1100 iteration loss is 0.9455306306921125\n",
      "at 1100 iteration loss is 1.1093921131524151\n",
      "at 1100 iteration loss is 1.0915935387663191\n",
      "at 1100 iteration loss is 1.1868423651878048\n",
      "at 1100 iteration loss is 0.9814357238983803\n",
      "at 1100 iteration loss is 1.1091993896066998\n",
      "at 1100 iteration loss is 1.0802120241075248\n",
      "at 1100 iteration loss is 1.1162921718856635\n",
      "at 1100 iteration loss is 1.0950382824852858\n",
      "at 1100 iteration loss is 1.0508259947349778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at 1200 iteration loss is 1.1667938448627937\n",
      "at 1200 iteration loss is 1.0759699166561962\n",
      "at 1200 iteration loss is 1.1057527239982725\n",
      "at 1200 iteration loss is 1.2540381838694397\n",
      "at 1200 iteration loss is 1.0720676329107068\n",
      "at 1200 iteration loss is 1.1391920717602073\n",
      "at 1200 iteration loss is 1.103715753800381\n",
      "at 1200 iteration loss is 1.1842062460300506\n",
      "at 1200 iteration loss is 0.945047023195125\n",
      "at 1200 iteration loss is 1.1096079585842487\n",
      "at 1200 iteration loss is 1.0912013531586087\n",
      "at 1200 iteration loss is 1.1879708945621796\n",
      "at 1200 iteration loss is 0.9825387814124085\n",
      "at 1200 iteration loss is 1.1097139699538423\n",
      "at 1200 iteration loss is 1.0807027971637875\n",
      "at 1200 iteration loss is 1.115475058571501\n",
      "at 1200 iteration loss is 1.0966906863494579\n",
      "at 1200 iteration loss is 1.0507669383467522\n",
      "at 1300 iteration loss is 1.1669372798882875\n",
      "at 1300 iteration loss is 1.0757832184364893\n",
      "at 1300 iteration loss is 1.1051597985721993\n",
      "at 1300 iteration loss is 1.253452280022643\n",
      "at 1300 iteration loss is 1.0720232549820274\n",
      "at 1300 iteration loss is 1.138722105333879\n",
      "at 1300 iteration loss is 1.1035715719673607\n",
      "at 1300 iteration loss is 1.1841657942410413\n",
      "at 1300 iteration loss is 0.9446357691291636\n",
      "at 1300 iteration loss is 1.109746946490555\n",
      "at 1300 iteration loss is 1.0908739050948555\n",
      "at 1300 iteration loss is 1.1888920946504995\n",
      "at 1300 iteration loss is 0.983464938672386\n",
      "at 1300 iteration loss is 1.1101551825589655\n",
      "at 1300 iteration loss is 1.0810934057323707\n",
      "at 1300 iteration loss is 1.1147448995544544\n",
      "at 1300 iteration loss is 1.098075925505237\n",
      "at 1300 iteration loss is 1.0507270945694251\n",
      "at 1400 iteration loss is 1.1670749980413413\n",
      "at 1400 iteration loss is 1.0756026070912466\n",
      "at 1400 iteration loss is 1.1046263725799035\n",
      "at 1400 iteration loss is 1.2529193997466033\n",
      "at 1400 iteration loss is 1.0719672858910243\n",
      "at 1400 iteration loss is 1.138318222270288\n",
      "at 1400 iteration loss is 1.1034532382078832\n",
      "at 1400 iteration loss is 1.1840931774288936\n",
      "at 1400 iteration loss is 0.9442858061241003\n",
      "at 1400 iteration loss is 1.1098380986948777\n",
      "at 1400 iteration loss is 1.0905994707227709\n",
      "at 1400 iteration loss is 1.1896551352884752\n",
      "at 1400 iteration loss is 0.9842462738325188\n",
      "at 1400 iteration loss is 1.1105353084885203\n",
      "at 1400 iteration loss is 1.081410637337331\n",
      "at 1400 iteration loss is 1.1141011870791526\n",
      "at 1400 iteration loss is 1.099243373295077\n",
      "at 1400 iteration loss is 1.0507008097977144\n",
      "at 1500 iteration loss is 1.1672056241465179\n",
      "at 1500 iteration loss is 1.0754349662562404\n",
      "at 1500 iteration loss is 1.1041546730931737\n",
      "at 1500 iteration loss is 1.2524450391945996\n",
      "at 1500 iteration loss is 1.0719100662416832\n",
      "at 1500 iteration loss is 1.1379707640612073\n",
      "at 1500 iteration loss is 1.1033556994916427\n",
      "at 1500 iteration loss is 1.1840078236079215\n",
      "at 1500 iteration loss is 0.9439877916311268\n",
      "at 1500 iteration loss is 1.109898810052761\n",
      "at 1500 iteration loss is 1.0903688421515867\n",
      "at 1500 iteration loss is 1.1902938782406018\n",
      "at 1500 iteration loss is 0.9849075543927025\n",
      "at 1500 iteration loss is 1.110863732815786\n",
      "at 1500 iteration loss is 1.0816721685555954\n",
      "at 1500 iteration loss is 1.1135384940735717\n",
      "at 1500 iteration loss is 1.1002308497769535\n",
      "at 1500 iteration loss is 1.0506841817887722\n",
      "at 1600 iteration loss is 1.1673282280200585\n",
      "at 1600 iteration loss is 1.0752830329083765\n",
      "at 1600 iteration loss is 1.1037419967204651\n",
      "at 1600 iteration loss is 1.2520283158112355\n",
      "at 1600 iteration loss is 1.0718566852423848\n",
      "at 1600 iteration loss is 1.1376716167515721\n",
      "at 1600 iteration loss is 1.1032750485847824\n",
      "at 1600 iteration loss is 1.18392030283173\n",
      "at 1600 iteration loss is 0.9437338450957036\n",
      "at 1600 iteration loss is 1.1099396678839974\n",
      "at 1600 iteration loss is 1.0901746502720198\n",
      "at 1600 iteration loss is 1.1908325714937127\n",
      "at 1600 iteration loss is 0.9854684313176735\n",
      "at 1600 iteration loss is 1.111147928300604\n",
      "at 1600 iteration loss is 1.0818901166125887\n",
      "at 1600 iteration loss is 1.1130492966925734\n",
      "at 1600 iteration loss is 1.1010681494684627\n",
      "at 1600 iteration loss is 1.050674464445163\n",
      "at 1700 iteration loss is 1.167442271878216\n",
      "at 1700 iteration loss is 1.0751473181323075\n",
      "at 1700 iteration loss is 1.1033833966998843\n",
      "at 1700 iteration loss is 1.251665272719475\n",
      "at 1700 iteration loss is 1.0718093200499133\n",
      "at 1700 iteration loss is 1.137413919661355\n",
      "at 1700 iteration loss is 1.1032082107027268\n",
      "at 1700 iteration loss is 1.1838361318480661\n",
      "at 1700 iteration loss is 0.9435173180440997\n",
      "at 1700 iteration loss is 1.10996724437697\n",
      "at 1700 iteration loss is 1.0900109111194731\n",
      "at 1700 iteration loss is 1.191289246242261\n",
      "at 1700 iteration loss is 0.9859448280359192\n",
      "at 1700 iteration loss is 1.1113940352575038\n",
      "at 1700 iteration loss is 1.0820731251476423\n",
      "at 1700 iteration loss is 1.1126254918901846\n",
      "at 1700 iteration loss is 1.1017792746525688\n",
      "at 1700 iteration loss is 1.0506696924750918\n",
      "at 1800 iteration loss is 1.1675475408942049\n",
      "at 1800 iteration loss is 1.0750271910408098\n",
      "at 1800 iteration loss is 1.1030731361275594\n",
      "at 1800 iteration loss is 1.2513506885080612\n",
      "at 1800 iteration loss is 1.0717685779106652\n",
      "at 1800 iteration loss is 1.1371918421871423\n",
      "at 1800 iteration loss is 1.1031527315984546\n",
      "at 1800 iteration loss is 1.1837579689766127\n",
      "at 1800 iteration loss is 0.9433325962978089\n",
      "at 1800 iteration loss is 1.109985718158381\n",
      "at 1800 iteration loss is 1.0898727116544529\n",
      "at 1800 iteration loss is 1.1916777717842166\n",
      "at 1800 iteration loss is 0.9863498498840407\n",
      "at 1800 iteration loss is 1.1116072127398844\n",
      "at 1800 iteration loss is 1.0822276012334457\n",
      "at 1800 iteration loss is 1.1122591792220216\n",
      "at 1800 iteration loss is 1.1023838919121833\n",
      "at 1800 iteration loss is 1.0506684396954027\n",
      "at 1900 iteration loss is 1.16764407254975\n",
      "at 1900 iteration loss is 1.0749214837671819\n",
      "at 1900 iteration loss is 1.1028054468869835\n",
      "at 1900 iteration loss is 1.251079042209383\n",
      "at 1900 iteration loss is 1.0717342594901011\n",
      "at 1900 iteration loss is 1.1370004094749202\n",
      "at 1900 iteration loss is 1.1031066302681716\n",
      "at 1900 iteration loss is 1.183686877453555\n",
      "at 1900 iteration loss is 0.9431749330273315\n",
      "at 1900 iteration loss is 1.1099978197878808\n",
      "at 1900 iteration loss is 1.0897559848517908\n",
      "at 1900 iteration loss is 1.1920091225552056\n",
      "at 1900 iteration loss is 0.9866944031883019\n",
      "at 1900 iteration loss is 1.111791859802296\n",
      "at 1900 iteration loss is 1.0823584595836748\n",
      "at 1900 iteration loss is 1.1119430328853934\n",
      "at 1900 iteration loss is 1.102898315965722\n",
      "at 1900 iteration loss is 1.0506696600369483\n",
      "at 2000 iteration loss is 1.1677320924597634\n",
      "at 2000 iteration loss is 1.0748288234531498\n",
      "at 2000 iteration loss is 1.1025749019151125\n",
      "at 2000 iteration loss is 1.250845004577156\n",
      "at 2000 iteration loss is 1.0717057873030884\n",
      "at 2000 iteration loss is 1.1368353638980158\n",
      "at 2000 iteration loss is 1.103068293763792\n",
      "at 2000 iteration loss is 1.1836230502719816\n",
      "at 2000 iteration loss is 0.9430403091704391\n",
      "at 2000 iteration loss is 1.110005386604819\n",
      "at 2000 iteration loss is 1.0896573436354735\n",
      "at 2000 iteration loss is 1.192292179147749\n",
      "at 2000 iteration loss is 0.986987634432281\n",
      "at 2000 iteration loss is 1.1119517622682815\n",
      "at 2000 iteration loss is 1.0824695792148047\n",
      "at 2000 iteration loss is 1.1116704496754308\n",
      "at 2000 iteration loss is 1.1033362001735303\n",
      "at 2000 iteration loss is 1.0506725806299262\n",
      "at 2100 iteration loss is 1.167811959731842\n",
      "at 2100 iteration loss is 1.074747809443569\n",
      "at 2100 iteration loss is 1.1023765754704915\n",
      "at 2100 iteration loss is 1.2506436669308525\n",
      "at 2100 iteration loss is 1.0716824412000692\n",
      "at 2100 iteration loss is 1.136693053255089\n",
      "at 2100 iteration loss is 1.1030364000953363\n",
      "at 2100 iteration loss is 1.1835662240419542\n",
      "at 2100 iteration loss is 0.9429253171917391\n",
      "at 2100 iteration loss is 1.1100096914435476\n",
      "at 2100 iteration loss is 1.0895739547686085\n",
      "at 2100 iteration loss is 1.192534250629484\n",
      "at 2100 iteration loss is 0.9872372545353031\n",
      "at 2100 iteration loss is 1.1120901960127711\n",
      "at 2100 iteration loss is 1.0825640910417054\n",
      "at 2100 iteration loss is 1.1114355778997151\n",
      "at 2100 iteration loss is 1.1037090402783654\n",
      "at 2100 iteration loss is 1.0506766282887077\n",
      "at 2200 iteration loss is 1.1678841224139203\n",
      "at 2200 iteration loss is 1.0746771033808806\n",
      "at 2200 iteration loss is 1.1022060900159285\n",
      "at 2200 iteration loss is 1.2504706273365442\n",
      "at 2200 iteration loss is 1.071663483393591\n",
      "at 2200 iteration loss is 1.1365703392815698\n",
      "at 2200 iteration loss is 1.1030098603416973\n",
      "at 2200 iteration loss is 1.1835159134869264\n",
      "at 2200 iteration loss is 0.9428270643494772\n",
      "at 2200 iteration loss is 1.1100116400184468\n",
      "at 2200 iteration loss is 1.0895034407337678\n",
      "at 2200 iteration loss is 1.192741427591526\n",
      "at 2200 iteration loss is 0.9874497870333115\n",
      "at 2200 iteration loss is 1.1122100040899023\n",
      "at 2200 iteration loss is 1.0826445649359704\n",
      "at 2200 iteration loss is 1.1112332861370702\n",
      "at 2200 iteration loss is 1.104026555377072\n",
      "at 2200 iteration loss is 1.050681377840492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at 2300 iteration loss is 1.1679490823355738\n",
      "at 2300 iteration loss is 1.0746154708471203\n",
      "at 2300 iteration loss is 1.1020596049474671\n",
      "at 2300 iteration loss is 1.2503220016207905\n",
      "at 2300 iteration loss is 1.0716482208593494\n",
      "at 2300 iteration loss is 1.1364645218967468\n",
      "at 2300 iteration loss is 1.1029877742382739\n",
      "at 2300 iteration loss is 1.1834715426686107\n",
      "at 2300 iteration loss is 0.9427430921041143\n",
      "at 2300 iteration loss is 1.1100118916301462\n",
      "at 2300 iteration loss is 1.0894438018435142\n",
      "at 2300 iteration loss is 1.1929188302337097\n",
      "at 2300 iteration loss is 0.9876307637519759\n",
      "at 2300 iteration loss is 1.112313657416754\n",
      "at 2300 iteration loss is 1.0827131360299476\n",
      "at 2300 iteration loss is 1.1110591044154947\n",
      "at 2300 iteration loss is 1.104296985160867\n",
      "at 2300 iteration loss is 1.0506865150442368\n",
      "at 2400 iteration loss is 1.1680073681212464\n",
      "at 2400 iteration loss is 1.0745617965315115\n",
      "at 2400 iteration loss is 1.101933777740311\n",
      "at 2400 iteration loss is 1.2501943969192368\n",
      "at 2400 iteration loss is 1.0716360327723855\n",
      "at 2400 iteration loss is 1.136373275865702\n",
      "at 2400 iteration loss is 1.1029693954679556\n",
      "at 2400 iteration loss is 1.1834325169073523\n",
      "at 2400 iteration loss is 0.9426713088329004\n",
      "at 2400 iteration loss is 1.1100109347386318\n",
      "at 2400 iteration loss is 1.0893933534120341\n",
      "at 2400 iteration loss is 1.1930707896026762\n",
      "at 2400 iteration loss is 0.9877848826960897\n",
      "at 2400 iteration loss is 1.1124033044999826\n",
      "at 2400 iteration loss is 1.0827715934962447\n",
      "at 2400 iteration loss is 1.11090915546325\n",
      "at 2400 iteration loss is 1.1045273277510614\n",
      "at 2400 iteration loss is 1.0506918094728723\n",
      "at 2500 iteration loss is 1.1680595150175421\n",
      "at 2500 iteration loss is 1.0745150853532892\n",
      "at 2500 iteration loss is 1.1018257141263395\n",
      "at 2500 iteration loss is 1.25008486853182\n",
      "at 2500 iteration loss is 1.071626378902969\n",
      "at 2500 iteration loss is 1.136294597424421\n",
      "at 2500 iteration loss is 1.1029541041153554\n",
      "at 2500 iteration loss is 1.1833982607869704\n",
      "at 2500 iteration loss is 0.9426099335104283\n",
      "at 2500 iteration loss is 1.1100091356564554\n",
      "at 2500 iteration loss is 1.0893506744428576\n",
      "at 2500 iteration loss is 1.1932009848528264\n",
      "at 2500 iteration loss is 0.98791613765536\n",
      "at 2500 iteration loss is 1.1124808133623925\n",
      "at 2500 iteration loss is 1.0828214454866472\n",
      "at 2500 iteration loss is 1.1107800852839833\n",
      "at 2500 iteration loss is 1.104723533717501\n",
      "at 2500 iteration loss is 1.0506970943534846\n",
      "at 2600 iteration loss is 1.1681060502380984\n",
      "at 2600 iteration loss is 1.0744744565132123\n",
      "at 2600 iteration loss is 1.1017329160698117\n",
      "at 2600 iteration loss is 1.2499908712799002\n",
      "at 2600 iteration loss is 1.0716187980764675\n",
      "at 2600 iteration loss is 1.1362267590224817\n",
      "at 2600 iteration loss is 1.102941384533034\n",
      "at 2600 iteration loss is 1.1833682368926188\n",
      "at 2600 iteration loss is 0.9425574484434115\n",
      "at 2600 iteration loss is 1.1100067709674195\n",
      "at 2600 iteration loss is 1.089314565326108\n",
      "at 2600 iteration loss is 1.193312550485317\n",
      "at 2600 iteration loss is 0.988027925900707\n",
      "at 2600 iteration loss is 1.112547807545734\n",
      "at 2600 iteration loss is 1.082863968394785\n",
      "at 2600 iteration loss is 1.1106689976213378\n",
      "at 2600 iteration loss is 1.104890666612464\n",
      "at 2600 iteration loss is 1.050702251374167\n",
      "at 2700 iteration loss is 1.168147482678203\n",
      "at 2700 iteration loss is 1.0744391343389283\n",
      "at 2700 iteration loss is 1.101653231935113\n",
      "at 2700 iteration loss is 1.2499102111796663\n",
      "at 2700 iteration loss is 1.0716129018449683\n",
      "at 2700 iteration loss is 1.1361682707654541\n",
      "at 2700 iteration loss is 1.1029308073814401\n",
      "at 2700 iteration loss is 1.1833419537227838\n",
      "at 2700 iteration loss is 0.9425125595032455\n",
      "at 2700 iteration loss is 1.1100040498728476\n",
      "at 2700 iteration loss is 1.0892840127183256\n",
      "at 2700 iteration loss is 1.1934081622728763\n",
      "at 2700 iteration loss is 0.9881231384334214\n",
      "at 2700 iteration loss is 1.1126056973623608\n",
      "at 2700 iteration loss is 1.082900245401604\n",
      "at 2700 iteration loss is 1.1105733943050362\n",
      "at 2700 iteration loss is 1.1050330371392187\n",
      "at 2700 iteration loss is 1.0507071991093253\n",
      "at 2800 iteration loss is 1.1681842960273552\n",
      "at 2800 iteration loss is 1.0744084380260515\n",
      "at 2800 iteration loss is 1.1015848108375768\n",
      "at 2800 iteration loss is 1.2498410002532643\n",
      "at 2800 iteration loss is 1.0716083662297975\n",
      "at 2800 iteration loss is 1.1361178474458942\n",
      "at 2800 iteration loss is 1.1029220149447263\n",
      "at 2800 iteration loss is 1.1833189676297002\n",
      "at 2800 iteration loss is 0.9424741625887023\n",
      "at 2800 iteration loss is 1.110001130128314\n",
      "at 2800 iteration loss is 1.089258160234687\n",
      "at 2800 iteration loss is 1.1934901074598192\n",
      "at 2800 iteration loss is 0.9882042360458743\n",
      "at 2800 iteration loss is 1.112655707179909\n",
      "at 2800 iteration loss is 1.0829311973889368\n",
      "at 2800 iteration loss is 1.1104911220902092\n",
      "at 2800 iteration loss is 1.1051543160628576\n",
      "at 2800 iteration loss is 1.0507118841299423\n",
      "at 2900 iteration loss is 1.1682169444807982\n",
      "at 2900 iteration loss is 1.0743817713823356\n",
      "at 2900 iteration loss is 1.1015260618765508\n",
      "at 2900 iteration loss is 1.2497816156608845\n",
      "at 2900 iteration loss is 1.071604923076526\n",
      "at 2900 iteration loss is 1.1360743802759545\n",
      "at 2900 iteration loss is 1.1029147090553293\n",
      "at 2900 iteration loss is 1.18329888157068\n",
      "at 2900 iteration loss is 0.9424413152835951\n",
      "at 2900 iteration loss is 1.109998129765095\n",
      "at 2900 iteration loss is 1.0892362838994696\n",
      "at 2900 iteration loss is 1.1935603429486266\n",
      "at 2900 iteration loss is 0.9882733136668111\n",
      "at 2900 iteration loss is 1.1126988993050466\n",
      "at 2900 iteration loss is 1.082957608200163\n",
      "at 2900 iteration loss is 1.110420325890517\n",
      "at 2900 iteration loss is 1.1052576296735404\n",
      "at 2900 iteration loss is 1.0507162741377276\n",
      "at 3000 iteration loss is 1.1682458504065905\n",
      "at 3000 iteration loss is 1.0743586131262703\n",
      "at 3000 iteration loss is 1.1014756182798109\n",
      "at 3000 iteration loss is 1.2497306634632253\n",
      "at 3000 iteration loss is 1.0716023518114919\n",
      "at 3000 iteration loss is 1.1360369126018952\n",
      "at 3000 iteration loss is 1.1029086411205105\n",
      "at 3000 iteration loss is 1.1832813422565907\n",
      "at 3000 iteration loss is 0.9424132128607685\n",
      "at 3000 iteration loss is 1.1099951359370768\n",
      "at 3000 iteration loss is 1.0892177715259588\n",
      "at 3000 iteration loss is 1.19362054403249\n",
      "at 3000 iteration loss is 0.9883321549296615\n",
      "at 3000 iteration loss is 1.1127361949057633\n",
      "at 3000 iteration loss is 1.0829801455643775\n",
      "at 3000 iteration loss is 1.1103594079651677\n",
      "at 3000 iteration loss is 1.1053456407445474\n",
      "at 3000 iteration loss is 1.0507203526448279\n",
      "at 3100 iteration loss is 1.1682714034580612\n",
      "at 3100 iteration loss is 1.0743385079845642\n",
      "at 3100 iteration loss is 1.1014323061627471\n",
      "at 3100 iteration loss is 1.249686946878006\n",
      "at 3100 iteration loss is 1.0716004719642516\n",
      "at 3100 iteration loss is 1.1360046190083313\n",
      "at 3100 iteration loss is 1.102903603858165\n",
      "at 3100 iteration loss is 1.1832660365936005\n",
      "at 3100 iteration loss is 0.9423891679337025\n",
      "at 3100 iteration loss is 1.1099922117338734\n",
      "at 3100 iteration loss is 1.0892021053625154\n",
      "at 3100 iteration loss is 1.1936721455096577\n",
      "at 3100 iteration loss is 0.9883822785223394\n",
      "at 3100 iteration loss is 1.112768392333631\n",
      "at 3100 iteration loss is 1.0829993785957654\n",
      "at 3100 iteration loss is 1.1103069924814735\n",
      "at 3100 iteration loss is 1.105420617323259\n",
      "at 3100 iteration loss is 1.0507241148460253\n",
      "at 3200 iteration loss is 1.1682939607322265\n",
      "at 3200 iteration loss is 1.0743210586669876\n",
      "at 3200 iteration loss is 1.1013951174674879\n",
      "at 3200 iteration loss is 1.2496494386853325\n",
      "at 3200 iteration loss is 1.0715991365858233\n",
      "at 3200 iteration loss is 1.1359767873194249\n",
      "at 3200 iteration loss is 1.1028994244324763\n",
      "at 3200 iteration loss is 1.1832526879166636\n",
      "at 3200 iteration loss is 0.9423685931777633\n",
      "at 3200 iteration loss is 1.109989401504642\n",
      "at 3200 iteration loss is 1.0891888474664975\n",
      "at 3200 iteration loss is 1.1937163765470313\n",
      "at 3200 iteration loss is 0.9884249775952825\n",
      "at 3200 iteration loss is 1.112796183155265\n",
      "at 3200 iteration loss is 1.083015792526017\n",
      "at 3200 iteration loss is 1.1102618948430236\n",
      "at 3200 iteration loss is 1.1054844912546553\n",
      "at 3200 iteration loss is 1.0507275644182228\n",
      "at 3300 iteration loss is 1.1683138476648884\n",
      "at 3300 iteration loss is 1.0743059187104227\n",
      "at 3300 iteration loss is 1.101363186608427\n",
      "at 3300 iteration loss is 1.2496172573564688\n",
      "at 3300 iteration loss is 1.071598226567351\n",
      "at 3300 iteration loss is 1.1359528030831405\n",
      "at 3300 iteration loss is 1.1028959587422922\n",
      "at 3300 iteration loss is 1.1832410522845869\n",
      "at 3300 iteration loss is 0.9423509866410134\n",
      "at 3300 iteration loss is 1.1099867350584232\n",
      "at 3300 iteration loss is 1.0891776273644556\n",
      "at 3300 iteration loss is 1.1937542903465264\n",
      "at 3300 iteration loss is 0.9884613532877861\n",
      "at 3300 iteration loss is 1.1128201661637838\n",
      "at 3300 iteration loss is 1.083029801163152\n",
      "at 3300 iteration loss is 1.1102230951959455\n",
      "at 3300 iteration loss is 1.1055389080059066\n",
      "at 3300 iteration loss is 1.0507307110450321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at 3400 iteration loss is 1.1683313594253264\n",
      "at 3400 iteration loss is 1.0742927861413025\n",
      "at 3400 iteration loss is 1.1013357703622602\n",
      "at 3400 iteration loss is 1.2495896464680283\n",
      "at 3400 iteration loss is 1.0715976458011287\n",
      "at 3400 iteration loss is 1.1359321361884933\n",
      "at 3400 iteration loss is 1.102893086662571\n",
      "at 3400 iteration loss is 1.1832309149756781\n",
      "at 3400 iteration loss is 0.9423359192441841\n",
      "at 3400 iteration loss is 1.1099842309966634\n",
      "at 3400 iteration loss is 1.089168131633359\n",
      "at 3400 iteration loss is 1.1937867894489533\n",
      "at 3400 iteration loss is 0.9884923432608638\n",
      "at 3400 iteration loss is 1.1128408596102661\n",
      "at 3400 iteration loss is 1.0830417574593652\n",
      "at 3400 iteration loss is 1.1101897155728984\n",
      "at 3400 iteration loss is 1.1055852691023316\n",
      "at 3400 iteration loss is 1.0507335685103818\n",
      "at 3500 iteration loss is 1.1683467626308068\n",
      "at 3500 iteration loss is 1.0742813978873105\n",
      "at 3500 iteration loss is 1.101312230575803\n",
      "at 3500 iteration loss is 1.2495659569848592\n",
      "at 3500 iteration loss is 1.0715973170983493\n",
      "at 3500 iteration loss is 1.1359143293180278\n",
      "at 3500 iteration loss is 1.1028907080762942\n",
      "at 3500 iteration loss is 1.1832220872484487\n",
      "at 3500 iteration loss is 0.9423230241346643\n",
      "at 3500 iteration loss is 1.1099818993633903\n",
      "at 3500 iteration loss is 1.089160095098965\n",
      "at 3500 iteration loss is 1.1938146473516578\n",
      "at 3500 iteration loss is 0.9885187459854403\n",
      "at 3500 iteration loss is 1.1128587118688784\n",
      "at 3500 iteration loss is 1.0830519624927457\n",
      "at 3500 iteration loss is 1.1101610001906148\n",
      "at 3500 iteration loss is 1.1056247682777696\n",
      "at 3500 iteration loss is 1.0507361532395485\n",
      "at 3600 iteration loss is 1.1683602972461233\n",
      "at 3600 iteration loss is 1.0742715248637928\n",
      "at 3600 iteration loss is 1.1012920193090079\n",
      "at 3600 iteration loss is 1.2495456320311888\n",
      "at 3600 iteration loss is 1.0715971787698153\n",
      "at 3600 iteration loss is 1.135898987981215\n",
      "at 3600 iteration loss is 1.1028887395634341\n",
      "at 3600 iteration loss is 1.1832144033900502\n",
      "at 3600 iteration loss is 0.9423119876130837\n",
      "at 3600 iteration loss is 1.1099797437523047\n",
      "at 3600 iteration loss is 1.089153293397341\n",
      "at 3600 iteration loss is 1.193838526996982\n",
      "at 3600 iteration loss is 0.9885412414196753\n",
      "at 3600 iteration loss is 1.1128741107260784\n",
      "at 3600 iteration loss is 1.083060673110891\n",
      "at 3600 iteration loss is 1.110136298473905\n",
      "at 3600 iteration loss is 1.105658422272801\n",
      "at 3600 iteration loss is 1.0507384831921227\n",
      "at 3700 iteration loss is 1.1683721785684844\n",
      "at 3700 iteration loss is 1.074262967661726\n",
      "at 3700 iteration loss is 1.101274666076231\n",
      "at 3700 iteration loss is 1.249528193811025\n",
      "at 3700 iteration loss is 1.0715971817778125\n",
      "at 3700 iteration loss is 1.1358857719108635\n",
      "at 3700 iteration loss is 1.1028871116370382\n",
      "at 3700 iteration loss is 1.1832077180520542\n",
      "at 3700 iteration loss is 0.9423025413955584\n",
      "at 3700 iteration loss is 1.1099777629782188\n",
      "at 3700 iteration loss is 1.08914753668655\n",
      "at 3700 iteration loss is 1.1938589965960715\n",
      "at 3700 iteration loss is 0.9885604086132254\n",
      "at 3700 iteration loss is 1.1128873914632933\n",
      "at 3700 iteration loss is 1.083068108441287\n",
      "at 3700 iteration loss is 1.1101150504329156\n",
      "at 3700 iteration loss is 1.105687097073322\n",
      "at 3700 iteration loss is 1.0507405770315335\n",
      "at 3800 iteration loss is 1.168382599225311\n",
      "at 3800 iteration loss is 1.0742555527686686\n",
      "at 3800 iteration loss is 1.1012597668920727\n",
      "at 3800 iteration loss is 1.2495132323799905\n",
      "at 3800 iteration loss is 1.0715972873744573\n",
      "at 3800 iteration loss is 1.1358743876354194\n",
      "at 3800 iteration loss is 1.1028857664354106\n",
      "at 3800 iteration loss is 1.1832019038610007\n",
      "at 3800 iteration loss is 0.942294456011614\n",
      "at 3800 iteration loss is 1.1099759523975332\n",
      "at 3800 iteration loss is 1.08914266432951\n",
      "at 3800 iteration loss is 1.1938765431787122\n",
      "at 3800 iteration loss is 0.9885767406955079\n",
      "at 3800 iteration loss is 1.1128988438834226\n",
      "at 3800 iteration loss is 1.0830744554394813\n",
      "at 3800 iteration loss is 1.1100967740694976\n",
      "at 3800 iteration loss is 1.1057115302636737\n",
      "at 3800 iteration loss is 1.0507424535114498\n",
      "at 3900 iteration loss is 1.1683917311333942\n",
      "at 3900 iteration loss is 1.074249129260042\n",
      "at 3900 iteration loss is 1.1012469748675908\n",
      "at 3900 iteration loss is 1.2495003960093556\n",
      "at 3900 iteration loss is 1.0715974651508726\n",
      "at 3900 iteration loss is 1.135864582066124\n",
      "at 3900 iteration loss is 1.1028846557948646\n",
      "at 3900 iteration loss is 1.183196849285094\n",
      "at 3900 iteration loss is 0.9422875351686567\n",
      "at 3900 iteration loss is 1.1099743049454844\n",
      "at 3900 iteration loss is 1.0891385403972673\n",
      "at 3900 iteration loss is 1.1938915841998115\n",
      "at 3900 iteration loss is 0.9885906576367928\n",
      "at 3900 iteration loss is 1.1129087184142308\n",
      "at 3900 iteration loss is 1.0830798736189091\n",
      "at 3900 iteration loss is 1.1100810545320905\n",
      "at 3900 iteration loss is 1.1057323500685918\n",
      "at 3900 iteration loss is 1.0507441310316326\n",
      "at 4000 iteration loss is 1.1683997273839402\n",
      "at 4000 iteration loss is 1.074243565904426\n",
      "at 4000 iteration loss is 1.1012359921376627\n",
      "at 4000 iteration loss is 1.2494893829178848\n",
      "at 4000 iteration loss is 1.0715976914311778\n",
      "at 4000 iteration loss is 1.135856136960364\n",
      "at 4000 iteration loss is 1.1028837396402182\n",
      "at 4000 iteration loss is 1.1831924567360257\n",
      "at 4000 iteration loss is 0.9422816109397114\n",
      "at 4000 iteration loss is 1.1099728119449173\n",
      "at 4000 iteration loss is 1.089135049865659\n",
      "at 4000 iteration loss is 1.1939044774834424\n",
      "at 4000 iteration loss is 0.9886025171130433\n",
      "at 4000 iteration loss is 1.112917231406076\n",
      "at 4000 iteration loss is 1.083084499083973\n",
      "at 4000 iteration loss is 1.1100675347768327\n",
      "at 4000 iteration loss is 1.105750091573424\n",
      "at 4000 iteration loss is 1.0507456273255789\n",
      "at 4100 iteration loss is 1.1684067240301415\n",
      "at 4100 iteration loss is 1.0742387486326364\n",
      "at 4100 iteration loss is 1.1012265629309506\n",
      "at 4100 iteration loss is 1.249479934177974\n",
      "at 4100 iteration loss is 1.0715979479544298\n",
      "at 4100 iteration loss is 1.13584886414159\n",
      "at 4100 iteration loss is 1.102882984640692\n",
      "at 4100 iteration loss is 1.1831886408843666\n",
      "at 4100 iteration loss is 0.9422765396528735\n",
      "at 4100 iteration loss is 1.1099714637310707\n",
      "at 4100 iteration loss is 1.089132095398112\n",
      "at 4100 iteration loss is 1.1939155297438329\n",
      "at 4100 iteration loss is 0.9886126237562671\n",
      "at 4100 iteration loss is 1.1129245697273866\n",
      "at 4100 iteration loss is 1.0830884479694904\n",
      "at 4100 iteration loss is 1.1100559075259686\n",
      "at 4100 iteration loss is 1.1057652105398659\n",
      "at 4100 iteration loss is 1.0507469592500285\n",
      "at 4200 iteration loss is 1.168412841763067\n",
      "at 4200 iteration loss is 1.0742345783260665\n",
      "at 4200 iteration loss is 1.1012184676204917\n",
      "at 4200 iteration loss is 1.2494718276295265\n",
      "at 4200 iteration loss is 1.0715982207960768\n",
      "at 4200 iteration loss is 1.1358426013726308\n",
      "at 4200 iteration loss is 1.1028823630875402\n",
      "at 4200 iteration loss is 1.1831853271676207\n",
      "at 4200 iteration loss is 0.9422721983791849\n",
      "at 4200 iteration loss is 1.1099702501286544\n",
      "at 4200 iteration loss is 1.0891295946240587\n",
      "at 4200 iteration loss is 1.1939250038876763\n",
      "at 4200 iteration loss is 0.9886212370302652\n",
      "at 4200 iteration loss is 1.1129308947486818\n",
      "at 4200 iteration loss is 1.0830918193741665\n",
      "at 4200 iteration loss is 1.110045908343443\n",
      "at 4200 iteration loss is 1.1057780951729943\n",
      "at 4200 iteration loss is 1.050748142652542\n",
      "at 4300 iteration loss is 1.168418187468453\n",
      "at 4300 iteration loss is 1.0742309688849738\n",
      "at 4300 iteration loss is 1.1012115176158948\n",
      "at 4300 iteration loss is 1.2494648726584905\n",
      "at 4300 iteration loss is 1.0715984994879733\n",
      "at 4300 iteration loss is 1.1358372087933093\n",
      "at 4300 iteration loss is 1.102881851956981\n",
      "at 4300 iteration loss is 1.1831824504711739\n",
      "at 4300 iteration loss is 0.9422684819311336\n",
      "at 4300 iteration loss is 1.1099691608108286\n",
      "at 4300 iteration loss is 1.089127477836485\n",
      "at 4300 iteration loss is 1.1939331252724827\n",
      "at 4300 iteration loss is 0.9886285779360776\n",
      "at 4300 iteration loss is 1.1129363457947425\n",
      "at 4300 iteration loss is 1.0830946978626503\n",
      "at 4300 iteration loss is 1.1100373096726146\n",
      "at 4300 iteration loss is 1.1057890761429032\n",
      "at 4300 iteration loss is 1.0507491922983747\n",
      "at 4400 iteration loss is 1.1684228556619671\n",
      "at 4400 iteration loss is 1.0742278455420589\n",
      "at 4400 iteration loss is 1.1012055509778504\n",
      "at 4400 iteration loss is 1.2494589057171748\n",
      "at 4400 iteration loss is 1.0715987763025168\n",
      "at 4400 iteration loss is 1.1358325658454302\n",
      "at 4400 iteration loss is 1.1028814321279585\n",
      "at 4400 iteration loss is 1.1831799539638355\n",
      "at 4400 iteration loss is 0.9422653002970174\n",
      "at 4400 iteration loss is 1.109968185564226\n",
      "at 4400 iteration loss is 1.089125686043958\n",
      "at 4400 iteration loss is 1.1939400870704584\n",
      "at 4400 iteration loss is 0.9886348347210481\n",
      "at 4400 iteration loss is 1.1129410431345623\n",
      "at 4400 iteration loss is 1.083097155599742\n",
      "at 4400 iteration loss is 1.1100299157024671\n",
      "at 4400 iteration loss is 1.1057984351194936\n",
      "at 4400 iteration loss is 1.0507501218417197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at 4500 iteration loss is 1.16842692980407\n",
      "at 4500 iteration loss is 1.074225143390835\n",
      "at 4500 iteration loss is 1.1012004286526385\n",
      "at 4500 iteration loss is 1.2494537864809128\n",
      "at 4500 iteration loss is 1.071599045672049\n",
      "at 4500 iteration loss is 1.1358285686186906\n",
      "at 4500 iteration loss is 1.1028810877293138\n",
      "at 4500 iteration loss is 1.183177788071178\n",
      "at 4500 iteration loss is 0.9422625764474887\n",
      "at 4500 iteration loss is 1.1099673144796613\n",
      "at 4500 iteration loss is 1.0891241693225127\n",
      "at 4500 iteration loss is 1.193946054865907\n",
      "at 4500 iteration loss is 0.9886401677396351\n",
      "at 4500 iteration loss is 1.112945090569906\n",
      "at 4500 iteration loss is 1.0830992541708622\n",
      "at 4500 iteration loss is 1.1100235579473197\n",
      "at 4500 iteration loss is 1.1058064120408004\n",
      "at 4500 iteration loss is 1.050750943829659\n",
      "at 4600 iteration loss is 1.1684304834981643\n",
      "at 4600 iteration loss is 1.074222806102\n",
      "at 4600 iteration loss is 1.1011960312388331\n",
      "at 4600 iteration loss is 1.2494493945506158\n",
      "at 4600 iteration loss is 1.0715993037195182\n",
      "at 4600 iteration loss is 1.13582512756011\n",
      "at 4600 iteration loss is 1.1028808055950727\n",
      "at 4600 iteration loss is 1.183175909571438\n",
      "at 4600 iteration loss is 0.9422602444600322\n",
      "at 4600 iteration loss is 1.109966538084517\n",
      "at 4600 iteration loss is 1.0891228854211792\n",
      "at 4600 iteration loss is 1.1939511705957546\n",
      "at 4600 iteration loss is 0.9886447135920587\n",
      "at 4600 iteration loss is 1.1129485776755235\n",
      "at 4600 iteration loss is 1.0831010461349693\n",
      "at 4600 iteration loss is 1.1100180914409477\n",
      "at 4600 iteration loss is 1.105813211302658\n",
      "at 4600 iteration loss is 1.050751669729639\n",
      "at 4700 iteration loss is 1.1684335815773508\n",
      "at 4700 iteration loss is 1.0742207848042526\n",
      "at 4700 iteration loss is 1.1011922562108896\n",
      "at 4700 iteration loss is 1.2494456266236489\n",
      "at 4700 iteration loss is 1.0715995478803493\n",
      "at 4700 iteration loss is 1.135822165497374\n",
      "at 4700 iteration loss is 1.1028805748100805\n",
      "at 4700 iteration loss is 1.183174280800197\n",
      "at 4700 iteration loss is 0.9422582479150492\n",
      "at 4700 iteration loss is 1.1099658474297027\n",
      "at 4700 iteration loss is 1.0891217985820876\n",
      "at 4700 iteration loss is 1.1939555559271147\n",
      "at 4700 iteration loss is 0.9886485886481466\n",
      "at 4700 iteration loss is 1.1129515817372557\n",
      "at 4700 iteration loss is 1.0831025763492625\n",
      "at 4700 iteration loss is 1.1100133914598433\n",
      "at 4700 iteration loss is 1.1058190070297238\n",
      "at 4700 iteration loss is 1.0507523099733305\n",
      "at 4800 iteration loss is 1.1684362810862394\n",
      "at 4800 iteration loss is 1.0742190371089033\n",
      "at 4800 iteration loss is 1.101189015534986\n",
      "at 4800 iteration loss is 1.249442394066447\n",
      "at 4800 iteration loss is 1.0715997765989906\n",
      "at 4800 iteration loss is 1.1358196159332608\n",
      "at 4800 iteration loss is 1.1028803863311158\n",
      "at 4800 iteration loss is 1.1831728689514263\n",
      "at 4800 iteration loss is 0.942256538524093\n",
      "at 4800 iteration loss is 1.1099652341416166\n",
      "at 4800 iteration loss is 1.089120878542111\n",
      "at 4800 iteration loss is 1.1939593151523507\n",
      "at 4800 iteration loss is 0.9886518920477932\n",
      "at 4800 iteration loss is 1.1129541694282454\n",
      "at 4800 iteration loss is 1.083103883099264\n",
      "at 4800 iteration loss is 1.1100093507021236\n",
      "at 4800 iteration loss is 1.1058239475641733\n",
      "at 4800 iteration loss is 1.0507528740113623\n",
      "at 4900 iteration loss is 1.1684386321648494\n",
      "at 4900 iteration loss is 1.0742175262601354\n",
      "at 4900 iteration loss is 1.1011862336216511\n",
      "at 4900 iteration loss is 1.2494396208318133\n",
      "at 4900 iteration loss is 1.0715999890863777\n",
      "at 4900 iteration loss is 1.135817421574103\n",
      "at 4900 iteration loss is 1.102880232671029\n",
      "at 4900 iteration loss is 1.183171645463784\n",
      "at 4900 iteration loss is 0.9422550749565035\n",
      "at 4900 iteration loss is 1.1099646904474638\n",
      "at 4900 iteration loss is 1.089120099688091\n",
      "at 4900 iteration loss is 1.1939625376705765\n",
      "at 4900 iteration loss is 0.9886547082558197\n",
      "at 4900 iteration loss is 1.1129563982582475\n",
      "at 4900 iteration loss is 1.083104999062864\n",
      "at 4900 iteration loss is 1.1100058768588348\n",
      "at 4900 iteration loss is 1.1058281592882042\n",
      "at 4900 iteration loss is 1.0507533703746958\n",
      "at 5000 iteration loss is 1.1684406788419104\n",
      "at 5000 iteration loss is 1.0742162203950394\n",
      "at 5000 iteration loss is 1.1011838455675818\n",
      "at 5000 iteration loss is 1.2494372416719148\n",
      "at 5000 iteration loss is 1.0716001851270032\n",
      "at 5000 iteration loss is 1.1358155330603221\n",
      "at 5000 iteration loss is 1.1028801076355341\n",
      "at 5000 iteration loss is 1.1831705854822456\n",
      "at 5000 iteration loss is 0.9422538218356786\n",
      "at 5000 iteration loss is 1.1099642091806179\n",
      "at 5000 iteration loss is 1.0891194403420037\n",
      "at 5000 iteration loss is 1.1939653001146957\n",
      "at 5000 iteration loss is 0.9886571092374913\n",
      "at 5000 iteration loss is 1.1129583178264142\n",
      "at 5000 iteration loss is 1.0831059521327755\n",
      "at 5000 iteration loss is 1.1100028905231638\n",
      "at 5000 iteration loss is 1.1058317498792445\n",
      "at 5000 iteration loss is 1.050753806739443\n",
      "at 5100 iteration loss is 1.1684424597449101\n",
      "at 5100 iteration loss is 1.074215091899491\n",
      "at 5100 iteration loss is 1.101181795645792\n",
      "at 5100 iteration loss is 1.2494352006050047\n",
      "at 5100 iteration loss is 1.0716003649262724\n",
      "at 5100 iteration loss is 1.135813907871397\n",
      "at 5100 iteration loss is 1.1028800061039503\n",
      "at 5100 iteration loss is 1.1831696673861807\n",
      "at 5100 iteration loss is 0.9422527488803863\n",
      "at 5100 iteration loss is 1.1099637837713396\n",
      "at 5100 iteration loss is 1.0891188821560778\n",
      "at 5100 iteration loss is 1.1939676681746254\n",
      "at 5100 iteration loss is 0.9886591563110873\n",
      "at 5100 iteration loss is 1.1129599709039613\n",
      "at 5100 iteration loss is 1.0831067661182185\n",
      "at 5100 iteration loss is 1.1100003233906295\n",
      "at 5100 iteration loss is 1.1058348110821057\n",
      "at 5100 iteration loss is 1.0507541899927404\n",
      "at 5200 iteration loss is 1.168444008734053\n",
      "at 5200 iteration loss is 1.0742141168476615\n",
      "at 5200 iteration loss is 1.1011800360089945\n",
      "at 5200 iteration loss is 1.2494334495998036\n",
      "at 5200 iteration loss is 1.0716005289904422\n",
      "at 5200 iteration loss is 1.135812509381388\n",
      "at 5200 iteration loss is 1.1028799238466176\n",
      "at 5200 iteration loss is 1.1831688723759952\n",
      "at 5200 iteration loss is 0.9422518301700904\n",
      "at 5200 iteration loss is 1.1099634082270107\n",
      "at 5200 iteration loss is 1.0891184096009325\n",
      "at 5200 iteration loss is 1.1939696981600907\n",
      "at 5200 iteration loss is 0.9886609017254875\n",
      "at 5200 iteration loss is 1.1129613943695893\n",
      "at 5200 iteration loss is 1.0831074613435596\n",
      "at 5200 iteration loss is 1.1099981167098236\n",
      "at 5200 iteration loss is 1.1058374210697994\n",
      "at 5200 iteration loss is 1.0507545262979088\n",
      "at 5300 iteration loss is 1.1684453554670473\n",
      "at 5300 iteration loss is 1.0742132745144994\n",
      "at 5300 iteration loss is 1.1011785255761204\n",
      "at 5300 iteration loss is 1.2494319474466624\n",
      "at 5300 iteration loss is 1.0716006780329024\n",
      "at 5300 iteration loss is 1.1358113060444222\n",
      "at 5300 iteration loss is 1.1028798573729324\n",
      "at 5300 iteration loss is 1.183168184111338\n",
      "at 5300 iteration loss is 0.9422510435163666\n",
      "at 5300 iteration loss is 1.1099630771051985\n",
      "at 5300 iteration loss is 1.0891180095324267\n",
      "at 5300 iteration loss is 1.1939714383402151\n",
      "at 5300 iteration loss is 0.9886623900036827\n",
      "at 5300 iteration loss is 1.1129626200175278\n",
      "at 5300 iteration loss is 1.083108055159079\n",
      "at 5300 iteration loss is 1.1099962199489073\n",
      "at 5300 iteration loss is 1.1058396464541151\n",
      "at 5300 iteration loss is 1.0507548211576732\n",
      "at 5400 iteration loss is 1.1684465259012464\n",
      "at 5400 iteration loss is 1.074212546951823\n",
      "at 5400 iteration loss is 1.1011772290760997\n",
      "at 5400 iteration loss is 1.2494306587889743\n",
      "at 5400 iteration loss is 1.0716008129015913\n",
      "at 5400 iteration loss is 1.1358102706923077\n",
      "at 5400 iteration loss is 1.1028798038049055\n",
      "at 5400 iteration loss is 1.1831675883946478\n",
      "at 5400 iteration loss is 0.9422503699250356\n",
      "at 5400 iteration loss is 1.1099627854820648\n",
      "at 5400 iteration loss is 1.0891176708251111\n",
      "at 5400 iteration loss is 1.1939729300917716\n",
      "at 5400 iteration loss is 0.9886636590869549\n",
      "at 5400 iteration loss is 1.1129636752554053\n",
      "at 5400 iteration loss is 1.0831085623767858\n",
      "at 5400 iteration loss is 1.1099945896478534\n",
      "at 5400 iteration loss is 1.1058415439979492\n",
      "at 5400 iteration loss is 1.0507550794745646\n",
      "at 5500 iteration loss is 1.1684475427393022\n",
      "at 5500 iteration loss is 1.0742119186198777\n",
      "at 5500 iteration loss is 1.101176116226706\n",
      "at 5500 iteration loss is 1.2494295532920896\n",
      "at 5500 iteration loss is 1.0716009345233968\n",
      "at 5500 iteration loss is 1.1358093799289253\n",
      "at 5500 iteration loss is 1.1028797607720267\n",
      "at 5500 iteration loss is 1.1831670728945451\n",
      "at 5500 iteration loss is 0.9422497931359105\n",
      "at 5500 iteration loss is 1.1099625289180957\n",
      "at 5500 iteration loss is 1.0891173840620414\n",
      "at 5500 iteration loss is 1.1939742088834495\n",
      "at 5500 iteration loss is 0.9886647413093662\n",
      "at 5500 iteration loss is 1.1129645837068625\n",
      "at 5500 iteration loss is 1.0831089956422646\n",
      "at 5500 iteration loss is 1.109993188430653\n",
      "at 5500 iteration loss is 1.1058431620736902\n",
      "at 5500 iteration loss is 1.050755305607943\n",
      "at 5600 iteration loss is 1.1684484258239956\n",
      "at 5600 iteration loss is 1.0742113760671748\n",
      "at 5600 iteration loss is 1.1011751610293818\n",
      "at 5600 iteration loss is 1.249428604930205\n",
      "at 5600 iteration loss is 1.071601043862062\n",
      "at 5600 iteration loss is 1.1358086136080943\n",
      "at 5600 iteration loss is 1.1028797263238594\n",
      "at 5600 iteration loss is 1.183166626904192\n",
      "at 5600 iteration loss is 0.9422492992289306\n",
      "at 5600 iteration loss is 1.1099623034226083\n",
      "at 5600 iteration loss is 1.0891171412722656\n",
      "at 5600 iteration loss is 1.193975305119532\n",
      "at 5600 iteration loss is 0.9886656642277257\n",
      "at 5600 iteration loss is 1.112965365731807\n",
      "at 5600 iteration loss is 1.083109365751987\n",
      "at 5600 iteration loss is 1.1099919841551853\n",
      "at 5600 iteration loss is 1.1058445419053453\n",
      "at 5600 iteration loss is 1.050755503427315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at 5700 iteration loss is 1.1684491924875453\n",
      "at 5700 iteration loss is 1.0742109076524262\n",
      "at 5700 iteration loss is 1.101174341163689\n",
      "at 5700 iteration loss is 1.2494277913745055\n",
      "at 5700 iteration loss is 1.0716011418868545\n",
      "at 5700 iteration loss is 1.1358079543834734\n",
      "at 5700 iteration loss is 1.1028796988574454\n",
      "at 5700 iteration loss is 1.1831662411303365\n",
      "at 5700 iteration loss is 0.9422488762871033\n",
      "at 5700 iteration loss is 1.1099621054181743\n",
      "at 5700 iteration loss is 1.08911693570868\n",
      "at 5700 iteration loss is 1.1939762448630977\n",
      "at 5700 iteration loss is 0.9886664513285359\n",
      "at 5700 iteration loss is 1.112966038875507\n",
      "at 5700 iteration loss is 1.0831096819240726\n",
      "at 5700 iteration loss is 1.1099909491816669\n",
      "at 5700 iteration loss is 1.1058457186265271\n",
      "at 5700 iteration loss is 1.0507556763617898\n",
      "at 5800 iteration loss is 1.1684498578601727\n",
      "at 5800 iteration loss is 1.0742105033030707\n",
      "at 5800 iteration loss is 1.1011736374672947\n",
      "at 5800 iteration loss is 1.24942709346815\n",
      "at 5800 iteration loss is 1.0716012295497164\n",
      "at 5800 iteration loss is 1.1358073873205843\n",
      "at 5800 iteration loss is 1.1028796770570215\n",
      "at 5800 iteration loss is 1.1831659075092333\n",
      "at 5800 iteration loss is 0.9422485141080388\n",
      "at 5800 iteration loss is 1.1099619317057265\n",
      "at 5800 iteration loss is 1.0891167616600161\n",
      "at 5800 iteration loss is 1.1939770504559235\n",
      "at 5800 iteration loss is 0.988667122630153\n",
      "at 5800 iteration loss is 1.1129666182561828\n",
      "at 5800 iteration loss is 1.0831099520293535\n",
      "at 5800 iteration loss is 1.109990059743124\n",
      "at 5800 iteration loss is 1.1058467221816255\n",
      "at 5800 iteration loss is 1.0507558274456368\n",
      "at 5900 iteration loss is 1.1684504351423388\n",
      "at 5900 iteration loss is 1.0742101543056821\n",
      "at 5900 iteration loss is 1.101173033489441\n",
      "at 5900 iteration loss is 1.2494264947758087\n",
      "at 5900 iteration loss is 1.0716013077690651\n",
      "at 5900 iteration loss is 1.1358068995624158\n",
      "at 5900 iteration loss is 1.1028796598439858\n",
      "at 5900 iteration loss is 1.1831656190461177\n",
      "at 5900 iteration loss is 0.9422482039570615\n",
      "at 5900 iteration loss is 1.1099617794309458\n",
      "at 5900 iteration loss is 1.0891166142917368\n",
      "at 5900 iteration loss is 1.1939777410498693\n",
      "at 5900 iteration loss is 0.9886676951957215\n",
      "at 5900 iteration loss is 1.112967116899475\n",
      "at 5900 iteration loss is 1.0831101827885663\n",
      "at 5900 iteration loss is 1.109989295403721\n",
      "at 5900 iteration loss is 1.105847578093439\n",
      "at 5900 iteration loss is 1.0507559593600209\n",
      "at 6000 iteration loss is 1.1684509358446418\n",
      "at 6000 iteration loss is 1.0742098531240818\n",
      "at 6000 iteration loss is 1.1011725151074923\n",
      "at 6000 iteration loss is 1.2494259811971482\n",
      "at 6000 iteration loss is 1.0716013774187831\n",
      "at 6000 iteration loss is 1.135806480041249\n",
      "at 6000 iteration loss is 1.1028796463354218\n",
      "at 6000 iteration loss is 1.183165369675279\n",
      "at 6000 iteration loss is 0.9422479383559164\n",
      "at 6000 iteration loss is 1.1099616460523074\n",
      "at 6000 iteration loss is 1.089116489511375\n",
      "at 6000 iteration loss is 1.1939783330623694\n",
      "at 6000 iteration loss is 0.9886681835701363\n",
      "at 6000 iteration loss is 1.112967546027024\n",
      "at 6000 iteration loss is 1.0831103799406292\n",
      "at 6000 iteration loss is 1.1099886385926978\n",
      "at 6000 iteration loss is 1.1058483081170813\n",
      "at 6000 iteration loss is 1.0507560744710367\n",
      "at 6100 iteration loss is 1.168451369998977\n",
      "at 6100 iteration loss is 1.074209593241551\n",
      "at 6100 iteration loss is 1.1011720701976853\n",
      "at 6100 iteration loss is 1.2494255406351926\n",
      "at 6100 iteration loss is 1.0716014393212259\n",
      "at 6100 iteration loss is 1.1358061192303204\n",
      "at 6100 iteration loss is 1.1028796358097102\n",
      "at 6100 iteration loss is 1.183165154138154\n",
      "at 6100 iteration loss is 0.9422477109019066\n",
      "at 6100 iteration loss is 1.1099615293110312\n",
      "at 6100 iteration loss is 1.08911638385457\n",
      "at 6100 iteration loss is 1.1939788405668819\n",
      "at 6100 iteration loss is 0.9886686001522872\n",
      "at 6100 iteration loss is 1.1129679153054357\n",
      "at 6100 iteration loss is 1.0831105483862835\n",
      "at 6100 iteration loss is 1.1099880742033907\n",
      "at 6100 iteration loss is 1.1058489307970425\n",
      "at 6100 iteration loss is 1.0507561748642327\n",
      "at 6200 iteration loss is 1.1684517463441964\n",
      "at 6200 iteration loss is 1.0742093690239822\n",
      "at 6200 iteration loss is 1.101171688352398\n",
      "at 6200 iteration loss is 1.2494251627117765\n",
      "at 6200 iteration loss is 1.071601494243272\n",
      "at 6200 iteration loss is 1.135805808929851\n",
      "at 6200 iteration loss is 1.1028796276780455\n",
      "at 6200 iteration loss is 1.1831649678771672\n",
      "at 6200 iteration loss is 0.9422475161130954\n",
      "at 6200 iteration loss is 1.1099614272030647\n",
      "at 6200 iteration loss is 1.0891162943886123\n",
      "at 6200 iteration loss is 1.1939792756275718\n",
      "at 6200 iteration loss is 0.9886689555121851\n",
      "at 6200 iteration loss is 1.1129682330610142\n",
      "at 6200 iteration loss is 1.083110692310668\n",
      "at 6200 iteration loss is 1.109987589248259\n",
      "at 6200 iteration loss is 1.1058494619417523\n",
      "at 6200 iteration loss is 1.0507562623758147\n",
      "at 6300 iteration loss is 1.1684520724892162\n",
      "at 6300 iteration loss is 1.0742091756012384\n",
      "at 6300 iteration loss is 1.1011713606373932\n",
      "at 6300 iteration loss is 1.2494248385234046\n",
      "at 6300 iteration loss is 1.0716015428946843\n",
      "at 6300 iteration loss is 1.1358055420826936\n",
      "at 6300 iteration loss is 1.1028796214608798\n",
      "at 6300 iteration loss is 1.1831648069433371\n",
      "at 6300 iteration loss is 0.9422473492958041\n",
      "at 6300 iteration loss is 1.1099613379531728\n",
      "at 6300 iteration loss is 1.0891162186308112\n",
      "at 6300 iteration loss is 1.1939796485862144\n",
      "at 6300 iteration loss is 0.9886692586611666\n",
      "at 6300 iteration loss is 1.1129685064649837\n",
      "at 6300 iteration loss is 1.0831108152879614\n",
      "at 6300 iteration loss is 1.1099871725621226\n",
      "at 6300 iteration loss is 1.1058499150278929\n",
      "at 6300 iteration loss is 1.0507563386207697\n",
      "at 6400 iteration loss is 1.1684523550561434\n",
      "at 6400 iteration loss is 1.0742090087643053\n",
      "at 6400 iteration loss is 1.101171079383366\n",
      "at 6400 iteration loss is 1.2494245604317655\n",
      "at 6400 iteration loss is 1.0716015859281809\n",
      "at 6400 iteration loss is 1.1358053126155188\n",
      "at 6400 iteration loss is 1.102879616768417\n",
      "at 6400 iteration loss is 1.1831646679158752\n",
      "at 6400 iteration loss is 0.9422472064311883\n",
      "at 6400 iteration loss is 1.1099612599911102\n",
      "at 6400 iteration loss is 1.0891161544794017\n",
      "at 6400 iteration loss is 1.193979968308115\n",
      "at 6400 iteration loss is 0.9886695172820985\n",
      "at 6400 iteration loss is 1.1129687416931962\n",
      "at 6400 iteration loss is 1.08311092037069\n",
      "at 6400 iteration loss is 1.109986814546876\n",
      "at 6400 iteration loss is 1.105850301544874\n",
      "at 6400 iteration loss is 1.0507564050181235\n",
      "at 6500 iteration loss is 1.1684525998057926\n",
      "at 6500 iteration loss is 1.0742088648761747\n",
      "at 6500 iteration loss is 1.1011708380069727\n",
      "at 6500 iteration loss is 1.2494243218840149\n",
      "at 6500 iteration loss is 1.0716016239407455\n",
      "at 6500 iteration loss is 1.1358051153020028\n",
      "at 6500 iteration loss is 1.102879613284517\n",
      "at 6500 iteration loss is 1.1831645478322714\n",
      "at 6500 iteration loss is 0.9422470840781543\n",
      "at 6500 iteration loss is 1.1099611919298324\n",
      "at 6500 iteration loss is 1.0891161001550613\n",
      "at 6500 iteration loss is 1.1939802423929247\n",
      "at 6500 iteration loss is 0.9886697379255389\n",
      "at 6500 iteration loss is 1.1129689440638566\n",
      "at 6500 iteration loss is 1.0831110101659696\n",
      "at 6500 iteration loss is 1.1099865069519006\n",
      "at 6500 iteration loss is 1.1058506312883412\n",
      "at 6500 iteration loss is 1.0507564628135733\n",
      "at 6600 iteration loss is 1.1684528117476565\n",
      "at 6600 iteration loss is 1.0742087407946355\n",
      "at 6600 iteration loss is 1.1011706308571565\n",
      "at 6600 iteration loss is 1.2494241172585576\n",
      "at 6600 iteration loss is 1.0716016574758025\n",
      "at 6600 iteration loss is 1.1358049456449957\n",
      "at 6600 iteration loss is 1.1028796107533931\n",
      "at 6600 iteration loss is 1.1831644441275084\n",
      "at 6600 iteration loss is 0.9422469792902461\n",
      "at 6600 iteration loss is 1.1099611325456649\n",
      "at 6600 iteration loss is 1.0891160541514187\n",
      "at 6600 iteration loss is 1.1939804773553413\n",
      "at 6600 iteration loss is 0.9886699261768761\n",
      "at 6600 iteration loss is 1.1129691181562493\n",
      "at 6600 iteration loss is 1.0831110869005816\n",
      "at 6600 iteration loss is 1.1099862426851934\n",
      "at 6600 iteration loss is 1.1058509126102563\n",
      "at 6600 iteration loss is 1.050756513099712\n",
      "at 6700 iteration loss is 1.1684529952361835\n",
      "at 6700 iteration loss is 1.0742086338054007\n",
      "at 6700 iteration loss is 1.101170453083208\n",
      "at 6700 iteration loss is 1.2494239417327515\n",
      "at 6700 iteration loss is 1.0716016870259666\n",
      "at 6700 iteration loss is 1.1358047997750296\n",
      "at 6700 iteration loss is 1.102879608968643\n",
      "at 6700 iteration loss is 1.1831643545812442\n",
      "at 6700 iteration loss is 0.9422468895445005\n",
      "at 6700 iteration loss is 1.1099610807603275\n",
      "at 6700 iteration loss is 1.089116015193156\n",
      "at 6700 iteration loss is 1.193980678780021\n",
      "at 6700 iteration loss is 0.9886700867987734\n",
      "at 6700 iteration loss is 1.1129692679130982\n",
      "at 6700 iteration loss is 1.0831111524765362\n",
      "at 6700 iteration loss is 1.1099860156509191\n",
      "at 6700 iteration loss is 1.1058511526320125\n",
      "at 6700 iteration loss is 1.0507565568340689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at 6800 iteration loss is 1.1684531540550023\n",
      "at 6800 iteration loss is 1.0742085415642055\n",
      "at 6800 iteration loss is 1.1011703005214846\n",
      "at 6800 iteration loss is 1.2494237911693857\n",
      "at 6800 iteration loss is 1.0716017130361688\n",
      "at 6800 iteration loss is 1.1358046743629153\n",
      "at 6800 iteration loss is 1.1028796077642058\n",
      "at 6800 iteration loss is 1.1831642772719195\n",
      "at 6800 iteration loss is 0.942246812680537\n",
      "at 6800 iteration loss is 1.1099610356247005\n",
      "at 6800 iteration loss is 1.0891159822005463\n",
      "at 6800 iteration loss is 1.1939808514543548\n",
      "at 6800 iteration loss is 0.9886702238525384\n",
      "at 6800 iteration loss is 1.1129693967287937\n",
      "at 6800 iteration loss is 1.0831112085184993\n",
      "at 6800 iteration loss is 1.1099858206096955\n",
      "at 6800 iteration loss is 1.1058513574260211\n",
      "at 6800 iteration loss is 1.0507565948551552\n",
      "at 6900 iteration loss is 1.1684532914905719\n",
      "at 6900 iteration loss is 1.0742084620466763\n",
      "at 6900 iteration loss is 1.1011701695981546\n",
      "at 6900 iteration loss is 1.2494236620192984\n",
      "at 6900 iteration loss is 1.0716017359069678\n",
      "at 6900 iteration loss is 1.135804566544485\n",
      "at 6900 iteration loss is 1.1028796070069304\n",
      "at 6900 iteration loss is 1.183164210536917\n",
      "at 6900 iteration loss is 0.9422467468484292\n",
      "at 6900 iteration loss is 1.109960996304211\n",
      "at 6900 iteration loss is 1.0891159542594422\n",
      "at 6900 iteration loss is 1.1939809994823036\n",
      "at 6900 iteration loss is 0.9886703408015753\n",
      "at 6900 iteration loss is 1.1129695075254267\n",
      "at 6900 iteration loss is 1.0831112564142902\n",
      "at 6900 iteration loss is 1.1099856530584549\n",
      "at 6900 iteration loss is 1.1058515321704774\n",
      "at 6900 iteration loss is 1.0507566278967313\n",
      "at 7000 iteration loss is 1.1684534103965134\n",
      "at 7000 iteration loss is 1.0742083935049371\n",
      "at 7000 iteration loss is 1.101170057245697\n",
      "at 7000 iteration loss is 1.2494235512378093\n",
      "at 7000 iteration loss is 1.0716017559979225\n",
      "at 7000 iteration loss is 1.1358044738557773\n",
      "at 7000 iteration loss is 1.1028796065904474\n",
      "at 7000 iteration loss is 1.1831641529379626\n",
      "at 7000 iteration loss is 0.942246690464053\n",
      "at 7000 iteration loss is 1.1099609620657156\n",
      "at 7000 iteration loss is 1.0891159305958666\n",
      "at 7000 iteration loss is 1.1939811263819642\n",
      "at 7000 iteration loss is 0.9886704405995438\n",
      "at 7000 iteration loss is 1.112969602818329\n",
      "at 7000 iteration loss is 1.0831112973494523\n",
      "at 7000 iteration loss is 1.1099855091271094\n",
      "at 7000 iteration loss is 1.1058516812812431\n",
      "at 7000 iteration loss is 1.0507566566004451\n",
      "at 7100 iteration loss is 1.1684535132497909\n",
      "at 7100 iteration loss is 1.0742083344300715\n",
      "at 7100 iteration loss is 1.1011699608312104\n",
      "at 7100 iteration loss is 1.2494234562130389\n",
      "at 7100 iteration loss is 1.071601773630951\n",
      "at 7100 iteration loss is 1.1358043941772435\n",
      "at 7100 iteration loss is 1.1028796064301434\n",
      "at 7100 iteration loss is 1.1831641032311062\n",
      "at 7100 iteration loss is 0.9422466421708787\n",
      "at 7100 iteration loss is 1.1099609322657493\n",
      "at 7100 iteration loss is 1.0891159105545052\n",
      "at 7100 iteration loss is 1.1939812351692112\n",
      "at 7100 iteration loss is 0.9886705257654992\n",
      "at 7100 iteration loss is 1.1129696847725292\n",
      "at 7100 iteration loss is 1.0831113323367767\n",
      "at 7100 iteration loss is 1.1099853854897117\n",
      "at 7100 iteration loss is 1.1058518085242564\n",
      "at 7100 iteration loss is 1.0507566815270333\n",
      "at 7200 iteration loss is 1.1684536021997443\n",
      "at 7200 iteration loss is 1.0742082835196332\n",
      "at 7200 iteration loss is 1.1011698780948818\n",
      "at 7200 iteration loss is 1.2494233747044001\n",
      "at 7200 iteration loss is 1.071601789093586\n",
      "at 7200 iteration loss is 1.135804325685711\n",
      "at 7200 iteration loss is 1.1028796064590487\n",
      "at 7200 iteration loss is 1.1831640603406859\n",
      "at 7200 iteration loss is 0.9422466008072554\n",
      "at 7200 iteration loss is 1.109960906340047\n",
      "at 7200 iteration loss is 1.0891158935805059\n",
      "at 7200 iteration loss is 1.193981328429406\n",
      "at 7200 iteration loss is 0.9886705984479486\n",
      "at 7200 iteration loss is 1.1129697552514195\n",
      "at 7200 iteration loss is 1.0831113622415085\n",
      "at 7200 iteration loss is 1.1099852792880565\n",
      "at 7200 iteration loss is 1.1058519171113377\n",
      "at 7200 iteration loss is 1.0507567031662206\n",
      "at 7300 iteration loss is 1.1684536791108413\n",
      "at 7300 iteration loss is 1.0742082396495505\n",
      "at 7300 iteration loss is 1.1011698070971343\n",
      "at 7300 iteration loss is 1.249423304789833\n",
      "at 7300 iteration loss is 1.0716018026420997\n",
      "at 7300 iteration loss is 1.135804266813024\n",
      "at 7300 iteration loss is 1.1028796066244466\n",
      "at 7300 iteration loss is 1.1831640233367242\n",
      "at 7300 iteration loss is 0.9422465653783945\n",
      "at 7300 iteration loss is 1.1099608837941815\n",
      "at 7300 iteration loss is 1.089115879204066\n",
      "at 7300 iteration loss is 1.1939814083788423\n",
      "at 7300 iteration loss is 0.9886706604794323\n",
      "at 7300 iteration loss is 1.1129698158586594\n",
      "at 7300 iteration loss is 1.0831113878028638\n",
      "at 7300 iteration loss is 1.1099851880659863\n",
      "at 7300 iteration loss is 1.1058520097818467\n",
      "at 7300 iteration loss is 1.0507567219454614\n",
      "at 7400 iteration loss is 1.16845374559996\n",
      "at 7400 iteration loss is 1.0742082018498293\n",
      "at 7400 iteration loss is 1.101169746173287\n",
      "at 7400 iteration loss is 1.2494232448205362\n",
      "at 7400 iteration loss is 1.0716018145044508\n",
      "at 7400 iteration loss is 1.1358042162104527\n",
      "at 7400 iteration loss is 1.102879606885121\n",
      "at 7400 iteration loss is 1.183163991415358\n",
      "at 7400 iteration loss is 0.9422465350323874\n",
      "at 7400 iteration loss is 1.1099608641952543\n",
      "at 7400 iteration loss is 1.0891158670273848\n",
      "at 7400 iteration loss is 1.193981476917448\n",
      "at 7400 iteration loss is 0.9886707134230717\n",
      "at 7400 iteration loss is 1.1129698679742939\n",
      "at 7400 iteration loss is 1.0831114096524146\n",
      "at 7400 iteration loss is 1.1099851097129247\n",
      "at 7400 iteration loss is 1.1058520888722942\n",
      "at 7400 iteration loss is 1.05075673823765\n",
      "at 7500 iteration loss is 1.168453803068862\n",
      "at 7500 iteration loss is 1.0742081692835426\n",
      "at 7500 iteration loss is 1.1011696938946114\n",
      "at 7500 iteration loss is 1.2494231933821258\n",
      "at 7500 iteration loss is 1.0716018248830548\n",
      "at 7500 iteration loss is 1.1358041727180481\n",
      "at 7500 iteration loss is 1.102879607209099\n",
      "at 7500 iteration loss is 1.1831639638818543\n",
      "at 7500 iteration loss is 0.9422465090396809\n",
      "at 7500 iteration loss is 1.1099608471645088\n",
      "at 7500 iteration loss is 1.089115856713628\n",
      "at 7500 iteration loss is 1.1939815356739434\n",
      "at 7500 iteration loss is 0.9886707586122385\n",
      "at 7500 iteration loss is 1.112969912785855\n",
      "at 7500 iteration loss is 1.0831114283297871\n",
      "at 7500 iteration loss is 1.109985042415313\n",
      "at 7500 iteration loss is 1.1058521563756714\n",
      "at 7500 iteration loss is 1.0507567523679084\n",
      "at 7600 iteration loss is 1.1684538527324801\n",
      "at 7600 iteration loss is 1.074208141228666\n",
      "at 7600 iteration loss is 1.1011696490349023\n",
      "at 7600 iteration loss is 1.2494231492613177\n",
      "at 7600 iteration loss is 1.0716018339573434\n",
      "at 7600 iteration loss is 1.1358041353382704\n",
      "at 7600 iteration loss is 1.10287960757181\n",
      "at 7600 iteration loss is 1.1831639401358982\n",
      "at 7600 iteration loss is 0.9422464867754808\n",
      "at 7600 iteration loss is 1.1099608323707801\n",
      "at 7600 iteration loss is 1.0891158479775718\n",
      "at 7600 iteration loss is 1.1939815860445553\n",
      "at 7600 iteration loss is 0.9886707971843732\n",
      "at 7600 iteration loss is 1.112969951315148\n",
      "at 7600 iteration loss is 1.0831114442960588\n",
      "at 7600 iteration loss is 1.1099849846148657\n",
      "at 7600 iteration loss is 1.1058522139920401\n",
      "at 7600 iteration loss is 1.0507567646195677\n",
      "at 7700 iteration loss is 1.1684538956435353\n",
      "at 7700 iteration loss is 1.0742081170623825\n",
      "at 7700 iteration loss is 1.1011696105417919\n",
      "at 7700 iteration loss is 1.2494231114173409\n",
      "at 7700 iteration loss is 1.0716018418861335\n",
      "at 7700 iteration loss is 1.1358041032132973\n",
      "at 7700 iteration loss is 1.1028796079545926\n",
      "at 7700 iteration loss is 1.1831639196588508\n",
      "at 7700 iteration loss is 0.9422464677047155\n",
      "at 7700 iteration loss is 1.1099608195247068\n",
      "at 7700 iteration loss is 1.0891158405776922\n",
      "at 7700 iteration loss is 1.1939816292262129\n",
      "at 7700 iteration loss is 0.9886708301098249\n",
      "at 7700 iteration loss is 1.1129699844413279\n",
      "at 7700 iteration loss is 1.0831114579452057\n",
      "at 7700 iteration loss is 1.1099849349726905\n",
      "at 7700 iteration loss is 1.1058522631716483\n",
      "at 7700 iteration loss is 1.0507567752394151\n",
      "at 7800 iteration loss is 1.1684539327139665\n",
      "at 7800 iteration loss is 1.074208096247515\n",
      "at 7800 iteration loss is 1.101169577512114\n",
      "at 7800 iteration loss is 1.249423078957422\n",
      "at 7800 iteration loss is 1.0716018488098027\n",
      "at 7800 iteration loss is 1.1358040756054901\n",
      "at 7800 iteration loss is 1.102879608343478\n",
      "at 7800 iteration loss is 1.183163902002713\n",
      "at 7800 iteration loss is 0.9422464513691331\n",
      "at 7800 iteration loss is 1.1099608083736068\n",
      "at 7800 iteration loss is 1.0891158343094667\n",
      "at 7800 iteration loss is 1.1939816662449942\n",
      "at 7800 iteration loss is 0.9886708582164323\n",
      "at 7800 iteration loss is 1.112970012920767\n",
      "at 7800 iteration loss is 1.0831114696138882\n",
      "at 7800 iteration loss is 1.1099848923384361\n",
      "at 7800 iteration loss is 1.1058523051516995\n",
      "at 7800 iteration loss is 1.0507567844423147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at 7900 iteration loss is 1.168453964733554\n",
      "at 7900 iteration loss is 1.074208078320806\n",
      "at 7900 iteration loss is 1.1011695491707658\n",
      "at 7900 iteration loss is 1.24942305111573\n",
      "at 7900 iteration loss is 1.0716018548522603\n",
      "at 7900 iteration loss is 1.135804051880584\n",
      "at 7900 iteration loss is 1.1028796087282084\n",
      "at 7900 iteration loss is 1.1831638867805594\n",
      "at 7900 iteration loss is 0.9422464373762736\n",
      "at 7900 iteration loss is 1.1099607986969504\n",
      "at 7900 iteration loss is 1.0891158289997\n",
      "at 7900 iteration loss is 1.1939816979805158\n",
      "at 7900 iteration loss is 0.9886708822104863\n",
      "at 7900 iteration loss is 1.1129700374041627\n",
      "at 7900 iteration loss is 1.0831114795897896\n",
      "at 7900 iteration loss is 1.1099848557237741\n",
      "at 7900 iteration loss is 1.105852340987695\n",
      "at 7900 iteration loss is 1.0507567924152448\n",
      "at 8000 iteration loss is 1.1684539923861244\n",
      "at 8000 iteration loss is 1.0742080628827901\n",
      "at 8000 iteration loss is 1.1011695248525553\n",
      "at 8000 iteration loss is 1.2494230272353497\n",
      "at 8000 iteration loss is 1.0716018601227553\n",
      "at 8000 iteration loss is 1.1358040314932345\n",
      "at 8000 iteration loss is 1.1028796091014406\n",
      "at 8000 iteration loss is 1.1831638736582684\n",
      "at 8000 iteration loss is 0.9422464253900162\n",
      "at 8000 iteration loss is 1.1099607903023836\n",
      "at 8000 iteration loss is 1.0891158245017227\n",
      "at 8000 iteration loss is 1.19398172518684\n",
      "at 8000 iteration loss is 0.988670902694604\n",
      "at 8000 iteration loss is 1.1129700584512705\n",
      "at 8000 iteration loss is 1.0831114881187587\n",
      "at 8000 iteration loss is 1.109984824279611\n",
      "at 8000 iteration loss is 1.1058523715801614\n",
      "at 8000 iteration loss is 1.0507567993208575\n",
      "at 8100 iteration loss is 1.168454016263627\n",
      "at 8100 iteration loss is 1.074208049589049\n",
      "at 8100 iteration loss is 1.1011695039866272\n",
      "at 8100 iteration loss is 1.249423006752782\n",
      "at 8100 iteration loss is 1.071601864717492\n",
      "at 8100 iteration loss is 1.135804013974566\n",
      "at 8100 iteration loss is 1.1028796094581046\n",
      "at 8100 iteration loss is 1.183163862347357\n",
      "at 8100 iteration loss is 0.9422464151224853\n",
      "at 8100 iteration loss is 1.1099607830222102\n",
      "at 8100 iteration loss is 1.0891158206913254\n",
      "at 8100 iteration loss is 1.1939817485103963\n",
      "at 8100 iteration loss is 0.9886709201829674\n",
      "at 8100 iteration loss is 1.112970076543583\n",
      "at 8100 iteration loss is 1.0831114954108945\n",
      "at 8100 iteration loss is 1.1099847972764922\n",
      "at 8100 iteration loss is 1.1058523976974413\n",
      "at 8100 iteration loss is 1.0507568053005791\n",
      "at 8200 iteration loss is 1.1684540368783634\n",
      "at 8200 iteration loss is 1.0742080381426595\n",
      "at 8200 iteration loss is 1.1011694860830872\n",
      "at 8200 iteration loss is 1.2494229891846689\n",
      "at 8200 iteration loss is 1.0716018687211046\n",
      "at 8200 iteration loss is 1.135803998921474\n",
      "at 8200 iteration loss is 1.1028796097948947\n",
      "at 8200 iteration loss is 1.1831638525987869\n",
      "at 8200 iteration loss is 0.9422464063271271\n",
      "at 8200 iteration loss is 1.1099607767103101\n",
      "at 8200 iteration loss is 1.089115817463319\n",
      "at 8200 iteration loss is 1.193981768505349\n",
      "at 8200 iteration loss is 0.988670935114326\n",
      "at 8200 iteration loss is 1.1129700920952537\n",
      "at 8200 iteration loss is 1.0831115016457562\n",
      "at 8200 iteration loss is 1.109984774087766\n",
      "at 8200 iteration loss is 1.1058524199951214\n",
      "at 8200 iteration loss is 1.050756810477337\n",
      "at 8300 iteration loss is 1.1684540546736044\n",
      "at 8300 iteration loss is 1.0742080282876683\n",
      "at 8300 iteration loss is 1.1011694707215298\n",
      "at 8300 iteration loss is 1.249422974116398\n",
      "at 8300 iteration loss is 1.0716018722079732\n",
      "at 8300 iteration loss is 1.1358039859874127\n",
      "at 8300 iteration loss is 1.1028796101098506\n",
      "at 8300 iteration loss is 1.1831638441975953\n",
      "at 8300 iteration loss is 0.9422463987927703\n",
      "at 8300 iteration loss is 1.1099607712394177\n",
      "at 8300 iteration loss is 1.0891158147286188\n",
      "at 8300 iteration loss is 1.1939817856467634\n",
      "at 8300 iteration loss is 0.9886709478630756\n",
      "at 8300 iteration loss is 1.1129701054624905\n",
      "at 8300 iteration loss is 1.0831115069768007\n",
      "at 8300 iteration loss is 1.109984754175115\n",
      "at 8300 iteration loss is 1.1058524390326099\n",
      "at 8300 iteration loss is 1.050756814957938\n",
      "at 8400 iteration loss is 1.168454070032818\n",
      "at 8400 iteration loss is 1.0742080198034654\n",
      "at 8400 iteration loss is 1.1011694575411826\n",
      "at 8400 iteration loss is 1.249422961192326\n",
      "at 8400 iteration loss is 1.071601875243406\n",
      "at 8400 iteration loss is 1.1358039748744713\n",
      "at 8400 iteration loss is 1.102879610402034\n",
      "at 8400 iteration loss is 1.1831638369582649\n",
      "at 8400 iteration loss is 0.9422463923385489\n",
      "at 8400 iteration loss is 1.1099607664987428\n",
      "at 8400 iteration loss is 1.089115812411775\n",
      "at 8400 iteration loss is 1.1939818003418974\n",
      "at 8400 iteration loss is 0.9886709587487121\n",
      "at 8400 iteration loss is 1.1129701169516477\n",
      "at 8400 iteration loss is 1.08311151153519\n",
      "at 8400 iteration loss is 1.1099847370761156\n",
      "at 8400 iteration loss is 1.105852455287263\n",
      "at 8400 iteration loss is 1.0507568188351473\n",
      "at 8500 iteration loss is 1.1684540832876642\n",
      "at 8500 iteration loss is 1.0742080124999203\n",
      "at 8500 iteration loss is 1.101169446232455\n",
      "at 8500 iteration loss is 1.2494229501073957\n",
      "at 8500 iteration loss is 1.071601877884691\n",
      "at 8500 iteration loss is 1.135803965326561\n",
      "at 8500 iteration loss is 1.1028796106712673\n",
      "at 8500 iteration loss is 1.1831638307207077\n",
      "at 8500 iteration loss is 0.9422463868095505\n",
      "at 8500 iteration loss is 1.1099607623918835\n",
      "at 8500 iteration loss is 1.0891158104488885\n",
      "at 8500 iteration loss is 1.1939818129398847\n",
      "at 8500 iteration loss is 0.9886709680438963\n",
      "at 8500 iteration loss is 1.1129701268261933\n",
      "at 8500 iteration loss is 1.0831115154330302\n",
      "at 8500 iteration loss is 1.10998472239355\n",
      "at 8500 iteration loss is 1.1058524691664415\n",
      "at 8500 iteration loss is 1.0507568221895098\n",
      "at 8600 iteration loss is 1.1684540947249407\n",
      "at 8600 iteration loss is 1.0742080062131893\n",
      "at 8600 iteration loss is 1.101169436529679\n",
      "at 8600 iteration loss is 1.24942294059994\n",
      "at 8600 iteration loss is 1.0716018801820473\n",
      "at 8600 iteration loss is 1.1358039571235559\n",
      "at 8600 iteration loss is 1.1028796109179282\n",
      "at 8600 iteration loss is 1.1831638253467998\n",
      "at 8600 iteration loss is 0.9422463820730883\n",
      "at 8600 iteration loss is 1.109960758834986\n",
      "at 8600 iteration loss is 1.0891158087858386\n",
      "at 8600 iteration loss is 1.1939818237400248\n",
      "at 8600 iteration loss is 0.9886709759813261\n",
      "at 8600 iteration loss is 1.112970135312694\n",
      "at 8600 iteration loss is 1.0831115187661413\n",
      "at 8600 iteration loss is 1.1099847097862245\n",
      "at 8600 iteration loss is 1.1058524810177892\n",
      "at 8600 iteration loss is 1.0507568250909354\n",
      "at 8700 iteration loss is 1.1684541045926038\n",
      "at 8700 iteration loss is 1.0742080008020918\n",
      "at 8700 iteration loss is 1.1011694282048807\n",
      "at 8700 iteration loss is 1.2494229324455155\n",
      "at 8700 iteration loss is 1.0716018821794573\n",
      "at 8700 iteration loss is 1.1358039500762456\n",
      "at 8700 iteration loss is 1.1028796111427879\n",
      "at 8700 iteration loss is 1.1831638207173811\n",
      "at 8700 iteration loss is 0.9422463780155136\n",
      "at 8700 iteration loss is 1.109960755755146\n",
      "at 8700 iteration loss is 1.0891158073767868\n",
      "at 8700 iteration loss is 1.1939818329989005\n",
      "at 8700 iteration loss is 0.988670982759607\n",
      "at 8700 iteration loss is 1.1129701426059797\n",
      "at 8700 iteration loss is 1.0831115216164293\n",
      "at 8700 iteration loss is 1.109984698961074\n",
      "at 8700 iteration loss is 1.1058524911379988\n",
      "at 8700 iteration loss is 1.0507568276000843\n",
      "at 8800 iteration loss is 1.1684541131049877\n",
      "at 8800 iteration loss is 1.0742079961449897\n",
      "at 8800 iteration loss is 1.101169421062435\n",
      "at 8800 iteration loss is 1.2494229254516045\n",
      "at 8800 iteration loss is 1.0716018839154136\n",
      "at 8800 iteration loss is 1.1358039440220045\n",
      "at 8800 iteration loss is 1.1028796113468864\n",
      "at 8800 iteration loss is 1.183163816729665\n",
      "at 8800 iteration loss is 0.9422463745394818\n",
      "at 8800 iteration loss is 1.1099607530890006\n",
      "at 8800 iteration loss is 1.0891158061829063\n",
      "at 8800 iteration loss is 1.1939818409364733\n",
      "at 8800 iteration loss is 0.9886709885482491\n",
      "at 8800 iteration loss is 1.1129701488735757\n",
      "at 8800 iteration loss is 1.0831115240539062\n",
      "at 8800 iteration loss is 1.109984689666381\n",
      "at 8800 iteration loss is 1.10585249978029\n",
      "at 8800 iteration loss is 1.0507568297695724\n",
      "at 8900 iteration loss is 1.1684541204473347\n",
      "at 8900 iteration loss is 1.074207992137093\n",
      "at 8900 iteration loss is 1.101169414934476\n",
      "at 8900 iteration loss is 1.2494229194530762\n",
      "at 8900 iteration loss is 1.0716018854235851\n",
      "at 8900 iteration loss is 1.13580393882106\n",
      "at 8900 iteration loss is 1.1028796115314363\n",
      "at 8900 iteration loss is 1.1831638132950015\n",
      "at 8900 iteration loss is 0.9422463715616131\n",
      "at 8900 iteration loss is 1.109960750781502\n",
      "at 8900 iteration loss is 1.0891158051713112\n",
      "at 8900 iteration loss is 1.193981847741313\n",
      "at 8900 iteration loss is 0.9886709934919418\n",
      "at 8900 iteration loss is 1.112970154259529\n",
      "at 8900 iteration loss is 1.083111526138425\n",
      "at 8900 iteration loss is 1.1099846816859478\n",
      "at 8900 iteration loss is 1.1058525071607925\n",
      "at 8900 iteration loss is 1.0507568316450286\n",
      "at 9000 iteration loss is 1.168454126779708\n",
      "at 9000 iteration loss is 1.0742079886881293\n",
      "at 9000 iteration loss is 1.1011694096769642\n",
      "at 9000 iteration loss is 1.2494229143082924\n",
      "at 9000 iteration loss is 1.0716018867333927\n",
      "at 9000 iteration loss is 1.1358039343532857\n",
      "at 9000 iteration loss is 1.1028796116977464\n",
      "at 9000 iteration loss is 1.183163810336938\n",
      "at 9000 iteration loss is 0.9422463690104854\n",
      "at 9000 iteration loss is 1.1099607487848393\n",
      "at 9000 iteration loss is 1.089115804314146\n",
      "at 9000 iteration loss is 1.1939818535750732\n",
      "at 9000 iteration loss is 0.9886709977141864\n",
      "at 9000 iteration loss is 1.1129701588876846\n",
      "at 9000 iteration loss is 1.0831115279211454\n",
      "at 9000 iteration loss is 1.1099846748340905\n",
      "at 9000 iteration loss is 1.1058525134639816\n",
      "at 9000 iteration loss is 1.0507568332660087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at 9100 iteration loss is 1.1684541322403974\n",
      "at 9100 iteration loss is 1.0742079857203426\n",
      "at 9100 iteration loss is 1.1011694051663\n",
      "at 9100 iteration loss is 1.2494229098957634\n",
      "at 9100 iteration loss is 1.0716018878705427\n",
      "at 9100 iteration loss is 1.1358039305154448\n",
      "at 9100 iteration loss is 1.1028796118471678\n",
      "at 9100 iteration loss is 1.1831638077895505\n",
      "at 9100 iteration loss is 0.9422463668249217\n",
      "at 9100 iteration loss is 1.1099607470575052\n",
      "at 9100 iteration loss is 1.0891158035878152\n",
      "at 9100 iteration loss is 1.1939818585763387\n",
      "at 9100 iteration loss is 0.9886710013204093\n",
      "at 9100 iteration loss is 1.112970162864519\n",
      "at 9100 iteration loss is 1.083111529445809\n",
      "at 9100 iteration loss is 1.1099846689513342\n",
      "at 9100 iteration loss is 1.105852518847327\n",
      "at 9100 iteration loss is 1.0507568346667957\n",
      "at 9200 iteration loss is 1.1684541369488606\n",
      "at 9200 iteration loss is 1.0742079831667672\n",
      "at 9200 iteration loss is 1.101169401296429\n",
      "at 9200 iteration loss is 1.2494229061112894\n",
      "at 9200 iteration loss is 1.0716018888574705\n",
      "at 9200 iteration loss is 1.1358039272188207\n",
      "at 9200 iteration loss is 1.1028796119810536\n",
      "at 9200 iteration loss is 1.1831638055960032\n",
      "at 9200 iteration loss is 0.9422463649525193\n",
      "at 9200 iteration loss is 1.1099607455634763\n",
      "at 9200 iteration loss is 1.0891158029723311\n",
      "at 9200 iteration loss is 1.193981862863915\n",
      "at 9200 iteration loss is 0.9886710044006106\n",
      "at 9200 iteration loss is 1.1129701662815703\n",
      "at 9200 iteration loss is 1.0831115307498063\n",
      "at 9200 iteration loss is 1.1099846639007216\n",
      "at 9200 iteration loss is 1.1058525234452454\n",
      "at 9200 iteration loss is 1.0507568358770936\n",
      "at 9300 iteration loss is 1.168454141008268\n",
      "at 9300 iteration loss is 1.0742079809697267\n",
      "at 9300 iteration loss is 1.1011693979763497\n",
      "at 9300 iteration loss is 1.2494229028654886\n",
      "at 9300 iteration loss is 1.0716018897137485\n",
      "at 9300 iteration loss is 1.1358039243871727\n",
      "at 9300 iteration loss is 1.1028796121007263\n",
      "at 9300 iteration loss is 1.1831638037072936\n",
      "at 9300 iteration loss is 0.9422463633483898\n",
      "at 9300 iteration loss is 1.1099607442714958\n",
      "at 9300 iteration loss is 1.0891158024507614\n",
      "at 9300 iteration loss is 1.1939818665396504\n",
      "at 9300 iteration loss is 0.9886710070316204\n",
      "at 9300 iteration loss is 1.1129701692175336\n",
      "at 9300 iteration loss is 1.0831115318651083\n",
      "at 9300 iteration loss is 1.1099846595646314\n",
      "at 9300 iteration loss is 1.1058525273724857\n",
      "at 9300 iteration loss is 1.0507568369226317\n",
      "at 9400 iteration loss is 1.1684541445077166\n",
      "at 9400 iteration loss is 1.074207979079557\n",
      "at 9400 iteration loss is 1.101169395127982\n",
      "at 9400 iteration loss is 1.2494229000817048\n",
      "at 9400 iteration loss is 1.071601890456451\n",
      "at 9400 iteration loss is 1.1358039219549894\n",
      "at 9400 iteration loss is 1.1028796122074573\n",
      "at 9400 iteration loss is 1.1831638020811863\n",
      "at 9400 iteration loss is 0.9422463619740817\n",
      "at 9400 iteration loss is 1.1099607431544551\n",
      "at 9400 iteration loss is 1.0891158020087655\n",
      "at 9400 iteration loss is 1.193981869690862\n",
      "at 9400 iteration loss is 0.9886710092790331\n",
      "at 9400 iteration loss is 1.1129701717400526\n",
      "at 9400 iteration loss is 1.0831115328190457\n",
      "at 9400 iteration loss is 1.1099846558420559\n",
      "at 9400 iteration loss is 1.1058525307270082\n",
      "at 9400 iteration loss is 1.0507568378256944\n",
      "at 9500 iteration loss is 1.1684541475241261\n",
      "at 9500 iteration loss is 1.074207977453492\n",
      "at 9500 iteration loss is 1.1011693926843265\n",
      "at 9500 iteration loss is 1.249422897694179\n",
      "at 9500 iteration loss is 1.071601891100452\n",
      "at 9500 iteration loss is 1.1358039198659753\n",
      "at 9500 iteration loss is 1.1028796123024533\n",
      "at 9500 iteration loss is 1.1831638006812735\n",
      "at 9500 iteration loss is 0.9422463607966562\n",
      "at 9500 iteration loss is 1.1099607421888433\n",
      "at 9500 iteration loss is 1.0891158016341893\n",
      "at 9500 iteration loss is 1.1939818723923987\n",
      "at 9500 iteration loss is 0.9886710111988499\n",
      "at 9500 iteration loss is 1.1129701739072766\n",
      "at 9500 iteration loss is 1.0831115336349904\n",
      "at 9500 iteration loss is 1.1099846526462518\n",
      "at 9500 iteration loss is 1.1058525335924443\n",
      "at 9500 iteration loss is 1.0507568386055737\n",
      "at 9600 iteration loss is 1.1684541501239072\n",
      "at 9600 iteration loss is 1.0742079760547134\n",
      "at 9600 iteration loss is 1.1011693905878992\n",
      "at 9600 iteration loss is 1.2494228956465179\n",
      "at 9600 iteration loss is 1.0716018916587111\n",
      "at 9600 iteration loss is 1.1358039180717634\n",
      "at 9600 iteration loss is 1.1028796123868512\n",
      "at 9600 iteration loss is 1.1831637994761803\n",
      "at 9600 iteration loss is 0.9422463597879001\n",
      "at 9600 iteration loss is 1.1099607413542851\n",
      "at 9600 iteration loss is 1.0891158013167417\n",
      "at 9600 iteration loss is 1.1939818747084345\n",
      "at 9600 iteration loss is 0.9886710128388861\n",
      "at 9600 iteration loss is 1.1129701757691868\n",
      "at 9600 iteration loss is 1.0831115343329203\n",
      "at 9600 iteration loss is 1.1099846499027328\n",
      "at 9600 iteration loss is 1.1058525360401974\n",
      "at 9600 iteration loss is 1.0507568392789723\n",
      "at 9700 iteration loss is 1.1684541523643799\n",
      "at 9700 iteration loss is 1.074207974851519\n",
      "at 9700 iteration loss is 1.1011693887893783\n",
      "at 9700 iteration loss is 1.2494228938903513\n",
      "at 9700 iteration loss is 1.0716018921425132\n",
      "at 9700 iteration loss is 1.1358039165307938\n",
      "at 9700 iteration loss is 1.1028796124617046\n",
      "at 9700 iteration loss is 1.183163798438871\n",
      "at 9700 iteration loss is 0.9422463589236403\n",
      "at 9700 iteration loss is 1.1099607406331216\n",
      "at 9700 iteration loss is 1.0891158010477011\n",
      "at 9700 iteration loss is 1.1939818766939816\n",
      "at 9700 iteration loss is 0.9886710142399698\n",
      "at 9700 iteration loss is 1.112970177368743\n",
      "at 9700 iteration loss is 1.0831115349299236\n",
      "at 9700 iteration loss is 1.1099846475475352\n",
      "at 9700 iteration loss is 1.1058525381312327\n",
      "at 9700 iteration loss is 1.0507568398603406\n",
      "at 9800 iteration loss is 1.168454154295013\n",
      "at 9800 iteration loss is 1.0742079738166195\n",
      "at 9800 iteration loss is 1.101169387246443\n",
      "at 9800 iteration loss is 1.249422892384188\n",
      "at 9800 iteration loss is 1.0716018925616795\n",
      "at 9800 iteration loss is 1.1358039152073565\n",
      "at 9800 iteration loss is 1.1028796125279885\n",
      "at 9800 iteration loss is 1.1831637975460476\n",
      "at 9800 iteration loss is 0.9422463581831717\n",
      "at 9800 iteration loss is 1.1099607400100473\n",
      "at 9800 iteration loss is 1.0891158008196784\n",
      "at 9800 iteration loss is 1.1939818783961997\n",
      "at 9800 iteration loss is 0.98867101543696\n",
      "at 9800 iteration loss is 1.1129701787428683\n",
      "at 9800 iteration loss is 1.0831115354406078\n",
      "at 9800 iteration loss is 1.1099846455257338\n",
      "at 9800 iteration loss is 1.105852539917603\n",
      "at 9800 iteration loss is 1.0507568403621834\n",
      "at 9900 iteration loss is 1.1684541559584973\n",
      "at 9900 iteration loss is 1.0742079729265246\n",
      "at 9900 iteration loss is 1.1011693859227845\n",
      "at 9900 iteration loss is 1.2494228910924439\n",
      "at 9900 iteration loss is 1.0716018929247515\n",
      "at 9900 iteration loss is 1.1358039140707752\n",
      "at 9900 iteration loss is 1.1028796125866012\n",
      "at 9900 iteration loss is 1.1831637967776376\n",
      "at 9900 iteration loss is 0.9422463575487587\n",
      "at 9900 iteration loss is 1.1099607394718123\n",
      "at 9900 iteration loss is 1.089115800626415\n",
      "at 9900 iteration loss is 1.1939818798555224\n",
      "at 9900 iteration loss is 0.9886710164596266\n",
      "at 9900 iteration loss is 1.112970179923297\n",
      "at 9900 iteration loss is 1.0831115358774661\n",
      "at 9900 iteration loss is 1.109984643790167\n",
      "at 9900 iteration loss is 1.1058525414437557\n",
      "at 9900 iteration loss is 1.0507568407953198\n",
      "at 0 iteration loss is 1.433394548293594\n",
      "at 0 iteration loss is 1.6109133054423694\n",
      "at 0 iteration loss is 2.393032000835891\n",
      "at 0 iteration loss is 1.7812548488974183\n",
      "at 0 iteration loss is 1.3577400797980088\n",
      "at 0 iteration loss is 1.2903539727665643\n",
      "at 0 iteration loss is 1.390457765389246\n",
      "at 0 iteration loss is 1.4476140184043722\n",
      "at 0 iteration loss is 1.3796579291503224\n",
      "at 0 iteration loss is 1.262375993405002\n",
      "at 0 iteration loss is 1.3530334608830843\n",
      "at 0 iteration loss is 1.448162627504338\n",
      "at 0 iteration loss is 1.3323306881051882\n",
      "at 0 iteration loss is 1.2929279573189136\n",
      "at 0 iteration loss is 1.4121734606708984\n",
      "at 0 iteration loss is 1.3250098640927348\n",
      "at 0 iteration loss is 1.2327986212612938\n",
      "at 0 iteration loss is 0.933928180336218\n",
      "at 100 iteration loss is 1.2363412508555522\n",
      "at 100 iteration loss is 1.1642493963258966\n",
      "at 100 iteration loss is 1.0854144558690555\n",
      "at 100 iteration loss is 1.2459111019806817\n",
      "at 100 iteration loss is 1.0673911512022296\n",
      "at 100 iteration loss is 1.249518886980661\n",
      "at 100 iteration loss is 1.206438610891471\n",
      "at 100 iteration loss is 1.165997694590006\n",
      "at 100 iteration loss is 1.0463564159839929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at 100 iteration loss is 1.1353561274982027\n",
      "at 100 iteration loss is 1.1475838070467352\n",
      "at 100 iteration loss is 1.159919214636983\n",
      "at 100 iteration loss is 1.2030764903044342\n",
      "at 100 iteration loss is 1.049551926990519\n",
      "at 100 iteration loss is 1.44778819326454\n",
      "at 100 iteration loss is 1.1685166999181023\n",
      "at 100 iteration loss is 1.0950335169622123\n",
      "at 100 iteration loss is 0.9913706966798099\n",
      "at 200 iteration loss is 1.2025168615026633\n",
      "at 200 iteration loss is 1.1791648093833735\n",
      "at 200 iteration loss is 1.0979352553712327\n",
      "at 200 iteration loss is 1.2652046141723425\n",
      "at 200 iteration loss is 1.0558341476179494\n",
      "at 200 iteration loss is 1.2637428459174247\n",
      "at 200 iteration loss is 1.202960209557528\n",
      "at 200 iteration loss is 1.1769996675589423\n",
      "at 200 iteration loss is 1.0480536524932256\n",
      "at 200 iteration loss is 1.1577752698454176\n",
      "at 200 iteration loss is 1.1402356905387996\n",
      "at 200 iteration loss is 1.1715209541947043\n",
      "at 200 iteration loss is 1.2240844587772455\n",
      "at 200 iteration loss is 1.05314010692245\n",
      "at 200 iteration loss is 1.4237782016051903\n",
      "at 200 iteration loss is 1.2268085342985662\n",
      "at 200 iteration loss is 1.1219315157477976\n",
      "at 200 iteration loss is 0.9967331294785178\n",
      "at 300 iteration loss is 1.176398902114708\n",
      "at 300 iteration loss is 1.191481587402496\n",
      "at 300 iteration loss is 1.1065400824373541\n",
      "at 300 iteration loss is 1.279284397752841\n",
      "at 300 iteration loss is 1.0477222089154217\n",
      "at 300 iteration loss is 1.2743940544382155\n",
      "at 300 iteration loss is 1.198635280990569\n",
      "at 300 iteration loss is 1.1881642381943318\n",
      "at 300 iteration loss is 1.0482095181228968\n",
      "at 300 iteration loss is 1.1778572337603257\n",
      "at 300 iteration loss is 1.1333741184774622\n",
      "at 300 iteration loss is 1.1808959668029573\n",
      "at 300 iteration loss is 1.2408214244964264\n",
      "at 300 iteration loss is 1.0546498978477217\n",
      "at 300 iteration loss is 1.4061410347209786\n",
      "at 300 iteration loss is 1.2774919407979255\n",
      "at 300 iteration loss is 1.1401536482229002\n",
      "at 300 iteration loss is 0.9990023950561818\n",
      "at 400 iteration loss is 1.1558382255351234\n",
      "at 400 iteration loss is 1.2018224316811055\n",
      "at 400 iteration loss is 1.1129617330521342\n",
      "at 400 iteration loss is 1.2903135224858862\n",
      "at 400 iteration loss is 1.042046671641384\n",
      "at 400 iteration loss is 1.2827248452346822\n",
      "at 400 iteration loss is 1.194147727450072\n",
      "at 400 iteration loss is 1.1987812611431514\n",
      "at 400 iteration loss is 1.0476908416818778\n",
      "at 400 iteration loss is 1.1958492157440586\n",
      "at 400 iteration loss is 1.1271604072616361\n",
      "at 400 iteration loss is 1.1886605444184966\n",
      "at 400 iteration loss is 1.254643536241892\n",
      "at 400 iteration loss is 1.0552189916755654\n",
      "at 400 iteration loss is 1.3929287453509682\n",
      "at 400 iteration loss is 1.3217044437556935\n",
      "at 400 iteration loss is 1.1533047243785177\n",
      "at 400 iteration loss is 0.9997699149961768\n",
      "at 500 iteration loss is 1.1393684732178198\n",
      "at 500 iteration loss is 1.2106440964361342\n",
      "at 500 iteration loss is 1.1181406428650669\n",
      "at 500 iteration loss is 1.299438846254961\n",
      "at 500 iteration loss is 1.0380504809917794\n",
      "at 500 iteration loss is 1.2894835607252848\n",
      "at 500 iteration loss is 1.1898568333212873\n",
      "at 500 iteration loss is 1.2086119998362062\n",
      "at 500 iteration loss is 1.046936238490318\n",
      "at 500 iteration loss is 1.2119922881684162\n",
      "at 500 iteration loss is 1.1216447582020412\n",
      "at 500 iteration loss is 1.1952665975863694\n",
      "at 500 iteration loss is 1.26632298592738\n",
      "at 500 iteration loss is 1.0554071132417921\n",
      "at 500 iteration loss is 1.3828383608926906\n",
      "at 500 iteration loss is 1.3603614328390374\n",
      "at 500 iteration loss is 1.1634138488396861\n",
      "at 500 iteration loss is 0.9998814482776064\n",
      "at 600 iteration loss is 1.1259759623147338\n",
      "at 600 iteration loss is 1.2182590377348657\n",
      "at 600 iteration loss is 1.1225614339026748\n",
      "at 600 iteration loss is 1.307258548341342\n",
      "at 600 iteration loss is 1.0352084333662783\n",
      "at 600 iteration loss is 1.2951191934190354\n",
      "at 600 iteration loss is 1.18592422925824\n",
      "at 600 iteration loss is 1.2175901219917336\n",
      "at 600 iteration loss is 1.0461535582748445\n",
      "at 600 iteration loss is 1.2264768024238546\n",
      "at 600 iteration loss is 1.1168064379272171\n",
      "at 600 iteration loss is 1.200996087191205\n",
      "at 600 iteration loss is 1.2763358325171184\n",
      "at 600 iteration loss is 1.0554728378415237\n",
      "at 600 iteration loss is 1.374984555469247\n",
      "at 600 iteration loss is 1.394215152698365\n",
      "at 600 iteration loss is 1.1716050098000086\n",
      "at 600 iteration loss is 0.9997598359471382\n",
      "at 700 iteration loss is 1.1149464958018742\n",
      "at 700 iteration loss is 1.2248837800146772\n",
      "at 700 iteration loss is 1.1264670848272558\n",
      "at 700 iteration loss is 1.3140933150864922\n",
      "at 700 iteration loss is 1.0331644074042976\n",
      "at 700 iteration loss is 1.2999093202509449\n",
      "at 700 iteration loss is 1.1824030885506627\n",
      "at 700 iteration loss is 1.225719975503084\n",
      "at 700 iteration loss is 1.0454322932814137\n",
      "at 700 iteration loss is 1.2394578061954185\n",
      "at 700 iteration loss is 1.1125899243325805\n",
      "at 700 iteration loss is 1.2060226972754646\n",
      "at 700 iteration loss is 1.2849989793412897\n",
      "at 700 iteration loss is 1.055525904201822\n",
      "at 700 iteration loss is 1.368760738918518\n",
      "at 700 iteration loss is 1.4238967017204414\n",
      "at 700 iteration loss is 1.1785024096125778\n",
      "at 700 iteration loss is 0.9996016469101209\n",
      "at 800 iteration loss is 1.1057660569902847\n",
      "at 800 iteration loss is 1.2306752478372327\n",
      "at 800 iteration loss is 1.1299788736418406\n",
      "at 800 iteration loss is 1.320127476623067\n",
      "at 800 iteration loss is 1.0316776599921713\n",
      "at 800 iteration loss is 1.3040335358433737\n",
      "at 800 iteration loss is 1.1792912241307574\n",
      "at 800 iteration loss is 1.2330384104928598\n",
      "at 800 iteration loss is 1.0448035382538843\n",
      "at 800 iteration loss is 1.2510708219796827\n",
      "at 800 iteration loss is 1.1089269899407772\n",
      "at 800 iteration loss is 1.2104594855675332\n",
      "at 800 iteration loss is 1.292538486799333\n",
      "at 800 iteration loss is 1.0556056356220087\n",
      "at 800 iteration loss is 1.3637475093609408\n",
      "at 800 iteration loss is 1.449943424094068\n",
      "at 800 iteration loss is 1.184459400284373\n",
      "at 800 iteration loss is 0.999487455595035\n",
      "at 900 iteration loss is 1.0980566786328736\n",
      "at 900 iteration loss is 1.2357533050377514\n",
      "at 900 iteration loss is 1.1331594798890126\n",
      "at 900 iteration loss is 1.3254788536361386\n",
      "at 900 iteration loss is 1.0305845641338025\n",
      "at 900 iteration loss is 1.3076145093746827\n",
      "at 900 iteration loss is 1.1765606819173502\n",
      "at 900 iteration loss is 1.239598017677412\n",
      "at 900 iteration loss is 1.0442710249309393\n",
      "at 900 iteration loss is 1.2614402991721074\n",
      "at 900 iteration loss is 1.105748484252561\n",
      "at 900 iteration loss is 1.2143867611203762\n",
      "at 900 iteration loss is 1.2991252242787923\n",
      "at 900 iteration loss is 1.0557199317597292\n",
      "at 900 iteration loss is 1.3596512926482225\n",
      "at 900 iteration loss is 1.4728171962628944\n",
      "at 900 iteration loss is 1.1896838773705505\n",
      "at 900 iteration loss is 0.9994412034577242\n",
      "at 1000 iteration loss is 1.0915346729330586\n",
      "at 1000 iteration loss is 1.2402138597331978\n",
      "at 1000 iteration loss is 1.1360447685859107\n",
      "at 1000 iteration loss is 1.3302322717227781\n",
      "at 1000 iteration loss is 1.0297728562193083\n",
      "at 1000 iteration loss is 1.3107408490932717\n",
      "at 1000 iteration loss is 1.1741735338195223\n",
      "at 1000 iteration loss is 1.2454584458192943\n",
      "at 1000 iteration loss is 1.0438268046485983\n",
      "at 1000 iteration loss is 1.2706829000593598\n",
      "at 1000 iteration loss is 1.1029899445234985\n",
      "at 1000 iteration loss is 1.2178667789459394\n",
      "at 1000 iteration loss is 1.30489429301557\n",
      "at 1000 iteration loss is 1.0558640730604225\n",
      "at 1000 iteration loss is 1.3562633326458937\n",
      "at 1000 iteration loss is 1.492917343805461\n",
      "at 1000 iteration loss is 1.1943057709193192\n",
      "at 1000 iteration loss is 0.9994611969390522\n",
      "at 1100 iteration loss is 1.0859830297641113\n",
      "at 1100 iteration loss is 1.244136372648613\n",
      "at 1100 iteration loss is 1.1386591304749043\n",
      "at 1100 iteration loss is 1.3344552705923378\n",
      "at 1100 iteration loss is 1.029164633390646\n",
      "at 1100 iteration loss is 1.3134799345137005\n",
      "at 1100 iteration loss is 1.1720899302391576\n",
      "at 1100 iteration loss is 1.2506813684247833\n",
      "at 1100 iteration loss is 1.0434589335670805\n",
      "at 1100 iteration loss is 1.2789082405997736\n",
      "at 1100 iteration loss is 1.1005938054051163\n",
      "at 1100 iteration loss is 1.2209511046193817\n",
      "at 1100 iteration loss is 1.3099560850673615\n",
      "at 1100 iteration loss is 1.0560294359044335\n",
      "at 1100 iteration loss is 1.3534324406473925\n",
      "at 1100 iteration loss is 1.5105903433652323\n",
      "at 1100 iteration loss is 1.1984129301133621\n",
      "at 1100 iteration loss is 0.9995357649472894\n",
      "at 1200 iteration loss is 1.0812328599542462\n",
      "at 1200 iteration loss is 1.2475882367233908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at 1200 iteration loss is 1.1410224861981164\n",
      "at 1200 iteration loss is 1.338205329629133\n",
      "at 1200 iteration loss is 1.0287051749952318\n",
      "at 1200 iteration loss is 1.3158852370718788\n",
      "at 1200 iteration loss is 1.1702719374066926\n",
      "at 1200 iteration loss is 1.255327441391426\n",
      "at 1200 iteration loss is 1.043155053456824\n",
      "at 1200 iteration loss is 1.2862186972537515\n",
      "at 1200 iteration loss is 1.0985098509673636\n",
      "at 1200 iteration loss is 1.2236842313629195\n",
      "at 1200 iteration loss is 1.314402895232122\n",
      "at 1200 iteration loss is 1.0562072726161424\n",
      "at 1200 iteration loss is 1.351046938213802\n",
      "at 1200 iteration loss is 1.526137496039534\n",
      "at 1200 iteration loss is 1.2020700138207192\n",
      "at 1200 iteration loss is 0.9996507997345908\n",
      "at 1300 iteration loss is 1.0771506867344989\n",
      "at 1300 iteration loss is 1.2506274501806722\n",
      "at 1300 iteration loss is 1.1431532103037128\n",
      "at 1300 iteration loss is 1.3415331575827747\n",
      "at 1300 iteration loss is 1.0283555703490361\n",
      "at 1300 iteration loss is 1.318000601199302\n",
      "at 1300 iteration loss is 1.1686851421940776\n",
      "at 1300 iteration loss is 1.2594544940089982\n",
      "at 1300 iteration loss is 1.042903905740414\n",
      "at 1300 iteration loss is 1.2927090623732564\n",
      "at 1300 iteration loss is 1.0966948298473578\n",
      "at 1300 iteration loss is 1.226105379128067\n",
      "at 1300 iteration loss is 1.318313096413058\n",
      "at 1300 iteration loss is 1.0563901425903575\n",
      "at 1300 iteration loss is 1.3490226700376793\n",
      "at 1300 iteration loss is 1.5398212238367535\n",
      "at 1300 iteration loss is 1.2053283506845278\n",
      "at 1300 iteration loss is 0.9997931018806245\n",
      "at 1400 iteration loss is 1.0736295764610557\n",
      "at 1400 iteration loss is 1.253304360501107\n",
      "at 1400 iteration loss is 1.1450691476705257\n",
      "at 1400 iteration loss is 1.344484212595209\n",
      "at 1400 iteration loss is 1.0280878215272586\n",
      "at 1400 iteration loss is 1.3198628339397933\n",
      "at 1400 iteration loss is 1.1672991154782353\n",
      "at 1400 iteration loss is 1.263116526506638\n",
      "at 1400 iteration loss is 1.042695835821314\n",
      "at 1400 iteration loss is 1.2984663529213\n",
      "at 1400 iteration loss is 1.0951117276575295\n",
      "at 1400 iteration loss is 1.228249446931716\n",
      "at 1400 iteration loss is 1.3217539351887426\n",
      "at 1400 iteration loss is 1.0565722726330813\n",
      "at 1400 iteration loss is 1.347294994052011\n",
      "at 1400 iteration loss is 1.5518703578655306\n",
      "at 1400 iteration loss is 1.208231054368266\n",
      "at 1400 iteration loss is 0.9999516232395248\n",
      "at 1500 iteration loss is 1.070582831886044\n",
      "at 1500 iteration loss is 1.2556628924314766\n",
      "at 1500 iteration loss is 1.1467878011371802\n",
      "at 1500 iteration loss is 1.3470994592373615\n",
      "at 1500 iteration loss is 1.0278815582322471\n",
      "at 1500 iteration loss is 1.321503340182066\n",
      "at 1500 iteration loss is 1.1660873231893434\n",
      "at 1500 iteration loss is 1.2663632387666077\n",
      "at 1500 iteration loss is 1.0425228295318312\n",
      "at 1500 iteration loss is 1.30356984449782\n",
      "at 1500 iteration loss is 1.0937289494215672\n",
      "at 1500 iteration loss is 1.230147584366501\n",
      "at 1500 iteration loss is 1.3247835147795537\n",
      "at 1500 iteration loss is 1.0567494662440686\n",
      "at 1500 iteration loss is 1.3458133710749052\n",
      "at 1500 iteration loss is 1.562484639906216\n",
      "at 1500 iteration loss is 1.2108156767464942\n",
      "at 1500 iteration loss is 1.0001177077000842\n",
      "at 1600 iteration loss is 1.067939425497883\n",
      "at 1600 iteration loss is 1.2577414765902548\n",
      "at 1600 iteration loss is 1.1483262074429879\n",
      "at 1600 iteration loss is 1.349415815767663\n",
      "at 1600 iteration loss is 1.02772180870993\n",
      "at 1600 iteration loss is 1.3229492087467727\n",
      "at 1600 iteration loss is 1.1650267963070289\n",
      "at 1600 iteration loss is 1.2692399025365741\n",
      "at 1600 iteration loss is 1.0423783542163387\n",
      "at 1600 iteration loss is 1.3080913061491193\n",
      "at 1600 iteration loss is 1.0925195325140582\n",
      "at 1600 iteration loss is 1.2318275959402396\n",
      "at 1600 iteration loss is 1.3274522765200496\n",
      "at 1600 iteration loss is 1.0569188537786862\n",
      "at 1600 iteration loss is 1.3445376577535657\n",
      "at 1600 iteration loss is 1.5718385824363135\n",
      "at 1600 iteration loss is 1.213115602632445\n",
      "at 1600 iteration loss is 1.0002848952144459\n",
      "at 1700 iteration loss is 1.0656406351715044\n",
      "at 1700 iteration loss is 1.2595737921358352\n",
      "at 1700 iteration loss is 1.1497007363422551\n",
      "at 1700 iteration loss is 1.3514664861911254\n",
      "at 1700 iteration loss is 1.027597468362763\n",
      "at 1700 iteration loss is 1.324223973933484\n",
      "at 1700 iteration loss is 1.1640977193704676\n",
      "at 1700 iteration loss is 1.2717874481731297\n",
      "at 1700 iteration loss is 1.0422571371976734\n",
      "at 1700 iteration loss is 1.3120953817956793\n",
      "at 1700 iteration loss is 1.0914604404037251\n",
      "at 1700 iteration loss is 1.2333142711435954\n",
      "at 1700 iteration loss is 1.3298041549338617\n",
      "at 1700 iteration loss is 1.0570786143780926\n",
      "at 1700 iteration loss is 1.3434355233499609\n",
      "at 1700 iteration loss is 1.5800847911135387\n",
      "at 1700 iteration loss is 1.2151608130974894\n",
      "at 1700 iteration loss is 1.0004485706799329\n",
      "at 1800 iteration loss is 1.0636375250044416\n",
      "at 1800 iteration loss is 1.2611893838999744\n",
      "at 1800 iteration loss is 1.1509269096714485\n",
      "at 1800 iteration loss is 1.3532812541763612\n",
      "at 1800 iteration loss is 1.027500234143365\n",
      "at 1800 iteration loss is 1.325348178391022\n",
      "at 1800 iteration loss is 1.163283015468754\n",
      "at 1800 iteration loss is 1.2740426783001328\n",
      "at 1800 iteration loss is 1.0421549427155423\n",
      "at 1800 iteration loss is 1.3156400635170993\n",
      "at 1800 iteration loss is 1.0905319518220844\n",
      "at 1800 iteration loss is 1.234629677735328\n",
      "at 1800 iteration loss is 1.3318775082029748\n",
      "at 1800 iteration loss is 1.0572277229814318\n",
      "at 1800 iteration loss is 1.3424806160794285\n",
      "at 1800 iteration loss is 1.5873568302388705\n",
      "at 1800 iteration loss is 1.216978339076351\n",
      "at 1800 iteration loss is 1.0006055907243896\n",
      "at 1900 iteration loss is 1.061889030348805\n",
      "at 1900 iteration loss is 1.2626141874004149\n",
      "at 1900 iteration loss is 1.1520192721879952\n",
      "at 1900 iteration loss is 1.354886764724626\n",
      "at 1900 iteration loss is 1.0274238535881453\n",
      "at 1900 iteration loss is 1.3263398089052485\n",
      "at 1900 iteration loss is 1.1625679626052974\n",
      "at 1900 iteration loss is 1.2760385499962634\n",
      "at 1900 iteration loss is 1.0420683724296658\n",
      "at 1900 iteration loss is 1.3187772117174874\n",
      "at 1900 iteration loss is 1.0897171429963985\n",
      "at 1900 iteration loss is 1.2357934316493249\n",
      "at 1900 iteration loss is 1.3337058856554185\n",
      "at 1900 iteration loss is 1.057365739562718\n",
      "at 1900 iteration loss is 1.3416512363675677\n",
      "at 1900 iteration loss is 1.5937716969132152\n",
      "at 1900 iteration loss is 1.2185925668466848\n",
      "at 1900 iteration loss is 1.00075394538171\n",
      "at 2000 iteration loss is 1.0603604817739014\n",
      "at 2000 iteration loss is 1.2638709814742344\n",
      "at 2000 iteration loss is 1.1529913173763817\n",
      "at 2000 iteration loss is 1.3563067988004138\n",
      "at 2000 iteration loss is 1.0273635890885573\n",
      "at 2000 iteration loss is 1.327214646673431\n",
      "at 2000 iteration loss is 1.161939854207364\n",
      "at 2000 iteration loss is 1.2778044875116579\n",
      "at 2000 iteration loss is 1.041994697114626\n",
      "at 2000 iteration loss is 1.3215530889712295\n",
      "at 2000 iteration loss is 1.089001453443393\n",
      "at 2000 iteration loss is 1.2368229473073813\n",
      "at 2000 iteration loss is 1.3353186714192786\n",
      "at 2000 iteration loss is 1.0574926418219044\n",
      "at 2000 iteration loss is 1.340929358545815\n",
      "at 2000 iteration loss is 1.5994319591589847\n",
      "at 2000 iteration loss is 1.2200254741265364\n",
      "at 2000 iteration loss is 1.0008924739705112\n",
      "at 2100 iteration loss is 1.0590224527992116\n",
      "at 2100 iteration loss is 1.2649797812873609\n",
      "at 2100 iteration loss is 1.1538554603394573\n",
      "at 2100 iteration loss is 1.357562538953579\n",
      "at 2100 iteration loss is 1.027315831316717\n",
      "at 2100 iteration loss is 1.3279865568827636\n",
      "at 2100 iteration loss is 1.1613877056762192\n",
      "at 2100 iteration loss is 1.2793667014798327\n",
      "at 2100 iteration loss is 1.0419317192072068\n",
      "at 2100 iteration loss is 1.324008884829269\n",
      "at 2100 iteration loss is 1.0883723236531146\n",
      "at 2100 iteration loss is 1.2377336688624483\n",
      "at 2100 iteration loss is 1.3367416304632864\n",
      "at 2100 iteration loss is 1.0576086963411317\n",
      "at 2100 iteration loss is 1.340299896337982\n",
      "at 2100 iteration loss is 1.6044276051780249\n",
      "at 2100 iteration loss is 1.2212968334448655\n",
      "at 2100 iteration loss is 1.0010206368475527\n",
      "at 2200 iteration loss is 1.057849849891161\n",
      "at 2200 iteration loss is 1.265958180798724\n",
      "at 2200 iteration loss is 1.1546230469102856\n",
      "at 2200 iteration loss is 1.3586728224137299\n",
      "at 2200 iteration loss is 1.0272778173441526\n",
      "at 2200 iteration loss is 1.3286677329597254\n",
      "at 2200 iteration loss is 1.1609020039316276\n",
      "at 2200 iteration loss is 1.2807484999901397\n",
      "at 2200 iteration loss is 1.0418776626627095\n",
      "at 2200 iteration loss is 1.3261812171114569\n",
      "at 2200 iteration loss is 1.0878188931849562\n",
      "at 2200 iteration loss is 1.2385392822272956\n",
      "at 2200 iteration loss is 1.3379973755389887\n",
      "at 2200 iteration loss is 1.0577143614664355\n",
      "at 2200 iteration loss is 1.3397501420867042\n",
      "at 2200 iteration loss is 1.60883764422934\n",
      "at 2200 iteration loss is 1.2224243986243655\n",
      "at 2200 iteration loss is 1.001138337287911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at 2300 iteration loss is 1.0568211861647137\n",
      "at 2300 iteration loss is 1.2668216517009365\n",
      "at 2300 iteration loss is 1.155304388581659\n",
      "at 2300 iteration loss is 1.359654378671068\n",
      "at 2300 iteration loss is 1.027247423157728\n",
      "at 2300 iteration loss is 1.3292689054422646\n",
      "at 2300 iteration loss is 1.1604744950140105\n",
      "at 2300 iteration loss is 1.2819705831018804\n",
      "at 2300 iteration loss is 1.0418310856707695\n",
      "at 2300 iteration loss is 1.3281026012611632\n",
      "at 2300 iteration loss is 1.0873317488823389\n",
      "at 2300 iteration loss is 1.2392519079808615\n",
      "at 2300 iteration loss is 1.3391057687414345\n",
      "at 2300 iteration loss is 1.0578102153456377\n",
      "at 2300 iteration loss is 1.339269332084381\n",
      "at 2300 iteration loss is 1.6127314939065982\n",
      "at 2300 iteration loss is 1.2234240803399774\n",
      "at 2300 iteration loss is 1.0012457853589356\n",
      "at 2400 iteration loss is 1.0559179961136063\n",
      "at 2400 iteration loss is 1.2675838045942514\n",
      "at 2400 iteration loss is 1.1559088145410858\n",
      "at 2400 iteration loss is 1.3605220496517485\n",
      "at 2400 iteration loss is 1.0272230096591304\n",
      "at 2400 iteration loss is 1.3297995222573429\n",
      "at 2400 iteration loss is 1.1600980044225282\n",
      "at 2400 iteration loss is 1.283051316418868\n",
      "at 2400 iteration loss is 1.0417908119117945\n",
      "at 2400 iteration loss is 1.3298018835690715\n",
      "at 2400 iteration loss is 1.0869027144011043\n",
      "at 2400 iteration loss is 1.2398822756861552\n",
      "at 2400 iteration loss is 1.340084268264802\n",
      "at 2400 iteration loss is 1.0578969034348542\n",
      "at 2400 iteration loss is 1.3388483050580802\n",
      "at 2400 iteration loss is 1.616170183670177\n",
      "at 2400 iteration loss is 1.2243101123482751\n",
      "at 2400 iteration loss is 1.0013433956047244\n",
      "at 2500 iteration loss is 1.0551243598475752\n",
      "at 2500 iteration loss is 1.2682566172781589\n",
      "at 2500 iteration loss is 1.1564447340187929\n",
      "at 2500 iteration loss is 1.3612889916537427\n",
      "at 2500 iteration loss is 1.027203307523879\n",
      "at 2500 iteration loss is 1.3302679052761102\n",
      "at 2500 iteration loss is 1.1597662851724735\n",
      "at 2500 iteration loss is 1.2840069819131086\n",
      "at 2500 iteration loss is 1.0417558765717245\n",
      "at 2500 iteration loss is 1.3313046369140573\n",
      "at 2500 iteration loss is 1.0865246737150596\n",
      "at 2500 iteration loss is 1.2404398805397632\n",
      "at 2500 iteration loss is 1.3409482287645675\n",
      "at 2500 iteration loss is 1.0579751008294438\n",
      "at 2500 iteration loss is 1.3384792306086637\n",
      "at 2500 iteration loss is 1.6192074002264292\n",
      "at 2500 iteration loss is 1.2250952082986148\n",
      "at 2500 iteration loss is 1.0014317112697804\n",
      "at 2600 iteration loss is 1.0544265132594706\n",
      "at 2600 iteration loss is 1.26885063437777\n",
      "at 2600 iteration loss is 1.1569197038978571\n",
      "at 2600 iteration loss is 1.3619668590413514\n",
      "at 2600 iteration loss is 1.0271873305661632\n",
      "at 2600 iteration loss is 1.3306813868228848\n",
      "at 2600 iteration loss is 1.1594738891314111\n",
      "at 2600 iteration loss is 1.2848520057801978\n",
      "at 2600 iteration loss is 1.0417254839733043\n",
      "at 2600 iteration loss is 1.3326335195000296\n",
      "at 2600 iteration loss is 1.0861914225748417\n",
      "at 2600 iteration loss is 1.2409331235338408\n",
      "at 2600 iteration loss is 1.3417111621707334\n",
      "at 2600 iteration loss is 1.0580454857506436\n",
      "at 2600 iteration loss is 1.3381553909790234\n",
      "at 2600 iteration loss is 1.6218903966677005\n",
      "at 2600 iteration loss is 1.2257907085931605\n",
      "at 2600 iteration loss is 1.0015113489928134\n",
      "at 2700 iteration loss is 1.053812526279622\n",
      "at 2700 iteration loss is 1.269375141973269\n",
      "at 2700 iteration loss is 1.1573404979693456\n",
      "at 2700 iteration loss is 1.3625659702803863\n",
      "at 2700 iteration loss is 1.0271743101930073\n",
      "at 2700 iteration loss is 1.3310464290296473\n",
      "at 2700 iteration loss is 1.1592160578329644\n",
      "at 2700 iteration loss is 1.2855991640616966\n",
      "at 2700 iteration loss is 1.0416989742918308\n",
      "at 2700 iteration loss is 1.3338085981887349\n",
      "at 2700 iteration loss is 1.0858975430122884\n",
      "at 2700 iteration loss is 1.2413694364506573\n",
      "at 2700 iteration loss is 1.342384964613483\n",
      "at 2700 iteration loss is 1.0581087213475757\n",
      "at 2700 iteration loss is 1.3378710040330863\n",
      "at 2700 iteration loss is 1.6242607841233376\n",
      "at 2700 iteration loss is 1.2264067168394899\n",
      "at 2700 iteration loss is 1.001582959086153\n",
      "at 2800 iteration loss is 1.0532720355665686\n",
      "at 2800 iteration loss is 1.2698383204307493\n",
      "at 2800 iteration loss is 1.1577131753341423\n",
      "at 2800 iteration loss is 1.3630954572680083\n",
      "at 2800 iteration loss is 1.0271636455777664\n",
      "at 2800 iteration loss is 1.3313687283860731\n",
      "at 2800 iteration loss is 1.1589886295747283\n",
      "at 2800 iteration loss is 1.2862597673063463\n",
      "at 2800 iteration loss is 1.0416757973516866\n",
      "at 2800 iteration loss is 1.3348476386642554\n",
      "at 2800 iteration loss is 1.085638296904979\n",
      "at 2800 iteration loss is 1.2417553930539866\n",
      "at 2800 iteration loss is 1.3429801141987923\n",
      "at 2800 iteration loss is 1.058165443644064\n",
      "at 2800 iteration loss is 1.337621078470087\n",
      "at 2800 iteration loss is 1.6263552219626654\n",
      "at 2800 iteration loss is 1.226952225690845\n",
      "at 2800 iteration loss is 1.001647197558925\n",
      "at 2900 iteration loss is 1.052796021083704\n",
      "at 2900 iteration loss is 1.2702473782227959\n",
      "at 2900 iteration loss is 1.1580431462964114\n",
      "at 2900 iteration loss is 1.3635633991216882\n",
      "at 2900 iteration loss is 1.0271548656267224\n",
      "at 2900 iteration loss is 1.3316533074411026\n",
      "at 2900 iteration loss is 1.1587879601443374\n",
      "at 2900 iteration loss is 1.2868438258120047\n",
      "at 2900 iteration loss is 1.041655491935499\n",
      "at 2900 iteration loss is 1.3357663649761644\n",
      "at 2900 iteration loss is 1.0854095353658608\n",
      "at 2900 iteration loss is 1.242096807819755\n",
      "at 2900 iteration loss is 1.3435058436316027\n",
      "at 2900 iteration loss is 1.0582162539860438\n",
      "at 2900 iteration loss is 1.3374012945276996\n",
      "at 2900 iteration loss is 1.6282060202779962\n",
      "at 2900 iteration loss is 1.227435232139657\n",
      "at 2900 iteration loss is 1.001704706908394\n",
      "at 3000 iteration loss is 1.0523766183302004\n",
      "at 3000 iteration loss is 1.2706086691677976\n",
      "at 3000 iteration loss is 1.158335234713535\n",
      "at 3000 iteration loss is 1.3639769416869174\n",
      "at 3000 iteration loss is 1.0271475998431272\n",
      "at 3000 iteration loss is 1.3319045953116002\n",
      "at 3000 iteration loss is 1.1586108549757208\n",
      "at 3000 iteration loss is 1.2873601970926105\n",
      "at 3000 iteration loss is 1.0416376693866074\n",
      "at 3000 iteration loss is 1.336578691108614\n",
      "at 3000 iteration loss is 1.0852076213276742\n",
      "at 3000 iteration loss is 1.242398823484752\n",
      "at 3000 iteration loss is 1.3439702910805624\n",
      "at 3000 iteration loss is 1.0582617147519895\n",
      "at 3000 iteration loss is 1.3372079050351573\n",
      "at 3000 iteration loss is 1.6298416664055797\n",
      "at 3000 iteration loss is 1.227862842558324\n",
      "at 3000 iteration loss is 1.0017561033996794\n",
      "at 3100 iteration loss is 1.0520069597466797\n",
      "at 3100 iteration loss is 1.2709277952019022\n",
      "at 3100 iteration loss is 1.158593736213666\n",
      "at 3100 iteration loss is 1.364342404040325\n",
      "at 3100 iteration loss is 1.0271415559366877\n",
      "at 3100 iteration loss is 1.332126498415433\n",
      "at 3100 iteration loss is 1.1584545109195965\n",
      "at 3100 iteration loss is 1.2878167172138635\n",
      "at 3100 iteration loss is 1.0416220005601726\n",
      "at 3100 iteration loss is 1.3372969271896753\n",
      "at 3100 iteration loss is 1.0850293631773678\n",
      "at 3100 iteration loss is 1.2426659886049447\n",
      "at 3100 iteration loss is 1.3443806321793994\n",
      "at 3100 iteration loss is 1.0583023473996094\n",
      "at 3100 iteration loss is 1.3370376528546806\n",
      "at 3100 iteration loss is 1.6312872855666967\n",
      "at 3100 iteration loss is 1.2282413679503024\n",
      "at 3100 iteration loss is 1.0018019691012416\n",
      "at 3200 iteration loss is 1.0516810401528336\n",
      "at 3200 iteration loss is 1.271209696522054\n",
      "at 3200 iteration loss is 1.1588224720069216\n",
      "at 3200 iteration loss is 1.36466537323161\n",
      "at 3200 iteration loss is 1.0271365025685104\n",
      "at 3200 iteration loss is 1.3323224626516381\n",
      "at 3200 iteration loss is 1.1583164661270797\n",
      "at 3200 iteration loss is 1.2882203175797584\n",
      "at 3200 iteration loss is 1.0416082053920444\n",
      "at 3200 iteration loss is 1.3379319628420836\n",
      "at 3200 iteration loss is 1.084871957684903\n",
      "at 3200 iteration loss is 1.2429023262164935\n",
      "at 3200 iteration loss is 1.344743195643606\n",
      "at 3200 iteration loss is 1.0583386321579886\n",
      "at 3200 iteration loss is 1.33688770162416\n",
      "at 3200 iteration loss is 1.6325650442863833\n",
      "at 3200 iteration loss is 1.2285764099864847\n",
      "at 3200 iteration loss is 1.0018428473678722\n",
      "at 3300 iteration loss is 1.0513936021033126\n",
      "at 3300 iteration loss is 1.2714587306984777\n",
      "at 3300 iteration loss is 1.1590248382336696\n",
      "at 3300 iteration loss is 1.364950788443819\n",
      "at 3300 iteration loss is 1.0271322560199847\n",
      "at 3300 iteration loss is 1.332495528087836\n",
      "at 3300 iteration loss is 1.158194556803179\n",
      "at 3300 iteration loss is 1.2885771286567145\n",
      "at 3300 iteration loss is 1.0415960445200017\n",
      "at 3300 iteration loss is 1.3384934300183224\n",
      "at 3300 iteration loss is 1.084732940783228\n",
      "at 3300 iteration loss is 1.2431113945914334\n",
      "at 3300 iteration loss is 1.3450635646312414\n",
      "at 3300 iteration loss is 1.0583710088527054\n",
      "at 3300 iteration loss is 1.3367555773723296\n",
      "at 3300 iteration loss is 1.6336945040359219\n",
      "at 3300 iteration loss is 1.2288729384661878\n",
      "at 3300 iteration loss is 1.0018792407889443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at 3400 iteration loss is 1.0511400378470508\n",
      "at 3400 iteration loss is 1.2716787421461813\n",
      "at 3400 iteration loss is 1.1592038509393028\n",
      "at 3400 iteration loss is 1.365203015670834\n",
      "at 3400 iteration loss is 1.02712866986937\n",
      "at 3400 iteration loss is 1.3326483770772597\n",
      "at 3400 iteration loss is 1.1580868797975061\n",
      "at 3400 iteration loss is 1.28889257201004\n",
      "at 3400 iteration loss is 1.0415853125195018\n",
      "at 3400 iteration loss is 1.3389898474829458\n",
      "at 3400 iteration loss is 1.0846101450074666\n",
      "at 3400 iteration loss is 1.2432963409810733\n",
      "at 3400 iteration loss is 1.3453466656810265\n",
      "at 3400 iteration loss is 1.0583998784857767\n",
      "at 3400 iteration loss is 1.3366391190788225\n",
      "at 3400 iteration loss is 1.6346929315144465\n",
      "at 3400 iteration loss is 1.2291353608695943\n",
      "at 3400 iteration loss is 1.0019116108684214\n",
      "at 3500 iteration loss is 1.0509163052005004\n",
      "at 3500 iteration loss is 1.2718731231639637\n",
      "at 3500 iteration loss is 1.1593621868592368\n",
      "at 3500 iteration loss is 1.3654259139226643\n",
      "at 3500 iteration loss is 1.027125626980163\n",
      "at 3500 iteration loss is 1.3327833766098618\n",
      "at 3500 iteration loss is 1.1579917601716445\n",
      "at 3500 iteration loss is 1.2891714419097393\n",
      "at 3500 iteration loss is 1.0415758324142752\n",
      "at 3500 iteration loss is 1.3394287489181291\n",
      "at 3500 iteration loss is 1.08450166260422\n",
      "at 3500 iteration loss is 1.243459949146678\n",
      "at 3500 iteration loss is 1.3455968468101251\n",
      "at 3500 iteration loss is 1.0584256052932601\n",
      "at 3500 iteration loss is 1.336536436637291\n",
      "at 3500 iteration loss is 1.6355755711067637\n",
      "at 3500 iteration loss is 1.229367584669123\n",
      "at 3500 iteration loss is 1.0019403788920616\n",
      "at 3600 iteration loss is 1.050718855138178\n",
      "at 3600 iteration loss is 1.2720448675924412\n",
      "at 3600 iteration loss is 1.1595022202551948\n",
      "at 3600 iteration loss is 1.365622893879238\n",
      "at 3600 iteration loss is 1.0271230332707109\n",
      "at 3600 iteration loss is 1.332902615600247\n",
      "at 3600 iteration loss is 1.1579077230232389\n",
      "at 3600 iteration loss is 1.2894179776458414\n",
      "at 3600 iteration loss is 1.0415674511976731\n",
      "at 3600 iteration loss is 1.3398167964439354\n",
      "at 3600 iteration loss is 1.0844058134863155\n",
      "at 3600 iteration loss is 1.2436046813904111\n",
      "at 3600 iteration loss is 1.345817946140439\n",
      "at 3600 iteration loss is 1.0584485190790913\n",
      "at 3600 iteration loss is 1.3364458749793253\n",
      "at 3600 iteration loss is 1.6363558843051813\n",
      "at 3600 iteration loss is 1.2295730730493113\n",
      "at 3600 iteration loss is 1.001965927580144\n",
      "at 3700 iteration loss is 1.0505445692954922\n",
      "at 3700 iteration loss is 1.2721966180067155\n",
      "at 3700 iteration loss is 1.159626056075092\n",
      "at 3700 iteration loss is 1.3657969698256522\n",
      "at 3700 iteration loss is 1.0271208128592992\n",
      "at 3700 iteration loss is 1.333007937727177\n",
      "at 3700 iteration loss is 1.1578334689622607\n",
      "at 3700 iteration loss is 1.2896359275813958\n",
      "at 3700 iteration loss is 1.0415600361588373\n",
      "at 3700 iteration loss is 1.3401598811683626\n",
      "at 3700 iteration loss is 1.0843211173421659\n",
      "at 3700 iteration loss is 1.243732715720445\n",
      "at 3700 iteration loss is 1.3460133522398308\n",
      "at 3700 iteration loss is 1.0584689176803708\n",
      "at 3700 iteration loss is 1.3363659833516093\n",
      "at 3700 iteration loss is 1.637045760242578\n",
      "at 3700 iteration loss is 1.2297548946545838\n",
      "at 3700 iteration loss is 1.0019886032317726\n",
      "at 3800 iteration loss is 1.0503907058918969\n",
      "at 3800 iteration loss is 1.272330707241562\n",
      "at 3800 iteration loss is 1.1597355597218355\n",
      "at 3800 iteration loss is 1.3659508056184775\n",
      "at 3800 iteration loss is 1.0271189042734403\n",
      "at 3800 iteration loss is 1.3331009703628656\n",
      "at 3800 iteration loss is 1.1577678527298292\n",
      "at 3800 iteration loss is 1.289828605866186\n",
      "at 3800 iteration loss is 1.0415534718526622\n",
      "at 3800 iteration loss is 1.340463212216921\n",
      "at 3800 iteration loss is 1.0842462693184953\n",
      "at 3800 iteration loss is 1.243845978712699\n",
      "at 3800 iteration loss is 1.3461860572084392\n",
      "at 3800 iteration loss is 1.058487069461637\n",
      "at 3800 iteration loss is 1.3362954889240068\n",
      "at 3800 iteration loss is 1.6376557009352457\n",
      "at 3800 iteration loss is 1.229915767946685\n",
      "at 3800 iteration loss is 1.0020087181477633\n",
      "at 3900 iteration loss is 1.0502548528344116\n",
      "at 3900 iteration loss is 1.272449194945144\n",
      "at 3900 iteration loss is 1.1598323837169981\n",
      "at 3900 iteration loss is 1.366086755355085\n",
      "at 3900 iteration loss is 1.0271172574841239\n",
      "at 3900 iteration loss is 1.333183150063747\n",
      "at 3900 iteration loss is 1.1577098645282822\n",
      "at 3900 iteration loss is 1.2899989426372174\n",
      "at 3900 iteration loss is 1.0415476575871867\n",
      "at 3900 iteration loss is 1.3407313955389344\n",
      "at 3900 iteration loss is 1.0841801187852114\n",
      "at 3900 iteration loss is 1.243946174567577\n",
      "at 3900 iteration loss is 1.3463387034060923\n",
      "at 3900 iteration loss is 1.0585032157670868\n",
      "at 3900 iteration loss is 1.336233274053577\n",
      "at 3900 iteration loss is 1.6381949843632284\n",
      "at 3900 iteration loss is 1.2300581007120859\n",
      "at 3900 iteration loss is 1.00202655317978\n",
      "at 4000 iteration loss is 1.0501348869656673\n",
      "at 4000 iteration loss is 1.2725538997688521\n",
      "at 4000 iteration loss is 1.1599179915376827\n",
      "at 4000 iteration loss is 1.3662068993464735\n",
      "at 4000 iteration loss is 1.0271158315806073\n",
      "at 4000 iteration loss is 1.3332557450363178\n",
      "at 4000 iteration loss is 1.157658613696205\n",
      "at 4000 iteration loss is 1.2901495284432953\n",
      "at 4000 iteration loss is 1.0415425053288923\n",
      "at 4000 iteration loss is 1.3409685036483403\n",
      "at 4000 iteration loss is 1.0841216507656277\n",
      "at 4000 iteration loss is 1.2440348108028232\n",
      "at 4000 iteration loss is 1.346473624601285\n",
      "at 4000 iteration loss is 1.0585175732830039\n",
      "at 4000 iteration loss is 1.3361783566473764\n",
      "at 4000 iteration loss is 1.6386718081108598\n",
      "at 4000 iteration loss is 1.2301840252167364\n",
      "at 4000 iteration loss is 1.0020423602985953\n",
      "at 4100 iteration loss is 1.0500289385869535\n",
      "at 4100 iteration loss is 1.2726464277242455\n",
      "at 4100 iteration loss is 1.1599936788919467\n",
      "at 4100 iteration loss is 1.3663130759289008\n",
      "at 4100 iteration loss is 1.0271145929434216\n",
      "at 4100 iteration loss is 1.3333198749409831\n",
      "at 4100 iteration loss is 1.157613314416185\n",
      "at 4100 iteration loss is 1.2902826535505774\n",
      "at 4100 iteration loss is 1.0415379379472682\n",
      "at 4100 iteration loss is 1.3411781373302767\n",
      "at 4100 iteration loss is 1.084069969677051\n",
      "at 4100 iteration loss is 1.244113220972661\n",
      "at 4100 iteration loss is 1.3465928822225675\n",
      "at 4100 iteration loss is 1.0585303362797973\n",
      "at 4100 iteration loss is 1.3361298731618039\n",
      "at 4100 iteration loss is 1.6390934159411326\n",
      "at 4100 iteration loss is 1.2302954294628003\n",
      "at 4100 iteration loss is 1.0020563651079453\n",
      "at 4200 iteration loss is 1.0499353605230615\n",
      "at 4200 iteration loss is 1.2727281971715267\n",
      "at 4200 iteration loss is 1.1600605926821288\n",
      "at 4200 iteration loss is 1.3664069095907174\n",
      "at 4200 iteration loss is 1.0271135138055103\n",
      "at 4200 iteration loss is 1.3333765283525296\n",
      "at 4200 iteration loss is 1.1575732731882813\n",
      "at 4200 iteration loss is 1.2904003427133932\n",
      "at 4200 iteration loss is 1.041533887736196\n",
      "at 4200 iteration loss is 1.341363480230752\n",
      "at 4200 iteration loss is 1.0840242850782873\n",
      "at 4200 iteration loss is 1.2441825847582115\n",
      "at 4200 iteration loss is 1.3466982973070123\n",
      "at 4200 iteration loss is 1.0585416787155477\n",
      "at 4200 iteration loss is 1.33608706385309\n",
      "at 4200 iteration loss is 1.6394662093761418\n",
      "at 4200 iteration loss is 1.230393984960783\n",
      "at 4200 iteration loss is 1.0020687692552528\n",
      "at 4300 iteration loss is 1.0498527011080276\n",
      "at 4300 iteration loss is 1.2728004608460861\n",
      "at 4300 iteration loss is 1.1601197478876863\n",
      "at 4300 iteration loss is 1.3664898358376787\n",
      "at 4300 iteration loss is 1.0271125711162215\n",
      "at 4300 iteration loss is 1.3334265781571113\n",
      "at 4300 iteration loss is 1.1575378778401446\n",
      "at 4300 iteration loss is 1.2905043859295007\n",
      "at 4300 iteration loss is 1.0415302951624064\n",
      "at 4300 iteration loss is 1.34152734714429\n",
      "at 4300 iteration loss is 1.083983899163837\n",
      "at 4300 iteration loss is 1.2442439457340777\n",
      "at 4300 iteration loss is 1.3467914786657684\n",
      "at 4300 iteration loss is 1.058551756192023\n",
      "at 4300 iteration loss is 1.3360492599561404\n",
      "at 4300 iteration loss is 1.6397958460948718\n",
      "at 4300 iteration loss is 1.2304811713911574\n",
      "at 4300 iteration loss is 1.0020797527086571\n",
      "at 4400 iteration loss is 1.0497796805639494\n",
      "at 4400 iteration loss is 1.2728643252793643\n",
      "at 4400 iteration loss is 1.1601720425808921\n",
      "at 4400 iteration loss is 1.3665631231724409\n",
      "at 4400 iteration loss is 1.0271117456420356\n",
      "at 4400 iteration loss is 1.3334707951317033\n",
      "at 4400 iteration loss is 1.1575065878767288\n",
      "at 4400 iteration loss is 1.2905963656405897\n",
      "at 4400 iteration loss is 1.0415271078011867\n",
      "at 4400 iteration loss is 1.3416722267228185\n",
      "at 4400 iteration loss is 1.0839481957809407\n",
      "at 4400 iteration loss is 1.2442982270806113\n",
      "at 4400 iteration loss is 1.3468738477219886\n",
      "at 4400 iteration loss is 1.0585607077605463\n",
      "at 4400 iteration loss is 1.3360158725201745\n",
      "at 4400 iteration loss is 1.6400873267335825\n",
      "at 4400 iteration loss is 1.2305582984930339\n",
      "at 4400 iteration loss is 1.002089475882976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at 4500 iteration loss is 1.049715170322547\n",
      "at 4500 iteration loss is 1.27292076792637\n",
      "at 4500 iteration loss is 1.1602182712704796\n",
      "at 4500 iteration loss is 1.366627892521408\n",
      "at 4500 iteration loss is 1.0271110212526222\n",
      "at 4500 iteration loss is 1.3335098599222703\n",
      "at 4500 iteration loss is 1.1574789259995883\n",
      "at 4500 iteration loss is 1.2906776807867688\n",
      "at 4500 iteration loss is 1.041524279427318\n",
      "at 4500 iteration loss is 1.341800319247239\n",
      "at 4500 iteration loss is 1.0839166307763877\n",
      "at 4500 iteration loss is 1.2443462454799796\n",
      "at 4500 iteration loss is 1.3469466604200353\n",
      "at 4500 iteration loss is 1.0585686575796305\n",
      "at 4500 iteration loss is 1.3359863826717522\n",
      "at 4500 iteration loss is 1.6403450714774563\n",
      "at 4500 iteration loss is 1.2306265254832613\n",
      "at 4500 iteration loss is 1.0020980816066871\n",
      "at 4600 iteration loss is 1.0496581749039287\n",
      "at 4600 iteration loss is 1.2729706522739064\n",
      "at 4600 iteration loss is 1.160259136750733\n",
      "at 4600 iteration loss is 1.366685134404117\n",
      "at 4600 iteration loss is 1.0271103843522886\n",
      "at 4600 iteration loss is 1.3335443736108394\n",
      "at 4600 iteration loss is 1.1574544706487488\n",
      "at 4600 iteration loss is 1.2907495680773233\n",
      "at 4600 iteration loss is 1.0415217692353638\n",
      "at 4600 iteration loss is 1.34191357003022\n",
      "at 4600 iteration loss is 1.083888723506105\n",
      "at 4600 iteration loss is 1.2443887234064637\n",
      "at 4600 iteration loss is 1.3470110265558852\n",
      "at 4600 iteration loss is 1.0585757164293115\n",
      "at 4600 iteration loss is 1.3359603331106653\n",
      "at 4600 iteration loss is 1.640572987661375\n",
      "at 4600 iteration loss is 1.23068687827824\n",
      "at 4600 iteration loss is 1.0021056969286641\n",
      "at 4700 iteration loss is 1.049607816021502\n",
      "at 4700 iteration loss is 1.273014741170201\n",
      "at 4700 iteration loss is 1.1602952606167811\n",
      "at 4700 iteration loss is 1.366735724106635\n",
      "at 4700 iteration loss is 1.0271098234256872\n",
      "at 4700 iteration loss is 1.3335748670388197\n",
      "at 4700 iteration loss is 1.1574328494397217\n",
      "at 4700 iteration loss is 1.2908131207987819\n",
      "at 4700 iteration loss is 1.0415195411683063\n",
      "at 4700 iteration loss is 1.3420136989539162\n",
      "at 4700 iteration loss is 1.0838640493627927\n",
      "at 4700 iteration loss is 1.244426299996967\n",
      "at 4700 iteration loss is 1.3470679268358574\n",
      "at 4700 iteration loss is 1.0585819830891048\n",
      "at 4700 iteration loss is 1.3359373206731213\n",
      "at 4700 iteration loss is 1.640774529448708\n",
      "at 4700 iteration loss is 1.2307402647621508\n",
      "at 4700 iteration loss is 1.0021124347680002\n",
      "at 4800 iteration loss is 1.0495633186279545\n",
      "at 4800 iteration loss is 1.2730537085873723\n",
      "at 4800 iteration loss is 1.1603271925911176\n",
      "at 4800 iteration loss is 1.3667804350903776\n",
      "at 4800 iteration loss is 1.027109328673482\n",
      "at 4800 iteration loss is 1.3336018090338475\n",
      "at 4800 iteration loss is 1.1574137333850036\n",
      "at 4800 iteration loss is 1.290869305444564\n",
      "at 4800 iteration loss is 1.041517563337413\n",
      "at 4800 iteration loss is 1.3421022265886688\n",
      "at 4800 iteration loss is 1.0838422331958824\n",
      "at 4800 iteration loss is 1.244459540666099\n",
      "at 4800 iteration loss is 1.3471182279334808\n",
      "at 4800 iteration loss is 1.058587545587749\n",
      "at 4800 iteration loss is 1.3359169898208318\n",
      "at 4800 iteration loss is 1.6409527505271022\n",
      "at 4800 iteration loss is 1.2307874883194452\n",
      "at 4800 iteration loss is 1.0021183954132824\n",
      "at 4900 iteration loss is 1.0495239986561802\n",
      "at 4900 iteration loss is 1.2730881500026365\n",
      "at 4900 iteration loss is 1.160355418791832\n",
      "at 4900 iteration loss is 1.3668199508411647\n",
      "at 4900 iteration loss is 1.027108891719084\n",
      "at 4900 iteration loss is 1.333625613669858\n",
      "at 4900 iteration loss is 1.1573968318037617\n",
      "at 4900 iteration loss is 1.2909189764179232\n",
      "at 4900 iteration loss is 1.0415158075192683\n",
      "at 4900 iteration loss is 1.3421804972876121\n",
      "at 4900 iteration loss is 1.0838229435144138\n",
      "at 4900 iteration loss is 1.2444889456110702\n",
      "at 4900 iteration loss is 1.3471626957816647\n",
      "at 4900 iteration loss is 1.0585924823334891\n",
      "at 4900 iteration loss is 1.3358990269348898\n",
      "at 4900 iteration loss is 1.6411103506466342\n",
      "at 4900 iteration loss is 1.2308292598259973\n",
      "at 4900 iteration loss is 1.002123667879611\n",
      "at 5000 iteration loss is 1.049489252242123\n",
      "at 5000 iteration loss is 1.2731185915617407\n",
      "at 5000 iteration loss is 1.160380369059617\n",
      "at 5000 iteration loss is 1.3668548753396086\n",
      "at 5000 iteration loss is 1.0271085053715368\n",
      "at 5000 iteration loss is 1.3336466466745363\n",
      "at 5000 iteration loss is 1.1573818878357476\n",
      "at 5000 iteration loss is 1.2909628890309504\n",
      "at 5000 iteration loss is 1.041514248718383\n",
      "at 5000 iteration loss is 1.3422496996066768\n",
      "at 5000 iteration loss is 1.083805887377429\n",
      "at 5000 iteration loss is 1.2445149573348175\n",
      "at 5000 iteration loss is 1.3472020073087536\n",
      "at 5000 iteration loss is 1.0585968631338765\n",
      "at 5000 iteration loss is 1.3358831553103296\n",
      "at 5000 iteration loss is 1.6412497167264053\n",
      "at 5000 iteration loss is 1.23086620827223\n",
      "at 5000 iteration loss is 1.0021283311327553\n",
      "at 5100 iteration loss is 1.0494585462448387\n",
      "at 5100 iteration loss is 1.2731454981685402\n",
      "at 5100 iteration loss is 1.1604024234483952\n",
      "at 5100 iteration loss is 1.3668857423131227\n",
      "at 5100 iteration loss is 1.0271081634330304\n",
      "at 5100 iteration loss is 1.3336652310847996\n",
      "at 5100 iteration loss is 1.1573686744861862\n",
      "at 5100 iteration loss is 1.2910017109968028\n",
      "at 5100 iteration loss is 1.0415128647858063\n",
      "at 5100 iteration loss is 1.3423108843593332\n",
      "at 5100 iteration loss is 1.0837908058886154\n",
      "at 5100 iteration loss is 1.2445379673008503\n",
      "at 5100 iteration loss is 1.3472367608020577\n",
      "at 5100 iteration loss is 1.0586007501140382\n",
      "at 5100 iteration loss is 1.3358691307617712\n",
      "at 5100 iteration loss is 1.6413729591686121\n",
      "at 5100 iteration loss is 1.230898890172536\n",
      "at 5100 iteration loss is 1.002132455190322\n",
      "at 5200 iteration loss is 1.0494314099032298\n",
      "at 5200 iteration loss is 1.2731692806273691\n",
      "at 5200 iteration loss is 1.1604219179732467\n",
      "at 5200 iteration loss is 1.3669130234111393\n",
      "at 5200 iteration loss is 1.027107860541874\n",
      "at 5200 iteration loss is 1.3336816522389197\n",
      "at 5200 iteration loss is 1.1573569911375683\n",
      "at 5200 iteration loss is 1.291036032589576\n",
      "at 5200 iteration loss is 1.0415116360857344\n",
      "at 5200 iteration loss is 1.3423649805796969\n",
      "at 5200 iteration loss is 1.0837774702223775\n",
      "at 5200 iteration loss is 1.2445583218201672\n",
      "at 5200 iteration loss is 1.3472674850604505\n",
      "at 5200 iteration loss is 1.0586041985420567\n",
      "at 5200 iteration loss is 1.3358567377626591\n",
      "at 5200 iteration loss is 1.6414819439428499\n",
      "at 5200 iteration loss is 1.2309277978983215\n",
      "at 5200 iteration loss is 1.0021361021099342\n",
      "at 5300 iteration loss is 1.049407427489749\n",
      "at 5300 iteration loss is 1.2731903019497737\n",
      "at 5300 iteration loss is 1.1604391496992505\n",
      "at 5300 iteration loss is 1.3669371354288242\n",
      "at 5300 iteration loss is 1.0271075920438106\n",
      "at 5300 iteration loss is 1.3336961621834171\n",
      "at 5300 iteration loss is 1.1573466604722824\n",
      "at 5300 iteration loss is 1.2910663756261047\n",
      "at 5300 iteration loss is 1.0415105452034337\n",
      "at 5300 iteration loss is 1.3424128096360923\n",
      "at 5300 iteration loss is 1.0837656781175813\n",
      "at 5300 iteration loss is 1.2445763272589487\n",
      "at 5300 iteration loss is 1.3472946474784293\n",
      "at 5300 iteration loss is 1.0586072575697496\n",
      "at 5300 iteration loss is 1.3358457860511133\n",
      "at 5300 iteration loss is 1.6415783209364527\n",
      "at 5300 iteration loss is 1.2309533670567314\n",
      "at 5300 iteration loss is 1.0021393268742007\n",
      "at 5400 iteration loss is 1.0493862318392224\n",
      "at 5400 iteration loss is 1.2732088829239039\n",
      "at 5400 iteration loss is 1.1604543812457595\n",
      "at 5400 iteration loss is 1.3669584466899634\n",
      "at 5400 iteration loss is 1.0271073538860007\n",
      "at 5400 iteration loss is 1.3337089835635862\n",
      "at 5400 iteration loss is 1.1573375257569478\n",
      "at 5400 iteration loss is 1.29109320140619\n",
      "at 5400 iteration loss is 1.0415095766888445\n",
      "at 5400 iteration loss is 1.342455097709203\n",
      "at 5400 iteration loss is 1.0837552507831067\n",
      "at 5400 iteration loss is 1.2445922546454766\n",
      "at 5400 iteration loss is 1.3473186611870325\n",
      "at 5400 iteration loss is 1.058609970896629\n",
      "at 5400 iteration loss is 1.3358361076442162\n",
      "at 5400 iteration loss is 1.6416635490078904\n",
      "at 5400 iteration loss is 1.230975983023551\n",
      "at 5400 iteration loss is 1.0021421781818627\n",
      "at 5500 iteration loss is 1.0493674986464538\n",
      "at 5500 iteration loss is 1.2732253070331838\n",
      "at 5500 iteration loss is 1.1604678447724457\n",
      "at 5500 iteration loss is 1.366977282686879\n",
      "at 5500 iteration loss is 1.0271071425292642\n",
      "at 5500 iteration loss is 1.333720313058369\n",
      "at 5500 iteration loss is 1.1573294484453664\n",
      "at 5500 iteration loss is 1.2911169177319437\n",
      "at 5500 iteration loss is 1.041508716831124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at 5500 iteration loss is 1.3424924868241965\n",
      "at 5500 iteration loss is 1.0837460301661908\n",
      "at 5500 iteration loss is 1.244606343745644\n",
      "at 5500 iteration loss is 1.347339891362229\n",
      "at 5500 iteration loss is 1.058612377364342\n",
      "at 5500 iteration loss is 1.3358275542102385\n",
      "at 5500 iteration loss is 1.641738918128543\n",
      "at 5500 iteration loss is 1.2309959867265756\n",
      "at 5500 iteration loss is 1.0021446991540004\n",
      "at 5600 iteration loss is 1.049350941439601\n",
      "at 5600 iteration loss is 1.2732398248006185\n",
      "at 5600 iteration loss is 1.1604797455061058\n",
      "at 5600 iteration loss is 1.3669939310638566\n",
      "at 5600 iteration loss is 1.0271069548750502\n",
      "at 5600 iteration loss is 1.333730324413118\n",
      "at 5600 iteration loss is 1.1573223060622442\n",
      "at 5600 iteration loss is 1.291137885112993\n",
      "at 5600 iteration loss is 1.0415079534600653\n",
      "at 5600 iteration loss is 1.342525544604318\n",
      "at 5600 iteration loss is 1.0837378765405181\n",
      "at 5600 iteration loss is 1.2446188066683894\n",
      "at 5600 iteration loss is 1.3473586607982464\n",
      "at 5600 iteration loss is 1.058614511488325\n",
      "at 5600 iteration loss is 1.335819994754813\n",
      "at 5600 iteration loss is 1.641805568952749\n",
      "at 5600 iteration loss is 1.2310136797649684\n",
      "at 5600 iteration loss is 1.0021469279636175\n",
      "at 5700 iteration loss is 1.0493363071479358\n",
      "at 5700 iteration loss is 1.2732526576260714\n",
      "at 5700 iteration loss is 1.1604902648606688\n",
      "at 5700 iteration loss is 1.367008646020487\n",
      "at 5700 iteration loss is 1.027106788204325\n",
      "at 5700 iteration loss is 1.3337391711174353\n",
      "at 5700 iteration loss is 1.1573159903344414\n",
      "at 5700 iteration loss is 1.2911564222519298\n",
      "at 5700 iteration loss is 1.041507275770968\n",
      "at 5700 iteration loss is 1.342554772894062\n",
      "at 5700 iteration loss is 1.0837306663762345\n",
      "at 5700 iteration loss is 1.2446298310553097\n",
      "at 5700 iteration loss is 1.3473752548318323\n",
      "at 5700 iteration loss is 1.0586164039328831\n",
      "at 5700 iteration loss is 1.3358133135826704\n",
      "at 5700 iteration loss is 1.6418645101159757\n",
      "at 5700 iteration loss is 1.2310293289404333\n",
      "at 5700 iteration loss is 1.0021488983962583\n",
      "at 5800 iteration loss is 1.0493233721926996\n",
      "at 5800 iteration loss is 1.2732640011759149\n",
      "at 5800 iteration loss is 1.1604995631969408\n",
      "at 5800 iteration loss is 1.3670216522024874\n",
      "at 5800 iteration loss is 1.0271066401262177\n",
      "at 5800 iteration loss is 1.3337469887697844\n",
      "at 5800 iteration loss is 1.157310405540533\n",
      "at 5800 iteration loss is 1.2911728108934777\n",
      "at 5800 iteration loss is 1.041506674169995\n",
      "at 5800 iteration loss is 1.3425806153829032\n",
      "at 5800 iteration loss is 1.0837242904586266\n",
      "at 5800 iteration loss is 1.2446395829024348\n",
      "at 5800 iteration loss is 1.3473899256933155\n",
      "at 5800 iteration loss is 1.0586180819353999\n",
      "at 5800 iteration loss is 1.3358074085014955\n",
      "at 5800 iteration loss is 1.6419166335258122\n",
      "at 5800 iteration loss is 1.2310431702674998\n",
      "at 5800 iteration loss is 1.0021506403487606\n",
      "at 5900 iteration loss is 1.0493119390384857\n",
      "at 5900 iteration loss is 1.273274028377422\n",
      "at 5900 iteration loss is 1.1605077822634071\n",
      "at 5900 iteration loss is 1.3670331481396247\n",
      "at 5900 iteration loss is 1.0271065085345983\n",
      "at 5900 iteration loss is 1.3337538971655627\n",
      "at 5900 iteration loss is 1.1573054670529366\n",
      "at 5900 iteration loss is 1.2911873001111407\n",
      "at 5900 iteration loss is 1.0415061401374757\n",
      "at 5900 iteration loss is 1.3426034643453917\n",
      "at 5900 iteration loss is 1.0837186522261855\n",
      "at 5900 iteration loss is 1.244648209056582\n",
      "at 5900 iteration loss is 1.3474028963513938\n",
      "at 5900 iteration loss is 1.0586195696848397\n",
      "at 5900 iteration loss is 1.335802189238596\n",
      "at 5900 iteration loss is 1.6419627278793427\n",
      "at 5900 iteration loss is 1.2310554125225222\n",
      "at 5900 iteration loss is 1.002152180272562\n",
      "at 6000 iteration loss is 1.0493018331502812\n",
      "at 6000 iteration loss is 1.2732828920641377\n",
      "at 6000 iteration loss is 1.1605150473547408\n",
      "at 6000 iteration loss is 1.3670433092835326\n",
      "at 6000 iteration loss is 1.0271063915712118\n",
      "at 6000 iteration loss is 1.3337600021410834\n",
      "at 6000 iteration loss is 1.1573011000499922\n",
      "at 6000 iteration loss is 1.2912001100966086\n",
      "at 6000 iteration loss is 1.0415056661069688\n",
      "at 6000 iteration loss is 1.3426236666000346\n",
      "at 6000 iteration loss is 1.0837136663022897\n",
      "at 6000 iteration loss is 1.2446558394238534\n",
      "at 6000 iteration loss is 1.3474143639107317\n",
      "at 6000 iteration loss is 1.058620888659283\n",
      "at 6000 iteration loss is 1.3357975760447576\n",
      "at 6000 iteration loss is 1.6420034906132468\n",
      "at 6000 iteration loss is 1.231066240384313\n",
      "at 6000 iteration loss is 1.0021535415674638\n",
      "at 6100 iteration loss is 1.0492929003079392\n",
      "at 6100 iteration loss is 1.2732907273130158\n",
      "at 6100 iteration loss is 1.160521469220484\n",
      "at 6100 iteration loss is 1.3670522906919467\n",
      "at 6100 iteration loss is 1.0271062875942172\n",
      "at 6100 iteration loss is 1.3337653972020505\n",
      "at 6100 iteration loss is 1.157297238378032\n",
      "at 6100 iteration loss is 1.2912114355095619\n",
      "at 6100 iteration loss is 1.0415052453581775\n",
      "at 6100 iteration loss is 1.3426415287774744\n",
      "at 6100 iteration loss is 1.0837092571977986\n",
      "at 6100 iteration loss is 1.2446625889234484\n",
      "at 6100 iteration loss is 1.3474245026145097\n",
      "at 6100 iteration loss is 1.0586220579267505\n",
      "at 6100 iteration loss is 1.335793498462834\n",
      "at 6100 iteration loss is 1.6420395384687296\n",
      "at 6100 iteration loss is 1.2310758172132035\n",
      "at 6100 iteration loss is 1.002154744931141\n",
      "at 6200 iteration loss is 1.049285004235718\n",
      "at 6200 iteration loss is 1.2732976535093339\n",
      "at 6200 iteration loss is 1.1605271457527064\n",
      "at 6200 iteration loss is 1.3670602294005867\n",
      "at 6200 iteration loss is 1.0271061951512297\n",
      "at 6200 iteration loss is 1.3337701649617764\n",
      "at 6200 iteration loss is 1.157293823545876\n",
      "at 6200 iteration loss is 1.291221448438906\n",
      "at 6200 iteration loss is 1.0415048719220685\n",
      "at 6200 iteration loss is 1.3426573219780562\n",
      "at 6200 iteration loss is 1.0837053581645495\n",
      "at 6200 iteration loss is 1.2446685592161926\n",
      "at 6200 iteration loss is 1.3474334664979808\n",
      "at 6200 iteration loss is 1.058623094413191\n",
      "at 6200 iteration loss is 1.3357898942414084\n",
      "at 6200 iteration loss is 1.6420714168322121\n",
      "at 6200 iteration loss is 1.231084287510079\n",
      "at 6200 iteration loss is 1.0021558086692215\n",
      "at 6300 iteration loss is 1.0492780245095992\n",
      "at 6300 iteration loss is 1.2733037761711457\n",
      "at 6300 iteration loss is 1.1605321634781205\n",
      "at 6300 iteration loss is 1.3670672465190001\n",
      "at 6300 iteration loss is 1.0271061129561077\n",
      "at 6300 iteration loss is 1.3337743784114036\n",
      "at 6300 iteration loss is 1.1572908038362608\n",
      "at 6300 iteration loss is 1.2912303010204753\n",
      "at 6300 iteration loss is 1.0415045404967618\n",
      "at 6300 iteration loss is 1.342671285889519\n",
      "at 6300 iteration loss is 1.08370191018212\n",
      "at 6300 iteration loss is 1.2446738402337325\n",
      "at 6300 iteration loss is 1.3474413917336576\n",
      "at 6300 iteration loss is 1.0586240131410993\n",
      "at 6300 iteration loss is 1.3357867083761776\n",
      "at 6300 iteration loss is 1.6420996079938939\n",
      "at 6300 iteration loss is 1.2310917790921194\n",
      "at 6300 iteration loss is 1.002156748970226\n",
      "at 6400 iteration loss is 1.0492718547096032\n",
      "at 6400 iteration loss is 1.273309188561353\n",
      "at 6400 iteration loss is 1.1605365988772425\n",
      "at 6400 iteration loss is 1.367073449082539\n",
      "at 6400 iteration loss is 1.0271060398688978\n",
      "at 6400 iteration loss is 1.3337781020418016\n",
      "at 6400 iteration loss is 1.1572881335205374\n",
      "at 6400 iteration loss is 1.2912381277510856\n",
      "at 6400 iteration loss is 1.0415042463729143\n",
      "at 6400 iteration loss is 1.3426836324274256\n",
      "at 6400 iteration loss is 1.0836988610622815\n",
      "at 6400 iteration loss is 1.2446785115314007\n",
      "at 6400 iteration loss is 1.3474483987040595\n",
      "at 6400 iteration loss is 1.0586248274419134\n",
      "at 6400 iteration loss is 1.335783892263954\n",
      "at 6400 iteration loss is 1.6421245384497525\n",
      "at 6400 iteration loss is 1.2310984050178262\n",
      "at 6400 iteration loss is 1.0021575801492646\n",
      "at 6500 iteration loss is 1.0492664007882073\n",
      "at 6500 iteration loss is 1.273313973112151\n",
      "at 6500 iteration loss is 1.1605405195506053\n",
      "at 6500 iteration loss is 1.367078931688857\n",
      "at 6500 iteration loss is 1.027105974878444\n",
      "at 6500 iteration loss is 1.333781392834482\n",
      "at 6500 iteration loss is 1.1572857721645815\n",
      "at 6500 iteration loss is 1.2912450475341632\n",
      "at 6500 iteration loss is 1.0415039853675208\n",
      "at 6500 iteration loss is 1.3426945489536302\n",
      "at 6500 iteration loss is 1.0836961646574395\n",
      "at 6500 iteration loss is 1.2446826434850808\n",
      "at 6500 iteration loss is 1.3474545938337092\n",
      "at 6500 iteration loss is 1.0586255491449938\n",
      "at 6500 iteration loss is 1.3357814029558615\n",
      "at 6500 iteration loss is 1.6421465853579722\n",
      "at 6500 iteration loss is 1.231104265290177\n",
      "at 6500 iteration loss is 1.0021583148639484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at 6600 iteration loss is 1.0492615796294706\n",
      "at 6600 iteration loss is 1.2733182026837324\n",
      "at 6600 iteration loss is 1.1605439852496804\n",
      "at 6600 iteration loss is 1.3670837779440004\n",
      "at 6600 iteration loss is 1.0271059170872459\n",
      "at 6600 iteration loss is 1.3337843011368575\n",
      "at 6600 iteration loss is 1.1572836840153002\n",
      "at 6600 iteration loss is 1.2912511654880698\n",
      "at 6600 iteration loss is 1.0415037537651473\n",
      "at 6600 iteration loss is 1.3427042011217083\n",
      "at 6600 iteration loss is 1.083693780160924\n",
      "at 6600 iteration loss is 1.2446862983500508\n",
      "at 6600 iteration loss is 1.3474600712083915\n",
      "at 6600 iteration loss is 1.058626188745731\n",
      "at 6600 iteration loss is 1.335779202498069\n",
      "at 6600 iteration loss is 1.642166082247789\n",
      "at 6600 iteration loss is 1.2311094483634017\n",
      "at 6600 iteration loss is 1.0021589643056334\n",
      "at 6700 iteration loss is 1.0492573177764204\n",
      "at 6700 iteration loss is 1.273321941676555\n",
      "at 6700 iteration loss is 1.1605470487882048\n",
      "at 6700 iteration loss is 1.3670880617402685\n",
      "at 6700 iteration loss is 1.0271058656982486\n",
      "at 6700 iteration loss is 1.3337868714353518\n",
      "at 6700 iteration loss is 1.1572818374583247\n",
      "at 6700 iteration loss is 1.2912565745446765\n",
      "at 6700 iteration loss is 1.041503548265749\n",
      "at 6700 iteration loss is 1.3427127353925783\n",
      "at 6700 iteration loss is 1.0836916714884521\n",
      "at 6700 iteration loss is 1.2446895311977202\n",
      "at 6700 iteration loss is 1.347464914006406\n",
      "at 6700 iteration loss is 1.058626755555014\n",
      "at 6700 iteration loss is 1.3357772573496518\n",
      "at 6700 iteration loss is 1.6421833240674548\n",
      "at 6700 iteration loss is 1.231114032476017\n",
      "at 6700 iteration loss is 1.0021595383687516\n",
      "at 6800 iteration loss is 1.049253550306973\n",
      "at 6800 iteration loss is 1.2733252470142513\n",
      "at 6800 iteration loss is 1.1605497568477507\n",
      "at 6800 iteration loss is 1.3670918483854322\n",
      "at 6800 iteration loss is 1.0271058200032726\n",
      "at 6800 iteration loss is 1.3337891430383255\n",
      "at 6800 iteration loss is 1.1572802045386184\n",
      "at 6800 iteration loss is 1.2912613568625209\n",
      "at 6800 iteration loss is 1.0415033659383353\n",
      "at 6800 iteration loss is 1.3427202812585686\n",
      "at 6800 iteration loss is 1.083689806731313\n",
      "at 6800 iteration loss is 1.2446923907443548\n",
      "at 6800 iteration loss is 1.3474691957636806\n",
      "at 6800 iteration loss is 1.0586272578321299\n",
      "at 6800 iteration loss is 1.335775537868558\n",
      "at 6800 iteration loss is 1.6421985716478946\n",
      "at 6800 iteration loss is 1.2311180868301184\n",
      "at 6800 iteration loss is 1.0021600458007165\n",
      "at 6900 iteration loss is 1.0492502198409812\n",
      "at 6900 iteration loss is 1.2733281690122236\n",
      "at 6900 iteration loss is 1.160552150689783\n",
      "at 6900 iteration loss is 1.3670951956005961\n",
      "at 6900 iteration loss is 1.0271057793728744\n",
      "at 6900 iteration loss is 1.333791150679324\n",
      "at 6900 iteration loss is 1.1572787605366808\n",
      "at 6900 iteration loss is 1.2912655850760426\n",
      "at 6900 iteration loss is 1.0415032041797967\n",
      "at 6900 iteration loss is 1.3427269532097053\n",
      "at 6900 iteration loss is 1.08368815767294\n",
      "at 6900 iteration loss is 1.244694920084217\n",
      "at 6900 iteration loss is 1.3474729814920525\n",
      "at 6900 iteration loss is 1.0586277029028675\n",
      "at 6900 iteration loss is 1.335774017857633\n",
      "at 6900 iteration loss is 1.642212055649729\n",
      "at 6900 iteration loss is 1.231121672634625\n",
      "at 6900 iteration loss is 1.0021604943345999\n",
      "at 7000 iteration loss is 1.0492472756630373\n",
      "at 7000 iteration loss is 1.273330752145253\n",
      "at 7000 iteration loss is 1.1605542667850581\n",
      "at 7000 iteration loss is 1.3670981544019907\n",
      "at 7000 iteration loss is 1.0271057432474036\n",
      "at 7000 iteration loss is 1.333792925049968\n",
      "at 7000 iteration loss is 1.1572774835938788\n",
      "at 7000 iteration loss is 1.2912693233999224\n",
      "at 7000 iteration loss is 1.0415030606783389\n",
      "at 7000 iteration loss is 1.3427328524720956\n",
      "at 7000 iteration loss is 1.083686699361507\n",
      "at 7000 iteration loss is 1.2446971573381564\n",
      "at 7000 iteration loss is 1.3474763286677547\n",
      "at 7000 iteration loss is 1.0586280972644677\n",
      "at 7000 iteration loss is 1.335772674163629\n",
      "at 7000 iteration loss is 1.6422239800535166\n",
      "at 7000 iteration loss is 1.231124844028159\n",
      "at 7000 iteration loss is 1.0021608908065236\n",
      "at 7100 iteration loss is 1.0492446729475051\n",
      "at 7100 iteration loss is 1.273333035725878\n",
      "at 7100 iteration loss is 1.1605561373699613\n",
      "at 7100 iteration loss is 1.3671007698802444\n",
      "at 7100 iteration loss is 1.0271057111291602\n",
      "at 7100 iteration loss is 1.3337944932707277\n",
      "at 7100 iteration loss is 1.1572763543812123\n",
      "at 7100 iteration loss is 1.2912726286053555\n",
      "at 7100 iteration loss is 1.0415029333809869\n",
      "at 7100 iteration loss is 1.342738068544873\n",
      "at 7100 iteration loss is 1.0836854097320467\n",
      "at 7100 iteration loss is 1.2446991362274107\n",
      "at 7100 iteration loss is 1.347479288105232\n",
      "at 7100 iteration loss is 1.058628446678873\n",
      "at 7100 iteration loss is 1.3357714863230576\n",
      "at 7100 iteration loss is 1.6422345252461341\n",
      "at 7100 iteration loss is 1.231127648895449\n",
      "at 7100 iteration loss is 1.0021612412595364\n",
      "at 7200 iteration loss is 1.0492423720738167\n",
      "at 7200 iteration loss is 1.2733350545039133\n",
      "at 7200 iteration loss is 1.1605577909382216\n",
      "at 7200 iteration loss is 1.3671030818890024\n",
      "at 7200 iteration loss is 1.0271056825754397\n",
      "at 7200 iteration loss is 1.3337958793067821\n",
      "at 7200 iteration loss is 1.1572753558064572\n",
      "at 7200 iteration loss is 1.291275550883073\n",
      "at 7200 iteration loss is 1.0415028204647139\n",
      "at 7200 iteration loss is 1.342742680558986\n",
      "at 7200 iteration loss is 1.0836842692723383\n",
      "at 7200 iteration loss is 1.2447008865812124\n",
      "at 7200 iteration loss is 1.3474819047295565\n",
      "at 7200 iteration loss is 1.0586287562555463\n",
      "at 7200 iteration loss is 1.3357704362492904\n",
      "at 7200 iteration loss is 1.642243850750008\n",
      "at 7200 iteration loss is 1.2311301295895025\n",
      "at 7200 iteration loss is 1.0021615510354944\n",
      "at 7300 iteration loss is 1.0492403380214963\n",
      "at 7300 iteration loss is 1.2733368391962903\n",
      "at 7300 iteration loss is 1.1605592526755408\n",
      "at 7300 iteration loss is 1.3671051256534867\n",
      "at 7300 iteration loss is 1.027105657192398\n",
      "at 7300 iteration loss is 1.3337971043354209\n",
      "at 7300 iteration loss is 1.1572744727552338\n",
      "at 7300 iteration loss is 1.2912781346062894\n",
      "at 7300 iteration loss is 1.0415027203107758\n",
      "at 7300 iteration loss is 1.3427467584785298\n",
      "at 7300 iteration loss is 1.0836832607274869\n",
      "at 7300 iteration loss is 1.2447024347858509\n",
      "at 7300 iteration loss is 1.3474842182592377\n",
      "at 7300 iteration loss is 1.0586290305250228\n",
      "at 7300 iteration loss is 1.3357695079561636\n",
      "at 7300 iteration loss is 1.642252097636586\n",
      "at 7300 iteration loss is 1.2311323235704297\n",
      "at 7300 iteration loss is 1.0021618248563278\n",
      "at 7400 iteration loss is 1.0492385398355981\n",
      "at 7400 iteration loss is 1.2733384169553401\n",
      "at 7400 iteration loss is 1.1605605448437504\n",
      "at 7400 iteration loss is 1.367106932308295\n",
      "at 7400 iteration loss is 1.0271056346296237\n",
      "at 7400 iteration loss is 1.3337981870706141\n",
      "at 7400 iteration loss is 1.157273691862074\n",
      "at 7400 iteration loss is 1.2912804190051694\n",
      "at 7400 iteration loss is 1.0415026314819122\n",
      "at 7400 iteration loss is 1.3427503641628602\n",
      "at 7400 iteration loss is 1.083682368838714\n",
      "at 7400 iteration loss is 1.2447038041819485\n",
      "at 7400 iteration loss is 1.3474862638098428\n",
      "at 7400 iteration loss is 1.0586292735042306\n",
      "at 7400 iteration loss is 1.3357686873137786\n",
      "at 7400 iteration loss is 1.6422593906605851\n",
      "at 7400 iteration loss is 1.2311342639705378\n",
      "at 7400 iteration loss is 1.0021620668959221\n",
      "at 7500 iteration loss is 1.0492369501543561\n",
      "at 7500 iteration loss is 1.2733398117826589\n",
      "at 7500 iteration loss is 1.1605616871203404\n",
      "at 7500 iteration loss is 1.3671085293726866\n",
      "at 7500 iteration loss is 1.0271056145753272\n",
      "at 7500 iteration loss is 1.3337991440497734\n",
      "at 7500 iteration loss is 1.1572730013079982\n",
      "at 7500 iteration loss is 1.2912824387630726\n",
      "at 7500 iteration loss is 1.0415025527020796\n",
      "at 7500 iteration loss is 1.342753552305621\n",
      "at 7500 iteration loss is 1.0836815801123898\n",
      "at 7500 iteration loss is 1.244705015415897\n",
      "at 7500 iteration loss is 1.3474880724275917\n",
      "at 7500 iteration loss is 1.0586294887544754\n",
      "at 7500 iteration loss is 1.3357679618327407\n",
      "at 7500 iteration loss is 1.6422658401473214\n",
      "at 7500 iteration loss is 1.2311359800941777\n",
      "at 7500 iteration loss is 1.002162280843675\n",
      "at 7600 iteration loss is 1.0492355447917738\n",
      "at 7600 iteration loss is 1.273341044894888\n",
      "at 7600 iteration loss is 1.1605626968985632\n",
      "at 7600 iteration loss is 1.3671099411705927\n",
      "at 7600 iteration loss is 1.0271055967520695\n",
      "at 7600 iteration loss is 1.3337999898870845\n",
      "at 7600 iteration loss is 1.1572723906415372\n",
      "at 7600 iteration loss is 1.2912842245436598\n",
      "at 7600 iteration loss is 1.041502482838442\n",
      "at 7600 iteration loss is 1.342756371264947\n",
      "at 7600 iteration loss is 1.0836808826158015\n",
      "at 7600 iteration loss is 1.2447060867507649\n",
      "at 7600 iteration loss is 1.3474896715610754\n",
      "at 7600 iteration loss is 1.0586296794329204\n",
      "at 7600 iteration loss is 1.335767320473519\n",
      "at 7600 iteration loss is 1.6422715436617117\n",
      "at 7600 iteration loss is 1.2311374978598892\n",
      "at 7600 iteration loss is 1.0021624699607057\n",
      "at 7700 iteration loss is 1.0492343023687585\n",
      "at 7700 iteration loss is 1.2733421350470118\n",
      "at 7700 iteration loss is 1.1605635895526811\n",
      "at 7700 iteration loss is 1.3671111892018177\n",
      "at 7700 iteration loss is 1.027105580912966\n",
      "at 7700 iteration loss is 1.3338007374973386\n",
      "at 7700 iteration loss is 1.1572718506204713\n",
      "at 7700 iteration loss is 1.2912858034568706\n",
      "at 7700 iteration loss is 1.0415024208853672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at 7700 iteration loss is 1.3427588637974728\n",
      "at 7700 iteration loss is 1.0836802657965592\n",
      "at 7700 iteration loss is 1.2447070343413325\n",
      "at 7700 iteration loss is 1.3474910854782673\n",
      "at 7700 iteration loss is 1.0586298483382774\n",
      "at 7700 iteration loss is 1.3357667534779807\n",
      "at 7700 iteration loss is 1.6422765874842036\n",
      "at 7700 iteration loss is 1.231138840191497\n",
      "at 7700 iteration loss is 1.0021626371295371\n",
      "at 7800 iteration loss is 1.0492332039871497\n",
      "at 7800 iteration loss is 1.273343098818099\n",
      "at 7800 iteration loss is 1.1605643786724071\n",
      "at 7800 iteration loss is 1.3671122924701045\n",
      "at 7800 iteration loss is 1.0271055668383382\n",
      "at 7800 iteration loss is 1.3338013982936912\n",
      "at 7800 iteration loss is 1.1572713730718969\n",
      "at 7800 iteration loss is 1.2912871994708843\n",
      "at 7800 iteration loss is 1.041502365950202\n",
      "at 7800 iteration loss is 1.342761067707285\n",
      "at 7800 iteration loss is 1.0836797203229067\n",
      "at 7800 iteration loss is 1.2447078724774034\n",
      "at 7800 iteration loss is 1.3474923356351838\n",
      "at 7800 iteration loss is 1.0586299979513591\n",
      "at 7800 iteration loss is 1.3357662522205493\n",
      "at 7800 iteration loss is 1.6422810479159824\n",
      "at 7800 iteration loss is 1.2311400273640445\n",
      "at 7800 iteration loss is 1.0021627848980479\n",
      "at 7900 iteration loss is 1.0492322329416361\n",
      "at 7900 iteration loss is 1.273343950863857\n",
      "at 7900 iteration loss is 1.1605650762701079\n",
      "at 7900 iteration loss is 1.3671132677730433\n",
      "at 7900 iteration loss is 1.0271055543327032\n",
      "at 7900 iteration loss is 1.3338019823623788\n",
      "at 7900 iteration loss is 1.1572709507684853\n",
      "at 7900 iteration loss is 1.2912884337762902\n",
      "at 7900 iteration loss is 1.041502317240634\n",
      "at 7900 iteration loss is 1.3427630164196709\n",
      "at 7900 iteration loss is 1.0836792379425073\n",
      "at 7900 iteration loss is 1.2447086137990389\n",
      "at 7900 iteration loss is 1.347493441001792\n",
      "at 7900 iteration loss is 1.0586301304710635\n",
      "at 7900 iteration loss is 1.3357658090766464\n",
      "at 7900 iteration loss is 1.6422849924331928\n",
      "at 7900 iteration loss is 1.2311410773097797\n",
      "at 7900 iteration loss is 1.0021629155183\n",
      "at 8000 iteration loss is 1.0492313744651534\n",
      "at 8000 iteration loss is 1.2733447041398593\n",
      "at 8000 iteration loss is 1.1605656929639574\n",
      "at 8000 iteration loss is 1.367114129958314\n",
      "at 8000 iteration loss is 1.0271055432221268\n",
      "at 8000 iteration loss is 1.3338024986171015\n",
      "at 8000 iteration loss is 1.1572705773190735\n",
      "at 8000 iteration loss is 1.291289525108057\n",
      "at 8000 iteration loss is 1.0415022740534612\n",
      "at 8000 iteration loss is 1.342764739488398\n",
      "at 8000 iteration loss is 1.0836788113575766\n",
      "at 8000 iteration loss is 1.2447092694869697\n",
      "at 8000 iteration loss is 1.347494418350141\n",
      "at 8000 iteration loss is 1.0586302478463063\n",
      "at 8000 iteration loss is 1.3357654173064506\n",
      "at 8000 iteration loss is 1.642288480707662\n",
      "at 8000 iteration loss is 1.2311420058888136\n",
      "at 8000 iteration loss is 1.0021630309808873\n",
      "at 8100 iteration loss is 1.049230615503872\n",
      "at 8100 iteration loss is 1.2733453700988495\n",
      "at 8100 iteration loss is 1.1605662381398\n",
      "at 8100 iteration loss is 1.367114892150142\n",
      "at 8100 iteration loss is 1.0271055333518475\n",
      "at 8100 iteration loss is 1.3338029549354204\n",
      "at 8100 iteration loss is 1.1572702470719067\n",
      "at 8100 iteration loss is 1.2912904900301534\n",
      "at 8100 iteration loss is 1.0415022357646087\n",
      "at 8100 iteration loss is 1.3427662630442012\n",
      "at 8100 iteration loss is 1.0836784341144556\n",
      "at 8100 iteration loss is 1.244709849431025\n",
      "at 8100 iteration loss is 1.3474952825090738\n",
      "at 8100 iteration loss is 1.0586303518043447\n",
      "at 8100 iteration loss is 1.335765070952159\n",
      "at 8100 iteration loss is 1.6422915655095474\n",
      "at 8100 iteration loss is 1.2311428271285014\n",
      "at 8100 iteration loss is 1.0021631330452838\n",
      "at 8200 iteration loss is 1.049229944518323\n",
      "at 8200 iteration loss is 1.273345958865141\n",
      "at 8200 iteration loss is 1.1605667200942305\n",
      "at 8200 iteration loss is 1.367115565949439\n",
      "at 8200 iteration loss is 1.0271055245841811\n",
      "at 8200 iteration loss is 1.3338033582792872\n",
      "at 8200 iteration loss is 1.1572699550290926\n",
      "at 8200 iteration loss is 1.2912913431871853\n",
      "at 8200 iteration loss is 1.0415022018202664\n",
      "at 8200 iteration loss is 1.342767610191323\n",
      "at 8200 iteration loss is 1.0836781005059695\n",
      "at 8200 iteration loss is 1.2447103623791418\n",
      "at 8200 iteration loss is 1.347496046589428\n",
      "at 8200 iteration loss is 1.058630443875919\n",
      "at 8200 iteration loss is 1.3357647647472009\n",
      "at 8200 iteration loss is 1.64229429350559\n",
      "at 8200 iteration loss is 1.2311435534352024\n",
      "at 8200 iteration loss is 1.0021632232666844\n",
      "at 8300 iteration loss is 1.0492293513076318\n",
      "at 8300 iteration loss is 1.2733464793887603\n",
      "at 8300 iteration loss is 1.1605671461610438\n",
      "at 8300 iteration loss is 1.3671161616106886\n",
      "at 8300 iteration loss is 1.0271055167966328\n",
      "at 8300 iteration loss is 1.3338037148015245\n",
      "at 8300 iteration loss is 1.1572696967709426\n",
      "at 8300 iteration loss is 1.291292097526847\n",
      "at 8300 iteration loss is 1.0415021717290105\n",
      "at 8300 iteration loss is 1.342768801358093\n",
      "at 8300 iteration loss is 1.0836778054850753\n",
      "at 8300 iteration loss is 1.244710816069167\n",
      "at 8300 iteration loss is 1.3474967221831178\n",
      "at 8300 iteration loss is 1.0586305254175354\n",
      "at 8300 iteration loss is 1.3357644940359834\n",
      "at 8300 iteration loss is 1.6422967059650326\n",
      "at 8300 iteration loss is 1.231144195781551\n",
      "at 8300 iteration loss is 1.002163303019716\n",
      "at 8400 iteration loss is 1.0492288268541627\n",
      "at 8400 iteration loss is 1.2733469395817043\n",
      "at 8400 iteration loss is 1.1605675228230137\n",
      "at 8400 iteration loss is 1.3671166881982908\n",
      "at 8400 iteration loss is 1.0271055098802417\n",
      "at 8400 iteration loss is 1.333804029939934\n",
      "at 8400 iteration loss is 1.1572694683890812\n",
      "at 8400 iteration loss is 1.2912927644965937\n",
      "at 8400 iteration loss is 1.0415021450548045\n",
      "at 8400 iteration loss is 1.3427698546069013\n",
      "at 8400 iteration loss is 1.0836775445885058\n",
      "at 8400 iteration loss is 1.2447112173454635\n",
      "at 8400 iteration loss is 1.3474973195391475\n",
      "at 8400 iteration loss is 1.058630597631248\n",
      "at 8400 iteration loss is 1.3357642547029804\n",
      "at 8400 iteration loss is 1.6422988393838913\n",
      "at 8400 iteration loss is 1.2311447638721238\n",
      "at 8400 iteration loss is 1.0021633735194129\n",
      "at 8500 iteration loss is 1.0492283631862036\n",
      "at 8500 iteration loss is 1.2733473464383724\n",
      "at 8500 iteration loss is 1.16056785581067\n",
      "at 8500 iteration loss is 1.3671171537247315\n",
      "at 8500 iteration loss is 1.0271055037380847\n",
      "at 8500 iteration loss is 1.3338043085004376\n",
      "at 8500 iteration loss is 1.1572692664272783\n",
      "at 8500 iteration loss is 1.2912933542175058\n",
      "at 8500 iteration loss is 1.041502121410778\n",
      "at 8500 iteration loss is 1.3427707859082507\n",
      "at 8500 iteration loss is 1.0836773138692393\n",
      "at 8500 iteration loss is 1.2447115722620417\n",
      "at 8500 iteration loss is 1.3474978477192159\n",
      "at 8500 iteration loss is 1.0586306615821903\n",
      "at 8500 iteration loss is 1.3357640431100453\n",
      "at 8500 iteration loss is 1.642300726037019\n",
      "at 8500 iteration loss is 1.2311452662899467\n",
      "at 8500 iteration loss is 1.0021634358397382\n",
      "at 8600 iteration loss is 1.0492279532566022\n",
      "at 8600 iteration loss is 1.2733477061420275\n",
      "at 8600 iteration loss is 1.160568150189631\n",
      "at 8600 iteration loss is 1.3671175652727114\n",
      "at 8600 iteration loss is 1.0271054982839605\n",
      "at 8600 iteration loss is 1.333804554730546\n",
      "at 8600 iteration loss is 1.1572690878291505\n",
      "at 8600 iteration loss is 1.2912938756380057\n",
      "at 8600 iteration loss is 1.0415021004537133\n",
      "at 8600 iteration loss is 1.3427716093830686\n",
      "at 8600 iteration loss is 1.0836771098367897\n",
      "at 8600 iteration loss is 1.2447118861738145\n",
      "at 8600 iteration loss is 1.3474983147352928\n",
      "at 8600 iteration loss is 1.058630718214135\n",
      "at 8600 iteration loss is 1.3357638560410132\n",
      "at 8600 iteration loss is 1.64230239446633\n",
      "at 8600 iteration loss is 1.2311457106260968\n",
      "at 8600 iteration loss is 1.0021634909299746\n",
      "at 8700 iteration loss is 1.0492275908354867\n",
      "at 8700 iteration loss is 1.2733480241588935\n",
      "at 8700 iteration loss is 1.1605684104377763\n",
      "at 8700 iteration loss is 1.3671179291030824\n",
      "at 8700 iteration loss is 1.0271054934412034\n",
      "at 8700 iteration loss is 1.3338047723842816\n",
      "at 8700 iteration loss is 1.1572689298918921\n",
      "at 8700 iteration loss is 1.2912943366697582\n",
      "at 8700 iteration loss is 1.0415020818791318\n",
      "at 8700 iteration loss is 1.3427723375169376\n",
      "at 8700 iteration loss is 1.0836769294043989\n",
      "at 8700 iteration loss is 1.244712163817295\n",
      "at 8700 iteration loss is 1.3474987276712453\n",
      "at 8700 iteration loss is 1.0586307683632805\n",
      "at 8700 iteration loss is 1.335763690652732\n",
      "at 8700 iteration loss is 1.642303869912542\n",
      "at 8700 iteration loss is 1.231146103594321\n",
      "at 8700 iteration loss is 1.002163539629197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at 8800 iteration loss is 1.049227270415447\n",
      "at 8800 iteration loss is 1.2733483053213384\n",
      "at 8800 iteration loss is 1.160568640513461\n",
      "at 8800 iteration loss is 1.3671182507502582\n",
      "at 8800 iteration loss is 1.0271054891416458\n",
      "at 8800 iteration loss is 1.3338049647795538\n",
      "at 8800 iteration loss is 1.1572687902253758\n",
      "at 8800 iteration loss is 1.2912947443078047\n",
      "at 8800 iteration loss is 1.041502065416944\n",
      "at 8800 iteration loss is 1.3427729813495175\n",
      "at 8800 iteration loss is 1.0836767698423388\n",
      "at 8800 iteration loss is 1.244712409382001\n",
      "at 8800 iteration loss is 1.3474990927903698\n",
      "at 8800 iteration loss is 1.0586308127704864\n",
      "at 8800 iteration loss is 1.335763544431779\n",
      "at 8800 iteration loss is 1.6423051746969926\n",
      "at 8800 iteration loss is 1.2311464511324162\n",
      "at 8800 iteration loss is 1.0021635826790727\n",
      "at 8900 iteration loss is 1.0492269871277191\n",
      "at 8900 iteration loss is 1.2733485539013971\n",
      "at 8900 iteration loss is 1.1605688439158175\n",
      "at 8900 iteration loss is 1.3671185351065247\n",
      "at 8900 iteration loss is 1.0271054853246706\n",
      "at 8900 iteration loss is 1.3338051348488424\n",
      "at 8900 iteration loss is 1.1572686667159762\n",
      "at 8900 iteration loss is 1.2912951047367864\n",
      "at 8900 iteration loss is 1.0415020508275805\n",
      "at 8900 iteration loss is 1.3427735506420087\n",
      "at 8900 iteration loss is 1.0836766287366153\n",
      "at 8900 iteration loss is 1.244712626573603\n",
      "at 8900 iteration loss is 1.3474994156304643\n",
      "at 8900 iteration loss is 1.0586308520921148\n",
      "at 8900 iteration loss is 1.3357634151562046\n",
      "at 8900 iteration loss is 1.642306328559291\n",
      "at 8900 iteration loss is 1.2311467584918965\n",
      "at 8900 iteration loss is 1.002163620735169\n",
      "at 9000 iteration loss is 1.049226736668094\n",
      "at 9000 iteration loss is 1.2733487736757634\n",
      "at 9000 iteration loss is 1.1605690237380455\n",
      "at 9000 iteration loss is 1.36711878649658\n",
      "at 9000 iteration loss is 1.0271054819363852\n",
      "at 9000 iteration loss is 1.333805285184003\n",
      "at 9000 iteration loss is 1.1572685574945785\n",
      "at 9000 iteration loss is 1.2912954234248466\n",
      "at 9000 iteration loss is 1.0415020378985482\n",
      "at 9000 iteration loss is 1.3427740540252315\n",
      "at 9000 iteration loss is 1.083676503952446\n",
      "at 9000 iteration loss is 1.244712818669789\n",
      "at 9000 iteration loss is 1.347499701087876\n",
      "at 9000 iteration loss is 1.0586308869096401\n",
      "at 9000 iteration loss is 1.3357633008617205\n",
      "at 9000 iteration loss is 1.6423073489559143\n",
      "at 9000 iteration loss is 1.2311470303172958\n",
      "at 9000 iteration loss is 1.0021636543769556\n",
      "at 9100 iteration loss is 1.049226515231441\n",
      "at 9100 iteration loss is 1.2733489679832548\n",
      "at 9100 iteration loss is 1.1605691827145292\n",
      "at 9100 iteration loss is 1.3671190087434149\n",
      "at 9100 iteration loss is 1.027105478928886\n",
      "at 9100 iteration loss is 1.3338054180758578\n",
      "at 9100 iteration loss is 1.1572684609083026\n",
      "at 9100 iteration loss is 1.2912957052066654\n",
      "at 9100 iteration loss is 1.0415020264413968\n",
      "at 9100 iteration loss is 1.3427744991305501\n",
      "at 9100 iteration loss is 1.083676393601974\n",
      "at 9100 iteration loss is 1.2447129885696915\n",
      "at 9100 iteration loss is 1.347499953491824\n",
      "at 9100 iteration loss is 1.0586309177381834\n",
      "at 9100 iteration loss is 1.3357631998118098\n",
      "at 9100 iteration loss is 1.6423082513242886\n",
      "at 9100 iteration loss is 1.2311472707163276\n",
      "at 9100 iteration loss is 1.002163684116641\n",
      "at 9200 iteration loss is 1.0492263194538027\n",
      "at 9200 iteration loss is 1.2733491397755785\n",
      "at 9200 iteration loss is 1.1605693232624652\n",
      "at 9200 iteration loss is 1.3671192052265209\n",
      "at 9200 iteration loss is 1.027105476259583\n",
      "at 9200 iteration loss is 1.3338055355491663\n",
      "at 9200 iteration loss is 1.157268375495471\n",
      "at 9200 iteration loss is 1.2912959543568396\n",
      "at 9200 iteration loss is 1.041502016288991\n",
      "at 9200 iteration loss is 1.3427748927056165\n",
      "at 9200 iteration loss is 1.083676296015692\n",
      "at 9200 iteration loss is 1.2447131388375845\n",
      "at 9200 iteration loss is 1.3475001766700885\n",
      "at 9200 iteration loss is 1.058630945034056\n",
      "at 9200 iteration loss is 1.3357631104712935\n",
      "at 9200 iteration loss is 1.642309049316293\n",
      "at 9200 iteration loss is 1.231147483321905\n",
      "at 9200 iteration loss is 1.002163710406973\n",
      "at 9300 iteration loss is 1.049226146361247\n",
      "at 9300 iteration loss is 1.273349291662246\n",
      "at 9300 iteration loss is 1.1605694475186739\n",
      "at 9300 iteration loss is 1.3671193789333806\n",
      "at 9300 iteration loss is 1.027105473890632\n",
      "at 9300 iteration loss is 1.333805639393562\n",
      "at 9300 iteration loss is 1.157268299963506\n",
      "at 9300 iteration loss is 1.2912961746547953\n",
      "at 9300 iteration loss is 1.0415020072931216\n",
      "at 9300 iteration loss is 1.3427752407167244\n",
      "at 9300 iteration loss is 1.0836762097172041\n",
      "at 9300 iteration loss is 1.244713271741563\n",
      "at 9300 iteration loss is 1.3475003740071105\n",
      "at 9300 iteration loss is 1.0586309692014688\n",
      "at 9300 iteration loss is 1.335763031482999\n",
      "at 9300 iteration loss is 1.6423097550047898\n",
      "at 9300 iteration loss is 1.2311476713470244\n",
      "at 9300 iteration loss is 1.002163733648159\n",
      "at 9400 iteration loss is 1.0492259933246124\n",
      "at 9400 iteration loss is 1.273349425950243\n",
      "at 9400 iteration loss is 1.1605695573721337\n",
      "at 9400 iteration loss is 1.36711953250494\n",
      "at 9400 iteration loss is 1.0271054717883945\n",
      "at 9400 iteration loss is 1.3338057311908529\n",
      "at 9400 iteration loss is 1.1572682331693556\n",
      "at 9400 iteration loss is 1.2912963694421504\n",
      "at 9400 iteration loss is 1.0415019993223649\n",
      "at 9400 iteration loss is 1.3427755484392994\n",
      "at 9400 iteration loss is 1.0836761334008793\n",
      "at 9400 iteration loss is 1.2447133892877384\n",
      "at 9400 iteration loss is 1.3475005484953422\n",
      "at 9400 iteration loss is 1.058630990598461\n",
      "at 9400 iteration loss is 1.335762961647091\n",
      "at 9400 iteration loss is 1.642310379066248\n",
      "at 9400 iteration loss is 1.2311478376332943\n",
      "at 9400 iteration loss is 1.0021637541939508\n",
      "at 9500 iteration loss is 1.049225858019538\n",
      "at 9500 iteration loss is 1.2733495446791188\n",
      "at 9500 iteration loss is 1.1605696544927344\n",
      "at 9500 iteration loss is 1.3671196682758275\n",
      "at 9500 iteration loss is 1.0271054699229791\n",
      "at 9500 iteration loss is 1.333805812339179\n",
      "at 9500 iteration loss is 1.1572681741022008\n",
      "at 9500 iteration loss is 1.2912965416734417\n",
      "at 9500 iteration loss is 1.0415019922601856\n",
      "at 9500 iteration loss is 1.3427758205379063\n",
      "at 9500 iteration loss is 1.0836760659121007\n",
      "at 9500 iteration loss is 1.2447134932504942\n",
      "at 9500 iteration loss is 1.3475007027806591\n",
      "at 9500 iteration loss is 1.0586310095421658\n",
      "at 9500 iteration loss is 1.335762899902839\n",
      "at 9500 iteration loss is 1.6423109309422539\n",
      "at 9500 iteration loss is 1.2311479846938567\n",
      "at 9500 iteration loss is 1.0021637723570467\n",
      "at 9600 iteration loss is 1.0492257383911117\n",
      "at 9600 iteration loss is 1.2733496496519963\n",
      "at 9600 iteration loss is 1.1605697403566948\n",
      "at 9600 iteration loss is 1.3671197883098931\n",
      "at 9600 iteration loss is 1.0271054682678264\n",
      "at 9600 iteration loss is 1.3338058840743439\n",
      "at 9600 iteration loss is 1.157268121868159\n",
      "at 9600 iteration loss is 1.2912966939609678\n",
      "at 9600 iteration loss is 1.0415019860032622\n",
      "at 9600 iteration loss is 1.3427760611369917\n",
      "at 9600 iteration loss is 1.0836760062298048\n",
      "at 9600 iteration loss is 1.2447135851992472\n",
      "at 9600 iteration loss is 1.347500839202502\n",
      "at 9600 iteration loss is 1.0586310263134766\n",
      "at 9600 iteration loss is 1.3357628453124808\n",
      "at 9600 iteration loss is 1.642311418982335\n",
      "at 9600 iteration loss is 1.2311481147513472\n",
      "at 9600 iteration loss is 1.0021637884138561\n",
      "at 9700 iteration loss is 1.0492256326226237\n",
      "at 9700 iteration loss is 1.2733497424629854\n",
      "at 9700 iteration loss is 1.160569816269038\n",
      "at 9700 iteration loss is 1.3671198944316303\n",
      "at 9700 iteration loss is 1.0271054667993416\n",
      "at 9700 iteration loss is 1.3338059474886772\n",
      "at 9700 iteration loss is 1.1572680756767522\n",
      "at 9700 iteration loss is 1.291296828614449\n",
      "at 9700 iteration loss is 1.0415019804599868\n",
      "at 9700 iteration loss is 1.3427762738834361\n",
      "at 9700 iteration loss is 1.0836759534510265\n",
      "at 9700 iteration loss is 1.2447136665221203\n",
      "at 9700 iteration loss is 1.3475009598293775\n",
      "at 9700 iteration loss is 1.0586310411611746\n",
      "at 9700 iteration loss is 1.3357627970469605\n",
      "at 9700 iteration loss is 1.642311850570276\n",
      "at 9700 iteration loss is 1.2311482297714804\n",
      "at 9700 iteration loss is 1.0021638026087112\n",
      "at 9800 iteration loss is 1.0492255391079515\n",
      "at 9800 iteration loss is 1.27334982452142\n",
      "at 9800 iteration loss is 1.1605698833834437\n",
      "at 9800 iteration loss is 1.3671199882539362\n",
      "at 9800 iteration loss is 1.0271054654965641\n",
      "at 9800 iteration loss is 1.3338060035476973\n",
      "at 9800 iteration loss is 1.157268034828949\n",
      "at 9800 iteration loss is 1.2912969476760667\n",
      "at 9800 iteration loss is 1.041501975549148\n",
      "at 9800 iteration loss is 1.3427764620018556\n",
      "at 9800 iteration loss is 1.0836759067772461\n",
      "at 9800 iteration loss is 1.2447137384468783\n",
      "at 9800 iteration loss is 1.3475010664902356\n",
      "at 9800 iteration loss is 1.0586310543055997\n",
      "at 9800 iteration loss is 1.3357627543733297\n",
      "at 9800 iteration loss is 1.642312232235811\n",
      "at 9800 iteration loss is 1.2311483314927352\n",
      "at 9800 iteration loss is 1.002163815157593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at 9900 iteration loss is 1.0492254564271377\n",
      "at 9900 iteration loss is 1.2733498970732817\n",
      "at 9900 iteration loss is 1.1605699427198117\n",
      "at 9900 iteration loss is 1.3671200712026692\n",
      "at 9900 iteration loss is 1.027105464340872\n",
      "at 9900 iteration loss is 1.3338060531048412\n",
      "at 9900 iteration loss is 1.157267998706584\n",
      "at 9900 iteration loss is 1.291297052951468\n",
      "at 9900 iteration loss is 1.041501971198749\n",
      "at 9900 iteration loss is 1.3427766283434999\n",
      "at 9900 iteration loss is 1.0836758655023027\n",
      "at 9900 iteration loss is 1.2447138020594506\n",
      "at 9900 iteration loss is 1.3475011608022203\n",
      "at 9900 iteration loss is 1.0586310659418907\n",
      "at 9900 iteration loss is 1.335762716643593\n",
      "at 9900 iteration loss is 1.6423125697534104\n",
      "at 9900 iteration loss is 1.2311484214526272\n",
      "at 9900 iteration loss is 1.00216382625142\n",
      "at 0 iteration loss is 1.3325444766753378\n",
      "at 0 iteration loss is 1.5867590163926109\n",
      "at 0 iteration loss is 1.5379566660810453\n",
      "at 0 iteration loss is 0.7952490573386687\n",
      "at 0 iteration loss is 0.38879842713802165\n",
      "at 0 iteration loss is 1.0907852225012538\n",
      "at 0 iteration loss is 1.236897192317611\n",
      "at 0 iteration loss is 1.0414844486726738\n",
      "at 0 iteration loss is 1.15437936809866\n",
      "at 0 iteration loss is 1.0086833813462386\n",
      "at 0 iteration loss is 1.1740243303686664\n",
      "at 0 iteration loss is 1.0892652114612047\n",
      "at 0 iteration loss is 1.1284806666360314\n",
      "at 0 iteration loss is 0.9765963659269072\n",
      "at 0 iteration loss is 1.1491102926285275\n",
      "at 0 iteration loss is 1.103964698978962\n",
      "at 0 iteration loss is 1.0482940117933213\n",
      "at 0 iteration loss is 0.9163345926826612\n",
      "at 100 iteration loss is 1.2294079517481808\n",
      "at 100 iteration loss is 1.1318154105361509\n",
      "at 100 iteration loss is 1.062623059044583\n",
      "at 100 iteration loss is 1.2194208326233995\n",
      "at 100 iteration loss is 1.023137115691708\n",
      "at 100 iteration loss is 1.2881323670602023\n",
      "at 100 iteration loss is 1.2261510599321592\n",
      "at 100 iteration loss is 1.0977320806824187\n",
      "at 100 iteration loss is 1.065619154711459\n",
      "at 100 iteration loss is 1.1246079719426911\n",
      "at 100 iteration loss is 1.1855551285468136\n",
      "at 100 iteration loss is 1.1052452781221287\n",
      "at 100 iteration loss is 1.1983656797319342\n",
      "at 100 iteration loss is 1.0084389856775862\n",
      "at 100 iteration loss is 1.3791333173751874\n",
      "at 100 iteration loss is 1.1546952723763686\n",
      "at 100 iteration loss is 1.1025356429943431\n",
      "at 100 iteration loss is 1.022741513186015\n",
      "at 200 iteration loss is 1.1960195449704174\n",
      "at 200 iteration loss is 1.1572308987806796\n",
      "at 200 iteration loss is 1.0893944700711717\n",
      "at 200 iteration loss is 1.2572727010915419\n",
      "at 200 iteration loss is 1.0243774068049194\n",
      "at 200 iteration loss is 1.2982806219724714\n",
      "at 200 iteration loss is 1.2180806949230747\n",
      "at 200 iteration loss is 1.1274473796976068\n",
      "at 200 iteration loss is 1.0645954186206497\n",
      "at 200 iteration loss is 1.161362022309602\n",
      "at 200 iteration loss is 1.1735146814271469\n",
      "at 200 iteration loss is 1.1335564153984063\n",
      "at 200 iteration loss is 1.2227616471209533\n",
      "at 200 iteration loss is 1.0201238435911537\n",
      "at 200 iteration loss is 1.3828639540908128\n",
      "at 200 iteration loss is 1.220361454175168\n",
      "at 200 iteration loss is 1.14065904730812\n",
      "at 200 iteration loss is 1.0229881254170798\n",
      "at 300 iteration loss is 1.1702959589698145\n",
      "at 300 iteration loss is 1.1758595298802155\n",
      "at 300 iteration loss is 1.106034377284282\n",
      "at 300 iteration loss is 1.2819027497979893\n",
      "at 300 iteration loss is 1.0236894489170714\n",
      "at 300 iteration loss is 1.3066104992416263\n",
      "at 300 iteration loss is 1.211221538847493\n",
      "at 300 iteration loss is 1.1498288558210887\n",
      "at 300 iteration loss is 1.0628980103504762\n",
      "at 300 iteration loss is 1.1902171815210092\n",
      "at 300 iteration loss is 1.1641052418239675\n",
      "at 300 iteration loss is 1.1531329734690272\n",
      "at 300 iteration loss is 1.2417693221491422\n",
      "at 300 iteration loss is 1.0265112551643163\n",
      "at 300 iteration loss is 1.3809298600074036\n",
      "at 300 iteration loss is 1.2771117198138335\n",
      "at 300 iteration loss is 1.1655233845415878\n",
      "at 300 iteration loss is 1.022565583503952\n",
      "at 400 iteration loss is 1.1500757379170115\n",
      "at 400 iteration loss is 1.1898793794521012\n",
      "at 400 iteration loss is 1.116770767287715\n",
      "at 400 iteration loss is 1.2988206587421036\n",
      "at 400 iteration loss is 1.0222820296572628\n",
      "at 400 iteration loss is 1.3135210332014227\n",
      "at 400 iteration loss is 1.2052038050440537\n",
      "at 400 iteration loss is 1.1669658079488403\n",
      "at 400 iteration loss is 1.0610010928075877\n",
      "at 400 iteration loss is 1.2135220196762129\n",
      "at 400 iteration loss is 1.1563739042669743\n",
      "at 400 iteration loss is 1.1670873336566738\n",
      "at 400 iteration loss is 1.257065507146185\n",
      "at 400 iteration loss is 1.0301266162010967\n",
      "at 400 iteration loss is 1.3766038636816005\n",
      "at 400 iteration loss is 1.3261743776291985\n",
      "at 400 iteration loss is 1.1824468817364546\n",
      "at 400 iteration loss is 1.021769491677927\n",
      "at 500 iteration loss is 1.1338908573771405\n",
      "at 500 iteration loss is 1.2008123297662188\n",
      "at 500 iteration loss is 1.1241549943912794\n",
      "at 500 iteration loss is 1.3112195742637254\n",
      "at 500 iteration loss is 1.02072097439129\n",
      "at 500 iteration loss is 1.3193668209092446\n",
      "at 500 iteration loss is 1.1999123354495622\n",
      "at 500 iteration loss is 1.1805044038901058\n",
      "at 500 iteration loss is 1.059182788415087\n",
      "at 500 iteration loss is 1.232913419703343\n",
      "at 500 iteration loss is 1.1498771820690294\n",
      "at 500 iteration loss is 1.1775111080640603\n",
      "at 500 iteration loss is 1.269709381780049\n",
      "at 500 iteration loss is 1.0323114586175497\n",
      "at 500 iteration loss is 1.3715569937589858\n",
      "at 500 iteration loss is 1.3687340278578197\n",
      "at 500 iteration loss is 1.1946560369859682\n",
      "at 500 iteration loss is 1.0209040031095478\n",
      "at 600 iteration loss is 1.1207353985919828\n",
      "at 600 iteration loss is 1.2096286797764009\n",
      "at 600 iteration loss is 1.1296235222109212\n",
      "at 600 iteration loss is 1.320866187271615\n",
      "at 600 iteration loss is 1.0192562342429312\n",
      "at 600 iteration loss is 1.3243938109331368\n",
      "at 600 iteration loss is 1.1952804303154605\n",
      "at 600 iteration loss is 1.1915488291777718\n",
      "at 600 iteration loss is 1.0575637926845274\n",
      "at 600 iteration loss is 1.2494334983554087\n",
      "at 600 iteration loss is 1.1443601630386784\n",
      "at 600 iteration loss is 1.185668023150584\n",
      "at 600 iteration loss is 1.2803716900164612\n",
      "at 600 iteration loss is 1.033757521355926\n",
      "at 600 iteration loss is 1.3665766771038306\n",
      "at 600 iteration loss is 1.4057778613121692\n",
      "at 600 iteration loss is 1.2040075974917295\n",
      "at 600 iteration loss is 1.0201397869293038\n",
      "at 700 iteration loss is 1.1099050099529904\n",
      "at 700 iteration loss is 1.2169336608827472\n",
      "at 700 iteration loss is 1.1339589432074675\n",
      "at 700 iteration loss is 1.3287304682345007\n",
      "at 700 iteration loss is 1.0179814290932887\n",
      "at 700 iteration loss is 1.328765247575163\n",
      "at 700 iteration loss is 1.1912435549964298\n",
      "at 700 iteration loss is 1.2008021179683106\n",
      "at 700 iteration loss is 1.056176306056177\n",
      "at 700 iteration loss is 1.2637382775586823\n",
      "at 700 iteration loss is 1.1396477833234697\n",
      "at 700 iteration loss is 1.19230066008231\n",
      "at 700 iteration loss is 1.2894900867557926\n",
      "at 700 iteration loss is 1.034815778412867\n",
      "at 700 iteration loss is 1.3619961887867238\n",
      "at 700 iteration loss is 1.4381090773850975\n",
      "at 700 iteration loss is 1.2115484532994232\n",
      "at 700 iteration loss is 1.0195424846849932\n",
      "at 800 iteration loss is 1.1008940911508858\n",
      "at 800 iteration loss is 1.2231091124517386\n",
      "at 800 iteration loss is 1.1375813962904586\n",
      "at 800 iteration loss is 1.3353539969028863\n",
      "at 800 iteration loss is 1.0169154896623214\n",
      "at 800 iteration loss is 1.3325928081941967\n",
      "at 800 iteration loss is 1.1877349078913153\n",
      "at 800 iteration loss is 1.2087094509841512\n",
      "at 800 iteration loss is 1.0550106164675621\n",
      "at 800 iteration loss is 1.2762532969214406\n",
      "at 800 iteration loss is 1.135606565620248\n",
      "at 800 iteration loss is 1.197848846282801\n",
      "at 800 iteration loss is 1.2973631096648657\n",
      "at 800 iteration loss is 1.035662032382416\n",
      "at 800 iteration loss is 1.3579258078287766\n",
      "at 800 iteration loss is 1.466386135688746\n",
      "at 800 iteration loss is 1.2178682587860337\n",
      "at 800 iteration loss is 1.0191186667978103\n",
      "at 900 iteration loss is 1.0933308978211234\n",
      "at 900 iteration loss is 1.2284036689160545\n",
      "at 900 iteration loss is 1.140716261612663\n",
      "at 900 iteration loss is 1.3410508244716322\n",
      "at 900 iteration loss is 1.0160444135158593\n",
      "at 900 iteration loss is 1.335957580272002\n",
      "at 900 iteration loss is 1.1846890104267713\n",
      "at 900 iteration loss is 1.215559063957682\n",
      "at 900 iteration loss is 1.0540406264228803\n",
      "at 900 iteration loss is 1.2872700416325198\n",
      "at 900 iteration loss is 1.132129602729678\n",
      "at 900 iteration loss is 1.2025812034850953\n",
      "at 900 iteration loss is 1.3042048104528843\n",
      "at 900 iteration loss is 1.0363832296364788\n",
      "at 900 iteration loss is 1.3543717810770524\n",
      "at 900 iteration loss is 1.4911566598679145\n",
      "at 900 iteration loss is 1.2233044885975084\n",
      "at 900 iteration loss is 1.018847961088694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at 1000 iteration loss is 1.0869360956647462\n",
      "at 1000 iteration loss is 1.2329865383863416\n",
      "at 1000 iteration loss is 1.143486420037449\n",
      "at 1000 iteration loss is 1.3460137817164564\n",
      "at 1000 iteration loss is 1.0153420824160613\n",
      "at 1000 iteration loss is 1.3389222087024177\n",
      "at 1000 iteration loss is 1.1820449915872087\n",
      "at 1000 iteration loss is 1.2215453705952355\n",
      "at 1000 iteration loss is 1.0532363753022695\n",
      "at 1000 iteration loss is 1.2970015365755039\n",
      "at 1000 iteration loss is 1.1291294321716692\n",
      "at 1000 iteration loss is 1.2066697205438424\n",
      "at 1000 iteration loss is 1.3101762065893758\n",
      "at 1000 iteration loss is 1.0370218672168687\n",
      "at 1000 iteration loss is 1.3512958547525948\n",
      "at 1000 iteration loss is 1.5128822265438553\n",
      "at 1000 iteration loss is 1.2280571407184546\n",
      "at 1000 iteration loss is 1.0187011042444731\n",
      "at 1100 iteration loss is 1.0814957133868137\n",
      "at 1100 iteration loss is 1.2369787484863628\n",
      "at 1100 iteration loss is 1.1459616868323022\n",
      "at 1100 iteration loss is 1.3503700643499412\n",
      "at 1100 iteration loss is 1.0147801589375336\n",
      "at 1100 iteration loss is 1.3415375763375508\n",
      "at 1100 iteration loss is 1.1797482825830694\n",
      "at 1100 iteration loss is 1.226806476841773\n",
      "at 1100 iteration loss is 1.0525695527309997\n",
      "at 1100 iteration loss is 1.3056133927840274\n",
      "at 1100 iteration loss is 1.1265338090687858\n",
      "at 1100 iteration loss is 1.2102310422607732\n",
      "at 1100 iteration loss is 1.3154035203796788\n",
      "at 1100 iteration loss is 1.0375986230934904\n",
      "at 1100 iteration loss is 1.348644242148447\n",
      "at 1100 iteration loss is 1.5319559586261775\n",
      "at 1100 iteration loss is 1.2322514977117525\n",
      "at 1100 iteration loss is 1.0186487936495754\n",
      "at 1200 iteration loss is 1.0768430600060066\n",
      "at 1200 iteration loss is 1.2404711821021634\n",
      "at 1200 iteration loss is 1.1481847851349283\n",
      "at 1200 iteration loss is 1.3542102271675271\n",
      "at 1200 iteration loss is 1.0143324001004226\n",
      "at 1200 iteration loss is 1.3438464646055002\n",
      "at 1200 iteration loss is 1.1777510677590055\n",
      "at 1200 iteration loss is 1.231445965404211\n",
      "at 1200 iteration loss is 1.0520155124469004\n",
      "at 1200 iteration loss is 1.313240956705563\n",
      "at 1200 iteration loss is 1.1242827318996897\n",
      "at 1200 iteration loss is 1.2133491934394347\n",
      "at 1200 iteration loss is 1.3199889698801355\n",
      "at 1200 iteration loss is 1.0381237633554847\n",
      "at 1200 iteration loss is 1.3463611478558088\n",
      "at 1200 iteration loss is 1.5487152198826926\n",
      "at 1200 iteration loss is 1.2359719794984274\n",
      "at 1200 iteration loss is 1.0186653847743916\n",
      "at 1300 iteration loss is 1.0728463447248835\n",
      "at 1300 iteration loss is 1.2435350527312166\n",
      "at 1300 iteration loss is 1.1501847416001645\n",
      "at 1300 iteration loss is 1.35760337802262\n",
      "at 1300 iteration loss is 1.0139762046441163\n",
      "at 1300 iteration loss is 1.3458856237595125\n",
      "at 1300 iteration loss is 1.1760120122381719\n",
      "at 1300 iteration loss is 1.235545450375853\n",
      "at 1300 iteration loss is 1.051553656589146\n",
      "at 1300 iteration loss is 1.319998833179009\n",
      "at 1300 iteration loss is 1.122326154163845\n",
      "at 1300 iteration loss is 1.216088148084371\n",
      "at 1300 iteration loss is 1.324017355262495\n",
      "at 1300 iteration loss is 1.038602800336864\n",
      "at 1300 iteration loss is 1.3443946118636174\n",
      "at 1300 iteration loss is 1.5634510850042802\n",
      "at 1300 iteration loss is 1.2392802161224103\n",
      "at 1300 iteration loss is 1.0187299644780832\n",
      "at 1400 iteration loss is 1.0694000108111683\n",
      "at 1400 iteration loss is 1.246228092351479\n",
      "at 1400 iteration loss is 1.1519836479148098\n",
      "at 1400 iteration loss is 1.3606052349975903\n",
      "at 1400 iteration loss is 1.0136928564126921\n",
      "at 1400 iteration loss is 1.3476870188341463\n",
      "at 1400 iteration loss is 1.1744956475009518\n",
      "at 1400 iteration loss is 1.2391718419412354\n",
      "at 1400 iteration loss is 1.0511671335446122\n",
      "at 1400 iteration loss is 1.3259862963586766\n",
      "at 1400 iteration loss is 1.1206221606988813\n",
      "at 1400 iteration loss is 1.2184988809032307\n",
      "at 1400 iteration loss is 1.3275602460919336\n",
      "at 1400 iteration loss is 1.039039227551351\n",
      "at 1400 iteration loss is 1.3426986166169048\n",
      "at 1400 iteration loss is 1.5764156608785747\n",
      "at 1400 iteration loss is 1.2422246233991814\n",
      "at 1400 iteration loss is 1.0188262130123091\n",
      "at 1500 iteration loss is 1.0664185448417478\n",
      "at 1500 iteration loss is 1.2485983075340417\n",
      "at 1500 iteration loss is 1.1535999788706117\n",
      "at 1500 iteration loss is 1.3632624916589022\n",
      "at 1500 iteration loss is 1.01346720684419\n",
      "at 1500 iteration loss is 1.349278645233798\n",
      "at 1500 iteration loss is 1.1731716431996329\n",
      "at 1500 iteration loss is 1.2423816158003522\n",
      "at 1500 iteration loss is 1.050842302664647\n",
      "at 1500 iteration loss is 1.3312905040181024\n",
      "at 1500 iteration loss is 1.1191354987994686\n",
      "at 1500 iteration loss is 1.220623418441083\n",
      "at 1500 iteration loss is 1.330678773050703\n",
      "at 1500 iteration loss is 1.0394357854191818\n",
      "at 1500 iteration loss is 1.341233442495548\n",
      "at 1500 iteration loss is 1.587827924935897\n",
      "at 1500 iteration loss is 1.2448454550139165\n",
      "at 1500 iteration loss is 1.0189417895597295\n",
      "at 1600 iteration loss is 1.0638319718935962\n",
      "at 1600 iteration loss is 1.2506863458252304\n",
      "at 1600 iteration loss is 1.1550501576904484\n",
      "at 1600 iteration loss is 1.3656152662929035\n",
      "at 1600 iteration loss is 1.0132871622820598\n",
      "at 1600 iteration loss is 1.3506851124861101\n",
      "at 1600 iteration loss is 1.172014085938015\n",
      "at 1600 iteration loss is 1.2452233947526457\n",
      "at 1600 iteration loss is 1.0505681705357264\n",
      "at 1600 iteration loss is 1.335988540358899\n",
      "at 1600 iteration loss is 1.1178363926763286\n",
      "at 1600 iteration loss is 1.222497248372833\n",
      "at 1600 iteration loss is 1.333425584871828\n",
      "at 1600 iteration loss is 1.0397950026002871\n",
      "at 1600 iteration loss is 1.3399652601155114\n",
      "at 1600 iteration loss is 1.5978784940970148\n",
      "at 1600 iteration loss is 1.2471774733368304\n",
      "at 1600 iteration loss is 1.0190675989818314\n",
      "at 1700 iteration loss is 1.06158252218874\n",
      "at 1700 iteration loss is 1.2525270559746882\n",
      "at 1700 iteration loss is 1.1563492531903241\n",
      "at 1700 iteration loss is 1.3676985500584955\n",
      "at 1700 iteration loss is 1.013143147076707\n",
      "at 1700 iteration loss is 1.3519280955619766\n",
      "at 1700 iteration loss is 1.171000820727479\n",
      "at 1700 iteration loss is 1.2477395778241045\n",
      "at 1700 iteration loss is 1.050335881583353\n",
      "at 1700 iteration loss is 1.340148828357603\n",
      "at 1700 iteration loss is 1.1166995863520341\n",
      "at 1700 iteration loss is 1.2241508196839566\n",
      "at 1700 iteration loss is 1.3358462874132822\n",
      "at 1700 iteration loss is 1.040119391598193\n",
      "at 1700 iteration loss is 1.338865442007537\n",
      "at 1700 iteration loss is 1.606733588424475\n",
      "at 1700 iteration loss is 1.2492513820317281\n",
      "at 1700 iteration loss is 1.0191970986963679\n",
      "at 1800 iteration loss is 1.0596221267341395\n",
      "at 1800 iteration loss is 1.2541505696776483\n",
      "at 1800 iteration loss is 1.1575112645188455\n",
      "at 1800 iteration loss is 1.3695431255871175\n",
      "at 1800 iteration loss is 1.0130276150108226\n",
      "at 1800 iteration loss is 1.3530267038555466\n",
      "at 1800 iteration loss is 1.170112874924337\n",
      "at 1800 iteration loss is 1.2499674272924468\n",
      "at 1800 iteration loss is 1.05013828848564\n",
      "at 1800 iteration loss is 1.3438321937989033\n",
      "at 1800 iteration loss is 1.1157035702942397\n",
      "at 1800 iteration loss is 1.22561053007685\n",
      "at 1800 iteration loss is 1.33798054719513\n",
      "at 1800 iteration loss is 1.0404114886396976\n",
      "at 1800 iteration loss is 1.3379098209149687\n",
      "at 1800 iteration loss is 1.614538365606823\n",
      "at 1800 iteration loss is 1.2510946238506289\n",
      "at 1800 iteration loss is 1.0193257047611326\n",
      "at 1900 iteration loss is 1.0579105095043928\n",
      "at 1900 iteration loss is 1.2555830901768212\n",
      "at 1900 iteration loss is 1.1585492232727674\n",
      "at 1900 iteration loss is 1.3711761992485123\n",
      "at 1900 iteration loss is 1.0129346333931184\n",
      "at 1900 iteration loss is 1.353997793686684\n",
      "at 1900 iteration loss is 1.1693339661804032\n",
      "at 1900 iteration loss is 1.2519398415404694\n",
      "at 1900 iteration loss is 1.0499696026723668\n",
      "at 1900 iteration loss is 1.3470927266201085\n",
      "at 1900 iteration loss is 1.1148299551736447\n",
      "at 1900 iteration loss is 1.2268994162302485\n",
      "at 1900 iteration loss is 1.3398629669124678\n",
      "at 1900 iteration loss is 1.0406738310561003\n",
      "at 1900 iteration loss is 1.3370779943449738\n",
      "at 1900 iteration loss is 1.621419749749105\n",
      "at 1900 iteration loss is 1.2527318580551314\n",
      "at 1900 iteration loss is 1.0194503089572335\n",
      "at 2000 iteration loss is 1.0564137155142472\n",
      "at 2000 iteration loss is 1.2568474939049534\n",
      "at 2000 iteration loss is 1.1594752251139313\n",
      "at 2000 iteration loss is 1.3726218727501123\n",
      "at 2000 iteration loss is 1.0128595418117228\n",
      "at 2000 iteration loss is 1.3548562383590885\n",
      "at 2000 iteration loss is 1.16865008761257\n",
      "at 2000 iteration loss is 1.2536859401362461\n",
      "at 2000 iteration loss is 1.0498251154689027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at 2000 iteration loss is 1.349978514202609\n",
      "at 2000 iteration loss is 1.1140629630517747\n",
      "at 2000 iteration loss is 1.2280376653030096\n",
      "at 2000 iteration loss is 1.3415237983973842\n",
      "at 2000 iteration loss is 1.0409089161634237\n",
      "at 2000 iteration loss is 1.3363527124241104\n",
      "at 2000 iteration loss is 1.6274888453297507\n",
      "at 2000 iteration loss is 1.254185278605735\n",
      "at 2000 iteration loss is 1.0195688983236466\n",
      "at 2100 iteration loss is 1.055102961894168\n",
      "at 2100 iteration loss is 1.257963807166534\n",
      "at 2100 iteration loss is 1.1603004426986776\n",
      "at 2100 iteration loss is 1.373901519258083\n",
      "at 2100 iteration loss is 1.012798678196641\n",
      "at 2100 iteration loss is 1.355615164030353\n",
      "at 2100 iteration loss is 1.1680491603638434\n",
      "at 2100 iteration loss is 1.2552315313887563\n",
      "at 2100 iteration loss is 1.049700977875015\n",
      "at 2100 iteration loss is 1.3525322849217207\n",
      "at 2100 iteration loss is 1.1133890121939707\n",
      "at 2100 iteration loss is 1.2290430135849248\n",
      "at 2100 iteration loss is 1.342989534495084\n",
      "at 2100 iteration loss is 1.0411191609695074\n",
      "at 2100 iteration loss is 1.3357193565038594\n",
      "at 2100 iteration loss is 1.6328430060092256\n",
      "at 2100 iteration loss is 1.255474853824552\n",
      "at 2100 iteration loss is 1.0196802615073846\n",
      "at 2200 iteration loss is 1.0539537314288092\n",
      "at 2200 iteration loss is 1.2589495950317766\n",
      "at 2200 iteration loss is 1.1610351415469595\n",
      "at 2200 iteration loss is 1.3750340981669869\n",
      "at 2200 iteration loss is 1.0127491618392583\n",
      "at 2200 iteration loss is 1.3562861567924154\n",
      "at 2200 iteration loss is 1.1675207433322026\n",
      "at 2200 iteration loss is 1.2565995017364158\n",
      "at 2200 iteration loss is 1.0495940274532143\n",
      "at 2200 iteration loss is 1.3547919820398724\n",
      "at 2200 iteration loss is 1.112796376598972\n",
      "at 2200 iteration loss is 1.2299310697297086\n",
      "at 2200 iteration loss is 1.3442834073036498\n",
      "at 2200 iteration loss is 1.0413068699864623\n",
      "at 2200 iteration loss is 1.335165502923066\n",
      "at 2200 iteration loss is 1.6375676134717694\n",
      "at 2200 iteration loss is 1.25661852664881\n",
      "at 2200 iteration loss is 1.0197837653471429\n",
      "at 2300 iteration loss is 1.052945050285788\n",
      "at 2300 iteration loss is 1.2598202855168181\n",
      "at 2300 iteration loss is 1.1616887059394458\n",
      "at 2300 iteration loss is 1.3760364267400589\n",
      "at 2300 iteration loss is 1.0127087229335294\n",
      "at 2300 iteration loss is 1.356879444895315\n",
      "at 2300 iteration loss is 1.1670557906369539\n",
      "at 2300 iteration loss is 1.2578101494048781\n",
      "at 2300 iteration loss is 1.0495016523914469\n",
      "at 2300 iteration loss is 1.35679127910261\n",
      "at 2300 iteration loss is 1.1122749053124314\n",
      "at 2300 iteration loss is 1.2307155844617481\n",
      "at 2300 iteration loss is 1.3454258118073044\n",
      "at 2300 iteration loss is 1.041474212800418\n",
      "at 2300 iteration loss is 1.3346805614591166\n",
      "at 2300 iteration loss is 1.6417376110126365\n",
      "at 2300 iteration loss is 1.2576323935323404\n",
      "at 2300 iteration loss is 1.019879186716775\n",
      "at 2400 iteration loss is 1.0520589072252955\n",
      "at 2400 iteration loss is 1.260589443989117\n",
      "at 2400 iteration loss is 1.1622696753778767\n",
      "at 2400 iteration loss is 1.3769234187277362\n",
      "at 2400 iteration loss is 1.0126755693191343\n",
      "at 2400 iteration loss is 1.3574040592391907\n",
      "at 2400 iteration loss is 1.166646448620725\n",
      "at 2400 iteration loss is 1.25888147553045\n",
      "at 2400 iteration loss is 1.0494216846180617\n",
      "at 2400 iteration loss is 1.3585600437528913\n",
      "at 2400 iteration loss is 1.1118157897634737\n",
      "at 2400 iteration loss is 1.2314086800779023\n",
      "at 2400 iteration loss is 1.3464346686936897\n",
      "at 2400 iteration loss is 1.0416232106379884\n",
      "at 2400 iteration loss is 1.334255477001771\n",
      "at 2400 iteration loss is 1.6454188286785023\n",
      "at 2400 iteration loss is 1.2585308697120736\n",
      "at 2400 iteration loss is 1.0199665870822796\n",
      "at 2500 iteration loss is 1.0512797826118214\n",
      "at 2500 iteration loss is 1.2612690079382904\n",
      "at 2500 iteration loss is 1.1627857895606009\n",
      "at 2500 iteration loss is 1.3777082959446203\n",
      "at 2500 iteration loss is 1.0126482825875818\n",
      "at 2500 iteration loss is 1.3578679747612004\n",
      "at 2500 iteration loss is 1.1662858854787406\n",
      "at 2500 iteration loss is 1.2598294409030841\n",
      "at 2500 iteration loss is 1.0493523155193014\n",
      "at 2500 iteration loss is 1.3601247549236772\n",
      "at 2500 iteration loss is 1.1114113698628543\n",
      "at 2500 iteration loss is 1.2320210482708573\n",
      "at 2500 iteration loss is 1.3473257367499707\n",
      "at 2500 iteration loss is 1.0417557303188878\n",
      "at 2500 iteration loss is 1.3338824836983443\n",
      "at 2500 iteration loss is 1.648669130587156\n",
      "at 2500 iteration loss is 1.2593268437219836\n",
      "at 2500 iteration loss is 1.020046219684967\n",
      "at 2600 iteration loss is 1.050594263469178\n",
      "at 2600 iteration loss is 1.261869489337187\n",
      "at 2600 iteration loss is 1.1632440391313577\n",
      "at 2600 iteration loss is 1.3784027766829374\n",
      "at 2600 iteration loss is 1.0126257371773228\n",
      "at 2600 iteration loss is 1.358278234993652\n",
      "at 2600 iteration loss is 1.1659681478002402\n",
      "at 2600 iteration loss is 1.2606681937195785\n",
      "at 2600 iteration loss is 1.0492920292205947\n",
      "at 2600 iteration loss is 1.3615088774851176\n",
      "at 2600 iteration loss is 1.1110549715561764\n",
      "at 2600 iteration loss is 1.2325621220596417\n",
      "at 2600 iteration loss is 1.3481128829333378\n",
      "at 2600 iteration loss is 1.0418734838560906\n",
      "at 2600 iteration loss is 1.3335549021747537\n",
      "at 2600 iteration loss is 1.6515394100960985\n",
      "at 2600 iteration loss is 1.2600318219615954\n",
      "at 2600 iteration loss is 1.0201184614390173\n",
      "at 2700 iteration loss is 1.0499907265746011\n",
      "at 2700 iteration loss is 1.2624001499794768\n",
      "at 2700 iteration loss is 1.163650719597031\n",
      "at 2700 iteration loss is 1.379017243756292\n",
      "at 2700 iteration loss is 1.012607037380009\n",
      "at 2700 iteration loss is 1.358641061793848\n",
      "at 2700 iteration loss is 1.1656880393399134\n",
      "at 2700 iteration loss is 1.2614102722023364\n",
      "at 2700 iteration loss is 1.0492395495301903\n",
      "at 2700 iteration loss is 1.3627331980072583\n",
      "at 2700 iteration loss is 1.110740770048657\n",
      "at 2700 iteration loss is 1.2330402259962858\n",
      "at 2700 iteration loss is 1.3488083165856064\n",
      "at 2700 iteration loss is 1.0419780321387027\n",
      "at 2700 iteration loss is 1.3332669719232562\n",
      "at 2700 iteration loss is 1.654074454446579\n",
      "at 2700 iteration loss is 1.2606560633814652\n",
      "at 2700 iteration loss is 1.0201837634340258\n",
      "at 2800 iteration loss is 1.0494590758155824\n",
      "at 2800 iteration loss is 1.2628691539693317\n",
      "at 2800 iteration loss is 1.1640114862569428\n",
      "at 2800 iteration loss is 1.3795608943876319\n",
      "at 2800 iteration loss is 1.0125914682638006\n",
      "at 2800 iteration loss is 1.3589619520127045\n",
      "at 2800 iteration loss is 1.165441018201263\n",
      "at 2800 iteration loss is 1.2620667850605787\n",
      "at 2800 iteration loss is 1.049193797537039\n",
      "at 2800 iteration loss is 1.3638161250651695\n",
      "at 2800 iteration loss is 1.1104636741033616\n",
      "at 2800 iteration loss is 1.2334627078228597\n",
      "at 2800 iteration loss is 1.3494227930649756\n",
      "at 2800 iteration loss is 1.0420707914054363\n",
      "at 2800 iteration loss is 1.3330137123387602\n",
      "at 2800 iteration loss is 1.6563136971744399\n",
      "at 2800 iteration loss is 1.2612087042050206\n",
      "at 2800 iteration loss is 1.0202426153723247\n",
      "at 2900 iteration loss is 1.048990523171323\n",
      "at 2900 iteration loss is 1.2632837007029092\n",
      "at 2900 iteration loss is 1.1643314084964929\n",
      "at 2900 iteration loss is 1.380041873820434\n",
      "at 2900 iteration loss is 1.0125784573966239\n",
      "at 2900 iteration loss is 1.3592457626640078\n",
      "at 2900 iteration loss is 1.1652231093222898\n",
      "at 2900 iteration loss is 1.2626475722408617\n",
      "at 2900 iteration loss is 1.049153857546401\n",
      "at 2900 iteration loss is 1.3647739573320992\n",
      "at 2900 iteration loss is 1.110219227738461\n",
      "at 2900 iteration loss is 1.2338360541073652\n",
      "at 2900 iteration loss is 1.3499657911564902\n",
      "at 2900 iteration loss is 1.0421530414953124\n",
      "at 2900 iteration loss is 1.3327908070967927\n",
      "at 2900 iteration loss is 1.65829187380711\n",
      "at 2900 iteration loss is 1.2616978727029131\n",
      "at 2900 iteration loss is 1.0202955203948603\n",
      "at 3000 iteration loss is 1.0485774050326608\n",
      "at 3000 iteration loss is 1.2636501410770495\n",
      "at 3000 iteration loss is 1.1646150222661105\n",
      "at 3000 iteration loss is 1.3804673943142292\n",
      "at 3000 iteration loss is 1.0125675449484473\n",
      "at 3000 iteration loss is 1.3594967859734344\n",
      "at 3000 iteration loss is 1.1650308297286194\n",
      "at 3000 iteration loss is 1.2631613480679103\n",
      "at 3000 iteration loss is 1.049118949567704\n",
      "at 3000 iteration loss is 1.3656211225271055\n",
      "at 3000 iteration loss is 1.1100035263707104\n",
      "at 3000 iteration loss is 1.234165991941801\n",
      "at 3000 iteration loss is 1.3504456679087642\n",
      "at 3000 iteration loss is 1.0422259351092422\n",
      "at 3000 iteration loss is 1.332594507580914\n",
      "at 3000 iteration loss is 1.660039594050318\n",
      "at 3000 iteration loss is 1.2621307942010809\n",
      "at 3000 iteration loss is 1.020342977615114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at 3100 iteration loss is 1.0482130273530106\n",
      "at 3100 iteration loss is 1.263974079204998\n",
      "at 3100 iteration loss is 1.1648663799557255\n",
      "at 3100 iteration loss is 1.3808438410226234\n",
      "at 3100 iteration loss is 1.0125583602973631\n",
      "at 3100 iteration loss is 1.3597188155232236\n",
      "at 3100 iteration loss is 1.1648611244827491\n",
      "at 3100 iteration loss is 1.2636158286285442\n",
      "at 3100 iteration loss is 1.0490884069754158\n",
      "at 3100 iteration loss is 1.3663703900916826\n",
      "at 3100 iteration loss is 1.1098131450183113\n",
      "at 3100 iteration loss is 1.2344575784597909\n",
      "at 3100 iteration loss is 1.3508697939729029\n",
      "at 3100 iteration loss is 1.0422905075201179\n",
      "at 3100 iteration loss is 1.3324215518987181\n",
      "at 3100 iteration loss is 1.6615838417262225\n",
      "at 3100 iteration loss is 1.262513886661966\n",
      "at 3100 iteration loss is 1.0203854703416333\n",
      "at 3200 iteration loss is 1.047891534479489\n",
      "at 3200 iteration loss is 1.2642604615630315\n",
      "at 3200 iteration loss is 1.1650890971804526\n",
      "at 3200 iteration loss is 1.3811768661151744\n",
      "at 3200 iteration loss is 1.012550603688805\n",
      "at 3200 iteration loss is 1.3599152045628924\n",
      "at 3200 iteration loss is 1.1647113116312187\n",
      "at 3200 iteration loss is 1.26401784505611\n",
      "at 3200 iteration loss is 1.0490616582741228\n",
      "at 3200 iteration loss is 1.3670330602655354\n",
      "at 3200 iteration loss is 1.1096450766223154\n",
      "at 3200 iteration loss is 1.2347152796794687\n",
      "at 3200 iteration loss is 1.3512446720541562\n",
      "at 3200 iteration loss is 1.0423476863305656\n",
      "at 3200 iteration loss is 1.3322690966976976\n",
      "at 3200 iteration loss is 1.6629484120914277\n",
      "at 3200 iteration loss is 1.2628528473022897\n",
      "at 3200 iteration loss is 1.0204234584717367\n",
      "at 3300 iteration loss is 1.047607797556532\n",
      "at 3300 iteration loss is 1.264513655206144\n",
      "at 3300 iteration loss is 1.165286396223376\n",
      "at 3300 iteration loss is 1.3814714723814618\n",
      "at 3300 iteration loss is 1.0125440318259271\n",
      "at 3300 iteration loss is 1.3600889174272481\n",
      "at 3300 iteration loss is 1.1645790347519014\n",
      "at 3300 iteration loss is 1.264373444207772\n",
      "at 3300 iteration loss is 1.0490382121363617\n",
      "at 3300 iteration loss is 1.36761913202059\n",
      "at 3300 iteration loss is 1.1094966788989744\n",
      "at 3300 iteration loss is 1.2349430399744832\n",
      "at 3300 iteration loss is 1.3515760407032067\n",
      "at 3300 iteration loss is 1.0423983010017566\n",
      "at 3300 iteration loss is 1.3321346595316297\n",
      "at 3300 iteration loss is 1.664154294786104\n",
      "at 3300 iteration loss is 1.2631527307948296\n",
      "at 3300 iteration loss is 1.0204573739188374\n",
      "at 3400 iteration loss is 1.0473573192026724\n",
      "at 3400 iteration loss is 1.264737516456704\n",
      "at 3400 iteration loss is 1.1654611460490818\n",
      "at 3400 iteration loss is 1.3817320874414811\n",
      "at 3400 iteration loss is 1.0125384465231235\n",
      "at 3400 iteration loss is 1.3602425748887996\n",
      "at 3400 iteration loss is 1.1644622219460357\n",
      "at 3400 iteration loss is 1.264687978081096\n",
      "at 3400 iteration loss is 1.0490176450636908\n",
      "at 3400 iteration loss is 1.368137452100995\n",
      "at 3400 iteration loss is 1.1093656284168618\n",
      "at 3400 iteration loss is 1.2351443433075544\n",
      "at 3400 iteration loss is 1.3518689653545615\n",
      "at 3400 iteration loss is 1.042443091970443\n",
      "at 3400 iteration loss is 1.3320160699593204\n",
      "at 3400 iteration loss is 1.665220009501106\n",
      "at 3400 iteration loss is 1.2634180196497353\n",
      "at 3400 iteration loss is 1.020487618222767\n",
      "at 3500 iteration loss is 1.0471361517921438\n",
      "at 3500 iteration loss is 1.2649354512749427\n",
      "at 3500 iteration loss is 1.165615898919849\n",
      "at 3500 iteration loss is 1.3819626295795184\n",
      "at 3500 iteration loss is 1.01253368575045\n",
      "at 3500 iteration loss is 1.360378494170981\n",
      "at 3500 iteration loss is 1.1643590503155998\n",
      "at 3500 iteration loss is 1.2649661831841996\n",
      "at 3500 iteration loss is 1.0489995911612777\n",
      "at 3500 iteration loss is 1.3685958472107917\n",
      "at 3500 iteration loss is 1.109249880818039\n",
      "at 3500 iteration loss is 1.2353222672180482\n",
      "at 3500 iteration loss is 1.3521279182516253\n",
      "at 3500 iteration loss is 1.0424827192406743\n",
      "at 3500 iteration loss is 1.3319114279016788\n",
      "at 3500 iteration loss is 1.666161900463375\n",
      "at 3500 iteration loss is 1.2636526873899336\n",
      "at 3500 iteration loss is 1.0205145617088436\n",
      "at 3600 iteration loss is 1.0469408271691385\n",
      "at 3600 iteration loss is 1.2651104683559942\n",
      "at 3600 iteration loss is 1.165752923726683\n",
      "at 3600 iteration loss is 1.3821665661187688\n",
      "at 3600 iteration loss is 1.0125296165477435\n",
      "at 3600 iteration loss is 1.3604987242601354\n",
      "at 3600 iteration loss is 1.1642679151259447\n",
      "at 3600 iteration loss is 1.2652122509529231\n",
      "at 3600 iteration loss is 1.0489837336241075\n",
      "at 3600 iteration loss is 1.3690012411941805\n",
      "at 3600 iteration loss is 1.109147636284243\n",
      "at 3600 iteration loss is 1.2354795304322077\n",
      "at 3600 iteration loss is 1.3523568486719768\n",
      "at 3600 iteration loss is 1.0425177703871675\n",
      "at 3600 iteration loss is 1.3318190680578317\n",
      "at 3600 iteration loss is 1.6669943950017394\n",
      "at 3600 iteration loss is 1.2638602551324005\n",
      "at 3600 iteration loss is 1.020538543724442\n",
      "at 3700 iteration loss is 1.0467682960153337\n",
      "at 3700 iteration loss is 1.2652652258589732\n",
      "at 3700 iteration loss is 1.1658742361991987\n",
      "at 3700 iteration loss is 1.3823469651612448\n",
      "at 3700 iteration loss is 1.0125261294037693\n",
      "at 3700 iteration loss is 1.3606050770765492\n",
      "at 3700 iteration loss is 1.1641874029833994\n",
      "at 3700 iteration loss is 1.2654298901977434\n",
      "at 3700 iteration loss is 1.0489697976164227\n",
      "at 3700 iteration loss is 1.3693597588686093\n",
      "at 3700 iteration loss is 1.1090573094963947\n",
      "at 3700 iteration loss is 1.2356185348581854\n",
      "at 3700 iteration loss is 1.352559244674673\n",
      "at 3700 iteration loss is 1.0425487679434267\n",
      "at 3700 iteration loss is 1.3317375294007094\n",
      "at 3700 iteration loss is 1.6677302307415363\n",
      "at 3700 iteration loss is 1.2640438421689089\n",
      "at 3700 iteration loss is 1.0205598736045831\n",
      "at 3800 iteration loss is 1.0466158754043278\n",
      "at 3800 iteration loss is 1.2654020725546127\n",
      "at 3800 iteration loss is 1.1659816261891316\n",
      "at 3800 iteration loss is 1.3825065414320268\n",
      "at 3800 iteration loss is 1.0125231337856324\n",
      "at 3800 iteration loss is 1.360699154996714\n",
      "at 3800 iteration loss is 1.1641162684639503\n",
      "at 3800 iteration loss is 1.2656223824617612\n",
      "at 3800 iteration loss is 1.048957544290903\n",
      "at 3800 iteration loss is 1.3696768179995398\n",
      "at 3800 iteration loss is 1.1089775034558227\n",
      "at 3800 iteration loss is 1.235741402635187\n",
      "at 3800 iteration loss is 1.352738187428145\n",
      "at 3800 iteration loss is 1.042576176172915\n",
      "at 3800 iteration loss is 1.331665528948577\n",
      "at 3800 iteration loss is 1.6683806553671172\n",
      "at 3800 iteration loss is 1.2642062111113923\n",
      "at 3800 iteration loss is 1.0205788321103262\n",
      "at 3900 iteration loss is 1.0464812033277242\n",
      "at 3900 iteration loss is 1.2655230840761085\n",
      "at 3900 iteration loss is 1.1660766822379935\n",
      "at 3900 iteration loss is 1.3826476968888035\n",
      "at 3900 iteration loss is 1.0125205545732938\n",
      "at 3900 iteration loss is 1.3607823751593162\n",
      "at 3900 iteration loss is 1.1640534137165806\n",
      "at 3900 iteration loss is 1.2657926310787644\n",
      "at 3900 iteration loss is 1.0489467657447764\n",
      "at 3900 iteration loss is 1.3699572107486109\n",
      "at 3900 iteration loss is 1.1089069866340984\n",
      "at 3900 iteration loss is 1.235850008824983\n",
      "at 3900 iteration loss is 1.3528963990377387\n",
      "at 3900 iteration loss is 1.0426004072388182\n",
      "at 3900 iteration loss is 1.331601939150548\n",
      "at 3900 iteration loss is 1.6689556023699808\n",
      "at 3900 iteration loss is 1.2643498081323987\n",
      "at 3900 iteration loss is 1.0205956731530799\n",
      "at 4000 iteration loss is 1.0463621991803236\n",
      "at 4000 iteration loss is 1.26563009487009\n",
      "at 4000 iteration loss is 1.1661608136443444\n",
      "at 4000 iteration loss is 1.3827725566865345\n",
      "at 4000 iteration loss is 1.0125183292078037\n",
      "at 4000 iteration loss is 1.3608559909352411\n",
      "at 4000 iteration loss is 1.1639978706372787\n",
      "at 4000 iteration loss is 1.2659432046363714\n",
      "at 4000 iteration loss is 1.048937280749861\n",
      "at 4000 iteration loss is 1.37020517578367\n",
      "at 4000 iteration loss is 1.1088446729996293\n",
      "at 4000 iteration loss is 1.2359460102630404\n",
      "at 4000 iteration loss is 1.3530362846723398\n",
      "at 4000 iteration loss is 1.0426218267991678\n",
      "at 4000 iteration loss is 1.3315457683383438\n",
      "at 4000 iteration loss is 1.6694638457529696\n",
      "at 4000 iteration loss is 1.264476798793105\n",
      "at 4000 iteration loss is 1.0206106256699186\n",
      "at 4100 iteration loss is 1.0462570293563922\n",
      "at 4100 iteration loss is 1.2657247263688933\n",
      "at 4100 iteration loss is 1.1662352702437506\n",
      "at 4100 iteration loss is 1.3828830010228277\n",
      "at 4100 iteration loss is 1.0125164054036944\n",
      "at 4100 iteration loss is 1.3609211108960024\n",
      "at 4100 iteration loss is 1.1639487852697246\n",
      "at 4100 iteration loss is 1.2660763754733306\n",
      "at 4100 iteration loss is 1.048928931124772\n",
      "at 4100 iteration loss is 1.3704244621095276\n",
      "at 4100 iteration loss is 1.1087896045364385\n",
      "at 4100 iteration loss is 1.236030871024242\n",
      "at 4100 iteration loss is 1.353159969686609\n",
      "at 4100 iteration loss is 1.042640759060936\n",
      "at 4100 iteration loss is 1.3314961437890003\n",
      "at 4100 iteration loss is 1.6699131362764157\n",
      "at 4100 iteration loss is 1.264589099912126\n",
      "at 4100 iteration loss is 1.0206238955538516\n",
      "at 4200 iteration loss is 1.0461640772435112\n",
      "at 4200 iteration loss is 1.2658084118398434\n",
      "at 4200 iteration loss is 1.1663011601071376\n",
      "at 4200 iteration loss is 1.3829806933316586\n",
      "at 4200 iteration loss is 1.012514739308263\n",
      "at 4200 iteration loss is 1.3609787155749142\n",
      "at 4200 iteration loss is 1.163905404138903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at 4200 iteration loss is 1.2661941537715031\n",
      "at 4200 iteration loss is 1.048921578642424\n",
      "at 4200 iteration loss is 1.3706183855614715\n",
      "at 4200 iteration loss is 1.1087409359266993\n",
      "at 4200 iteration loss is 1.236105884903619\n",
      "at 4200 iteration loss is 1.3532693323466956\n",
      "at 4200 iteration loss is 1.042657491330575\n",
      "at 4200 iteration loss is 1.3314522970185014\n",
      "at 4200 iteration loss is 1.6703103215007236\n",
      "at 4200 iteration loss is 1.2646884078894742\n",
      "at 4200 iteration loss is 1.0206356675719621\n",
      "at 4300 iteration loss is 1.0460819170108961\n",
      "at 4300 iteration loss is 1.2658824183104422\n",
      "at 4300 iteration loss is 1.166359465352755\n",
      "at 4300 iteration loss is 1.3830671052411556\n",
      "at 4300 iteration loss is 1.0125132940158132\n",
      "at 4300 iteration loss is 1.3610296722801185\n",
      "at 4300 iteration loss is 1.1638670622658425\n",
      "at 4300 iteration loss is 1.2662983177414773\n",
      "at 4300 iteration loss is 1.048915102385585\n",
      "at 4300 iteration loss is 1.3707898787987367\n",
      "at 4300 iteration loss is 1.1086979211155517\n",
      "at 4300 iteration loss is 1.236172195264528\n",
      "at 4300 iteration loss is 1.353366032690594\n",
      "at 4300 iteration loss is 1.0426722780999182\n",
      "at 4300 iteration loss is 1.3314135509876963\n",
      "at 4300 iteration loss is 1.6706614515936433\n",
      "at 4300 iteration loss is 1.2647762238623705\n",
      "at 4300 iteration loss is 1.020646107225825\n",
      "at 4400 iteration loss is 1.0460092906802891\n",
      "at 4400 iteration loss is 1.2659478659190135\n",
      "at 4400 iteration loss is 1.1664110562546424\n",
      "at 4400 iteration loss is 1.3831435386646649\n",
      "at 4400 iteration loss is 1.0125120383645139\n",
      "at 4400 iteration loss is 1.3610747481876735\n",
      "at 4400 iteration loss is 1.1638331726470432\n",
      "at 4400 iteration loss is 1.266390440345502\n",
      "at 4400 iteration loss is 1.0489093964790266\n",
      "at 4400 iteration loss is 1.3709415355412893\n",
      "at 4400 iteration loss is 1.1086599015162022\n",
      "at 4400 iteration loss is 1.2362308125646508\n",
      "at 4400 iteration loss is 1.3534515379879344\n",
      "at 4400 iteration loss is 1.0426853447064208\n",
      "at 4400 iteration loss is 1.3313793089522663\n",
      "at 4400 iteration loss is 1.6709718726228118\n",
      "at 4400 iteration loss is 1.2648538760338923\n",
      "at 4400 iteration loss is 1.0206553625244659\n",
      "at 4500 iteration loss is 1.0459450880433399\n",
      "at 4500 iteration loss is 1.2660057449974276\n",
      "at 4500 iteration loss is 1.166456703817214\n",
      "at 4500 iteration loss is 1.383211145352704\n",
      "at 4500 iteration loss is 1.0125109459588488\n",
      "at 4500 iteration loss is 1.361114621915831\n",
      "at 4500 iteration loss is 1.1638032170121053\n",
      "at 4500 iteration loss is 1.2664719129519686\n",
      "at 4500 iteration loss is 1.0489043681394405\n",
      "at 4500 iteration loss is 1.371075649709475\n",
      "at 4500 iteration loss is 1.1086262956467394\n",
      "at 4500 iteration loss is 1.236282629833212\n",
      "at 4500 iteration loss is 1.3535271452063264\n",
      "at 4500 iteration loss is 1.0426968906056737\n",
      "at 4500 iteration loss is 1.3313490447300733\n",
      "at 4500 iteration loss is 1.671246308839357\n",
      "at 4500 iteration loss is 1.2649225394819636\n",
      "at 4500 iteration loss is 1.0206635656517409\n",
      "at 4600 iteration loss is 1.0458883290524736\n",
      "at 4600 iteration loss is 1.2660569311550673\n",
      "at 4600 iteration loss is 1.1664970909720649\n",
      "at 4600 iteration loss is 1.383270944196449\n",
      "at 4600 iteration loss is 1.0125099943726403\n",
      "at 4600 iteration loss is 1.3611498937577688\n",
      "at 4600 iteration loss is 1.1637767376982928\n",
      "at 4600 iteration loss is 1.266543966271487\n",
      "at 4600 iteration loss is 1.048899935994439\n",
      "at 4600 iteration loss is 1.3711942500513805\n",
      "at 4600 iteration loss is 1.1085965900183177\n",
      "at 4600 iteration loss is 1.236328436340249\n",
      "at 4600 iteration loss is 1.3535940008412588\n",
      "at 4600 iteration loss is 1.0427070922923254\n",
      "at 4600 iteration loss is 1.3313222941934995\n",
      "at 4600 iteration loss is 1.6714889352717655\n",
      "at 4600 iteration loss is 1.2649832537252028\n",
      "at 4600 iteration loss is 1.0206708345183924\n",
      "at 4700 iteration loss is 1.0458381483653372\n",
      "at 4700 iteration loss is 1.266102198600579\n",
      "at 4700 iteration loss is 1.166532822539788\n",
      "at 4700 iteration loss is 1.383323836540465\n",
      "at 4700 iteration loss is 1.012509164497088\n",
      "at 4700 iteration loss is 1.3611810947291645\n",
      "at 4700 iteration loss is 1.163753330502483\n",
      "at 4700 iteration loss is 1.2666076888852609\n",
      "at 4700 iteration loss is 1.048896028630261\n",
      "at 4700 iteration loss is 1.371299130776349\n",
      "at 4700 iteration loss is 1.1085703311185464\n",
      "at 4700 iteration loss is 1.236368929670275\n",
      "at 4700 iteration loss is 1.3536531184229184\n",
      "at 4700 iteration loss is 1.0427161059034984\n",
      "at 4700 iteration loss is 1.331298647823058\n",
      "at 4700 iteration loss is 1.6717034417869374\n",
      "at 4700 iteration loss is 1.2650369382936755\n",
      "at 4700 iteration loss is 1.0206772741950993\n",
      "at 4800 iteration loss is 1.0457937817674772\n",
      "at 4800 iteration loss is 1.2661422319093443\n",
      "at 4800 iteration loss is 1.1665644340866874\n",
      "at 4800 iteration loss is 1.3833706197329723\n",
      "at 4800 iteration loss is 1.0125084400054682\n",
      "at 4800 iteration loss is 1.3612086945685176\n",
      "at 4800 iteration loss is 1.1637326383892799\n",
      "at 4800 iteration loss is 1.2666640436412628\n",
      "at 4800 iteration loss is 1.0488925833344334\n",
      "at 4800 iteration loss is 1.371391878653887\n",
      "at 4800 iteration loss is 1.1085471183544364\n",
      "at 4800 iteration loss is 1.2364047263874303\n",
      "at 4800 iteration loss is 1.3537053939751484\n",
      "at 4800 iteration loss is 1.0427240695363265\n",
      "at 4800 iteration loss is 1.331277744182334\n",
      "at 4800 iteration loss is 1.6718930896337576\n",
      "at 4800 iteration loss is 1.2650844065265288\n",
      "at 4800 iteration loss is 1.0206829782269886\n",
      "at 4900 iteration loss is 1.0457545542356488\n",
      "at 4900 iteration loss is 1.2661776364196462\n",
      "at 4900 iteration loss is 1.1665923997941303\n",
      "at 4900 iteration loss is 1.3834119991160527\n",
      "at 4900 iteration loss is 1.0125078069121398\n",
      "at 4900 iteration loss is 1.3612331088119944\n",
      "at 4900 iteration loss is 1.1637143459499106\n",
      "at 4900 iteration loss is 1.2667138821626132\n",
      "at 4900 iteration loss is 1.0488895450051772\n",
      "at 4900 iteration loss is 1.3714738969848492\n",
      "at 4900 iteration loss is 1.1085265978369458\n",
      "at 4900 iteration loss is 1.2364363714571946\n",
      "at 4900 iteration loss is 1.3537516196685364\n",
      "at 4900 iteration loss is 1.042731105308834\n",
      "at 4900 iteration loss is 1.3312592641943326\n",
      "at 4900 iteration loss is 1.672060761361174\n",
      "at 4900 iteration loss is 1.265126377794925\n",
      "at 4900 iteration loss is 1.020688029833004\n",
      "at 5000 iteration loss is 1.045719869436228\n",
      "at 5000 iteration loss is 1.2662089474186065\n",
      "at 5000 iteration loss is 1.1666171394468443\n",
      "at 5000 iteration loss is 1.3834485986349732\n",
      "at 5000 iteration loss is 1.0125072532078772\n",
      "at 5000 iteration loss is 1.3612547050502246\n",
      "at 5000 iteration loss is 1.163698174520115\n",
      "at 5000 iteration loss is 1.2667579576846733\n",
      "at 5000 iteration loss is 1.0488868652038104\n",
      "at 5000 iteration loss is 1.3715464268051025\n",
      "at 5000 iteration loss is 1.1085084569043224\n",
      "at 5000 iteration loss is 1.236464346570162\n",
      "at 5000 iteration loss is 1.3537924958804552\n",
      "at 5000 iteration loss is 1.0427373211909\n",
      "at 5000 iteration loss is 1.3312429261161722\n",
      "at 5000 iteration loss is 1.6722090048947371\n",
      "at 5000 iteration loss is 1.2651634883272496\n",
      "at 5000 iteration loss is 1.0206925029953988\n",
      "at 5100 iteration loss is 1.0456892004804712\n",
      "at 5100 iteration loss is 1.266236638259781\n",
      "at 5100 iteration loss is 1.1666390246358802\n",
      "at 5100 iteration loss is 1.3834809702253892\n",
      "at 5100 iteration loss is 1.012506768557287\n",
      "at 5100 iteration loss is 1.3612738084619673\n",
      "at 5100 iteration loss is 1.1636838778768932\n",
      "at 5100 iteration loss is 1.2667969364128044\n",
      "at 5100 iteration loss is 1.0488845013300976\n",
      "at 5100 iteration loss is 1.3716105656406472\n",
      "at 5100 iteration loss is 1.1084924192945196\n",
      "at 5100 iteration loss is 1.2364890774963146\n",
      "at 5100 iteration loss is 1.3538286418494456\n",
      "at 5100 iteration loss is 1.0427428126296698\n",
      "at 5100 iteration loss is 1.3312284811232584\n",
      "at 5100 iteration loss is 1.6723400724612465\n",
      "at 5100 iteration loss is 1.265196300794362\n",
      "at 5100 iteration loss is 1.020696463445772\n",
      "at 5200 iteration loss is 1.045662081781762\n",
      "at 5200 iteration loss is 1.2662611275374136\n",
      "at 5200 iteration loss is 1.1666583842622422\n",
      "at 5200 iteration loss is 1.3835096021189273\n",
      "at 5200 iteration loss is 1.012506344046806\n",
      "at 5200 iteration loss is 1.3612907067084552\n",
      "at 5200 iteration loss is 1.1636712384441368\n",
      "at 5200 iteration loss is 1.2668314075707534\n",
      "at 5200 iteration loss is 1.0488824159035814\n",
      "at 5200 iteration loss is 1.3716672840964739\n",
      "at 5200 iteration loss is 1.1084782408882696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at 5200 iteration loss is 1.2365109405830534\n",
      "at 5200 iteration loss is 1.3538606050888904\n",
      "at 5200 iteration loss is 1.0427476639914919\n",
      "at 5200 iteration loss is 1.3312157094261405\n",
      "at 5200 iteration loss is 1.672455954968362\n",
      "at 5200 iteration loss is 1.265225312795272\n",
      "at 5200 iteration loss is 1.020699969554715\n",
      "at 5300 iteration loss is 1.045638101880003\n",
      "at 5300 iteration loss is 1.2662827854276137\n",
      "at 5300 iteration loss is 1.1666755094182697\n",
      "at 5300 iteration loss is 1.3835349261916536\n",
      "at 5300 iteration loss is 1.012505971974143\n",
      "at 5300 iteration loss is 1.3613056542624595\n",
      "at 5300 iteration loss is 1.1636600639458885\n",
      "at 5300 iteration loss is 1.2668618922902923\n",
      "at 5300 iteration loss is 1.0488805759364725\n",
      "at 5300 iteration loss is 1.3717174405290737\n",
      "at 5300 iteration loss is 1.1084657059542093\n",
      "at 5300 iteration loss is 1.2365302684969859\n",
      "at 5300 iteration loss is 1.3538888697053963\n",
      "at 5300 iteration loss is 1.0427519498403406\n",
      "at 5300 iteration loss is 1.3312044168535784\n",
      "at 5300 iteration loss is 1.6725584123736126\n",
      "at 5300 iteration loss is 1.2652509643681689\n",
      "at 5300 iteration loss is 1.0207030731323983\n",
      "at 5400 iteration loss is 1.0456168971155713\n",
      "at 5400 iteration loss is 1.2663019392936294\n",
      "at 5400 iteration loss is 1.1666906577157534\n",
      "at 5400 iteration loss is 1.3835573244655148\n",
      "at 5400 iteration loss is 1.012505645671691\n",
      "at 5400 iteration loss is 1.3613188762374953\n",
      "at 5400 iteration loss is 1.1636501844536036\n",
      "at 5400 iteration loss is 1.2668888514753958\n",
      "at 5400 iteration loss is 1.0488789523857829\n",
      "at 5400 iteration loss is 1.3717617940237015\n",
      "at 5400 iteration loss is 1.1084546238359112\n",
      "at 5400 iteration loss is 1.236547355297708\n",
      "at 5400 iteration loss is 1.3539138637500012\n",
      "at 5400 iteration loss is 1.0427557360706692\n",
      "at 5400 iteration loss is 1.3311944318440587\n",
      "at 5400 iteration loss is 1.6726490005135495\n",
      "at 5400 iteration loss is 1.2652736446377464\n",
      "at 5400 iteration loss is 1.020705820147399\n",
      "at 5500 iteration loss is 1.0455981460501387\n",
      "at 5500 iteration loss is 1.266318878641013\n",
      "at 5500 iteration loss is 1.166704057122438\n",
      "at 5500 iteration loss is 1.383577134860309\n",
      "at 5500 iteration loss is 1.0125053593579674\n",
      "at 5500 iteration loss is 1.361330571774991\n",
      "at 5500 iteration loss is 1.1636414497803582\n",
      "at 5500 iteration loss is 1.2669126927590575\n",
      "at 5500 iteration loss is 1.0488775196741986\n",
      "at 5500 iteration loss is 1.3718010158720617\n",
      "at 5500 iteration loss is 1.1084448260281234\n",
      "at 5500 iteration loss is 1.236562460921483\n",
      "at 5500 iteration loss is 1.353935965715216\n",
      "at 5500 iteration loss is 1.0427590809108216\n",
      "at 5500 iteration loss is 1.3311856027955717\n",
      "at 5500 iteration loss is 1.6727290948079303\n",
      "at 5500 iteration loss is 1.2652936976974374\n",
      "at 5500 iteration loss is 1.0207082513708838\n",
      "at 5600 iteration loss is 1.0455815645445115\n",
      "at 5600 iteration loss is 1.2663338594983395\n",
      "at 5600 iteration loss is 1.1667159093619124\n",
      "at 5600 iteration loss is 1.3835946562824712\n",
      "at 5600 iteration loss is 1.0125051080122178\n",
      "at 5600 iteration loss is 1.3613409170405357\n",
      "at 5600 iteration loss is 1.1636337271807489\n",
      "at 5600 iteration loss is 1.2669337766572435\n",
      "at 5600 iteration loss is 1.048876255270667\n",
      "at 5600 iteration loss is 1.3718356997235628\n",
      "at 5600 iteration loss is 1.1084361635959306\n",
      "at 5600 iteration loss is 1.2365758151435997\n",
      "at 5600 iteration loss is 1.3539555102775753\n",
      "at 5600 iteration loss is 1.0427620358114498\n",
      "at 5600 iteration loss is 1.3311777957299205\n",
      "at 5600 iteration loss is 1.6727999112047083\n",
      "at 5600 iteration loss is 1.2653114278140094\n",
      "at 5600 iteration loss is 1.020710402952971\n",
      "at 5700 iteration loss is 1.0455669014148474\n",
      "at 5700 iteration loss is 1.2663471082903037\n",
      "at 5700 iteration loss is 1.1667263929259222\n",
      "at 5700 iteration loss is 1.3836101531270593\n",
      "at 5700 iteration loss is 1.012504887268225\n",
      "at 5700 iteration loss is 1.361350067874348\n",
      "at 5700 iteration loss is 1.1636268993202032\n",
      "at 5700 iteration loss is 1.2669524220124853\n",
      "at 5700 iteration loss is 1.0488751393229312\n",
      "at 5700 iteration loss is 1.3718663705632774\n",
      "at 5700 iteration loss is 1.1084285048961695\n",
      "at 5700 iteration loss is 1.2365876210801339\n",
      "at 5700 iteration loss is 1.3539727933736352\n",
      "at 5700 iteration loss is 1.0427646462318252\n",
      "at 5700 iteration loss is 1.3311708922333332\n",
      "at 5700 iteration loss is 1.6728625246883824\n",
      "at 5700 iteration loss is 1.2653271040321468\n",
      "at 5700 iteration loss is 1.0207123069376471\n",
      "at 5800 iteration loss is 1.0455539345982745\n",
      "at 5800 iteration loss is 1.266358825262191\n",
      "at 5800 iteration loss is 1.1667356657428147\n",
      "at 5800 iteration loss is 1.3836238592605672\n",
      "at 5800 iteration loss is 1.0125046933241513\n",
      "at 5800 iteration loss is 1.3613581621359543\n",
      "at 5800 iteration loss is 1.163620862481857\n",
      "at 5800 iteration loss is 1.266968910809036\n",
      "at 5800 iteration loss is 1.0488741543353544\n",
      "at 5800 iteration loss is 1.3718934926521829\n",
      "at 5800 iteration loss is 1.1084217335653823\n",
      "at 5800 iteration loss is 1.2365980582827678\n",
      "at 5800 iteration loss is 1.3539880766870662\n",
      "at 5800 iteration loss is 1.0427669523356138\n",
      "at 5800 iteration loss is 1.3311647876401311\n",
      "at 5800 iteration loss is 1.6729178856363014\n",
      "at 5800 iteration loss is 1.2653409642478661\n",
      "at 5800 iteration loss is 1.020713991722269\n",
      "at 5900 iteration loss is 1.0455424677673821\n",
      "at 5900 iteration loss is 1.2663691875078\n",
      "at 5900 iteration loss is 1.1667438675409165\n",
      "at 5900 iteration loss is 1.3836359815443475\n",
      "at 5900 iteration loss is 1.0125045228657146\n",
      "at 5900 iteration loss is 1.3613653217783517\n",
      "at 5900 iteration loss is 1.1636155249829339\n",
      "at 5900 iteration loss is 1.2669834924320011\n",
      "at 5900 iteration loss is 1.0488732848862272\n",
      "at 5900 iteration loss is 1.3719174765494855\n",
      "at 5900 iteration loss is 1.1084157467428386\n",
      "at 5900 iteration loss is 1.2366072854740082\n",
      "at 5900 iteration loss is 1.35400159161534\n",
      "at 5900 iteration loss is 1.042768989606335\n",
      "at 5900 iteration loss is 1.3311593894301381\n",
      "at 5900 iteration loss is 1.6729668342739683\n",
      "at 5900 iteration loss is 1.2653532188117393\n",
      "at 5900 iteration loss is 1.0207154824671383\n",
      "at 6000 iteration loss is 1.0455323273404382\n",
      "at 6000 iteration loss is 1.2663783516468585\n",
      "at 6000 iteration loss is 1.1667511219414668\n",
      "at 6000 iteration loss is 1.383646702951626\n",
      "at 6000 iteration loss is 1.012504373000613\n",
      "at 6000 iteration loss is 1.3613716546828993\n",
      "at 6000 iteration loss is 1.1636108057759806\n",
      "at 6000 iteration loss is 1.2669963874346264\n",
      "at 6000 iteration loss is 1.0488725173795852\n",
      "at 6000 iteration loss is 1.3719386853231377\n",
      "at 6000 iteration loss is 1.1084104535009687\n",
      "at 6000 iteration loss is 1.236615442964669\n",
      "at 6000 iteration loss is 1.3540135427765354\n",
      "at 6000 iteration loss is 1.0427707893916818\n",
      "at 6000 iteration loss is 1.3311546158143708\n",
      "at 6000 iteration loss is 1.6730101134509892\n",
      "at 6000 iteration loss is 1.2653640537160156\n",
      "at 6000 iteration loss is 1.020716801460262\n",
      "at 6100 iteration loss is 1.0455233598405975\n",
      "at 6100 iteration loss is 1.2663864561925686\n",
      "at 6100 iteration loss is 1.1667575383117694\n",
      "at 6100 iteration loss is 1.3836561853249243\n",
      "at 6100 iteration loss is 1.0125042412023566\n",
      "at 6100 iteration loss is 1.3613772562825652\n",
      "at 6100 iteration loss is 1.1636066332132287\n",
      "at 6100 iteration loss is 1.2670077908704533\n",
      "at 6100 iteration loss is 1.048871839827202\n",
      "at 6100 iteration loss is 1.371957440042321\n",
      "at 6100 iteration loss is 1.1084057734588404\n",
      "at 6100 iteration loss is 1.2366226547905677\n",
      "at 6100 iteration loss is 1.3540241111097013\n",
      "at 6100 iteration loss is 1.0427723793848322\n",
      "at 6100 iteration loss is 1.3311503944865084\n",
      "at 6100 iteration loss is 1.6730483799332838\n",
      "at 6100 iteration loss is 1.2653736334135164\n",
      "at 6100 iteration loss is 1.020717968441927\n",
      "at 6200 iteration loss is 1.045515429562983\n",
      "at 6200 iteration loss is 1.2663936236452031\n",
      "at 6200 iteration loss is 1.1667632134058645\n",
      "at 6200 iteration loss is 1.3836645718153595\n",
      "at 6200 iteration loss is 1.0125041252620648\n",
      "at 6200 iteration loss is 1.3613822109979234\n",
      "at 6200 iteration loss is 1.1636029439549194\n",
      "at 6200 iteration loss is 1.2670178752405707\n",
      "at 6200 iteration loss is 1.0488712416569728\n",
      "at 6200 iteration loss is 1.3719740246348766\n",
      "at 6200 iteration loss is 1.108401635557183\n",
      "at 6200 iteration loss is 1.2366290306010863\n",
      "at 6200 iteration loss is 1.3540334566159635\n",
      "at 6200 iteration loss is 1.0427737840499478\n",
      "at 6200 iteration loss is 1.331146661520501\n",
      "at 6200 iteration loss is 1.6730822143842812\n",
      "at 6200 iteration loss is 1.2653821033107395\n",
      "at 6200 iteration loss is 1.0207190008933187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at 6300 iteration loss is 1.0455084165134747\n",
      "at 6300 iteration loss is 1.2663999623435043\n",
      "at 6300 iteration loss is 1.1667682328169207\n",
      "at 6300 iteration loss is 1.3836719890404847\n",
      "at 6300 iteration loss is 1.0125040232469982\n",
      "at 6300 iteration loss is 1.3613865935075338\n",
      "at 6300 iteration loss is 1.1635996820047594\n",
      "at 6300 iteration loss is 1.267026793100381\n",
      "at 6300 iteration loss is 1.0488707135444426\n",
      "at 6300 iteration loss is 1.3719886901830887\n",
      "at 6300 iteration loss is 1.1083979769760648\n",
      "at 6300 iteration loss is 1.2366346673284436\n",
      "at 6300 iteration loss is 1.3540417207820927\n",
      "at 6300 iteration loss is 1.0427750249983134\n",
      "at 6300 iteration loss is 1.3311433603969998\n",
      "at 6300 iteration loss is 1.6731121301876428\n",
      "at 6300 iteration loss is 1.2653895919727052\n",
      "at 6300 iteration loss is 1.0207199142930041\n",
      "at 6400 iteration loss is 1.0455022145873307\n",
      "at 6400 iteration loss is 1.266405568101943\n",
      "at 6400 iteration loss is 1.1667726722628504\n",
      "at 6400 iteration loss is 1.383678548993156\n",
      "at 6400 iteration loss is 1.0125039334648265\n",
      "at 6400 iteration loss is 1.3613904698718078\n",
      "at 6400 iteration loss is 1.1635967978576107\n",
      "at 6400 iteration loss is 1.2670346793652008\n",
      "at 6400 iteration loss is 1.0488702472646128\n",
      "at 6400 iteration loss is 1.372001658722739\n",
      "at 6400 iteration loss is 1.108394742178513\n",
      "at 6400 iteration loss is 1.2366396506631792\n",
      "at 6400 iteration loss is 1.3540490287233689\n",
      "at 6400 iteration loss is 1.042776121320771\n",
      "at 6400 iteration loss is 1.331140441143432\n",
      "at 6400 iteration loss is 1.6731385812462185\n",
      "at 6400 iteration loss is 1.2653962130728287\n",
      "at 6400 iteration loss is 1.0207207223447372\n",
      "at 6500 iteration loss is 1.0454967299595572\n",
      "at 6500 iteration loss is 1.2664105256586105\n",
      "at 6500 iteration loss is 1.1667765987241825\n",
      "at 6500 iteration loss is 1.383684350730093\n",
      "at 6500 iteration loss is 1.0125038544327467\n",
      "at 6500 iteration loss is 1.361393898527231\n",
      "at 6500 iteration loss is 1.1635942477463055\n",
      "at 6500 iteration loss is 1.2670416533494393\n",
      "at 6500 iteration loss is 1.0488698355615278\n",
      "at 6500 iteration loss is 1.3720131266028277\n",
      "at 6500 iteration loss is 1.108391882065367\n",
      "at 6500 iteration loss is 1.236644056358341\n",
      "at 6500 iteration loss is 1.354055491078282\n",
      "at 6500 iteration loss is 1.0427770898815094\n",
      "at 6500 iteration loss is 1.331137859574294\n",
      "at 6500 iteration loss is 1.673161968876223\n",
      "at 6500 iteration loss is 1.2654020671172135\n",
      "at 6500 iteration loss is 1.0207214371796922\n",
      "at 6600 iteration loss is 1.0454918796622583\n",
      "at 6600 iteration loss is 1.266414909955678\n",
      "at 6600 iteration loss is 1.1667800714511232\n",
      "at 6600 iteration loss is 1.3836894818655732\n",
      "at 6600 iteration loss is 1.012503784850772\n",
      "at 6600 iteration loss is 1.3613969311659284\n",
      "at 6600 iteration loss is 1.1635919929759961\n",
      "at 6600 iteration loss is 1.2670478205701556\n",
      "at 6600 iteration loss is 1.048869472033482\n",
      "at 6600 iteration loss is 1.3720232674567743\n",
      "at 6600 iteration loss is 1.108389353228376\n",
      "at 6600 iteration loss is 1.2366479513823063\n",
      "at 6600 iteration loss is 1.3540612056838701\n",
      "at 6600 iteration loss is 1.0427779455776711\n",
      "at 6600 iteration loss is 1.3311355766199362\n",
      "at 6600 iteration loss is 1.6731826479017797\n",
      "at 6600 iteration loss is 1.2654072429694527\n",
      "at 6600 iteration loss is 1.02072206953593\n",
      "at 6700 iteration loss is 1.045487590327204\n",
      "at 6700 iteration loss is 1.266418787271816\n",
      "at 6700 iteration loss is 1.1667831428547646\n",
      "at 6700 iteration loss is 1.383694019892733\n",
      "at 6700 iteration loss is 1.0125037235785832\n",
      "at 6700 iteration loss is 1.361399613513789\n",
      "at 6700 iteration loss is 1.1635899993358827\n",
      "at 6700 iteration loss is 1.2670532743421723\n",
      "at 6700 iteration loss is 1.048869151031958\n",
      "at 6700 iteration loss is 1.37203223483001\n",
      "at 6700 iteration loss is 1.1083871172900976\n",
      "at 6700 iteration loss is 1.2366513949378022\n",
      "at 6700 iteration loss is 1.3540662590570884\n",
      "at 6700 iteration loss is 1.042778701568748\n",
      "at 6700 iteration loss is 1.3311335577334407\n",
      "at 6700 iteration loss is 1.6732009320426626\n",
      "at 6700 iteration loss is 1.265411819198952\n",
      "at 6700 iteration loss is 1.020722628917586\n",
      "at 6800 iteration loss is 1.0454837970742523\n",
      "at 6800 iteration loss is 1.2664222162236691\n",
      "at 6800 iteration loss is 1.1667858592957336\n",
      "at 6800 iteration loss is 1.3836980333523532\n",
      "at 6800 iteration loss is 1.012503669615426\n",
      "at 6800 iteration loss is 1.361401986018832\n",
      "at 6800 iteration loss is 1.1635882365792314\n",
      "at 6800 iteration loss is 1.2670580971888523\n",
      "at 6800 iteration loss is 1.0488688675725966\n",
      "at 6800 iteration loss is 1.372040164503678\n",
      "at 6800 iteration loss is 1.1083851403204572\n",
      "at 6800 iteration loss is 1.2366544393626697\n",
      "at 6800 iteration loss is 1.354070727704709\n",
      "at 6800 iteration loss is 1.042779369479248\n",
      "at 6800 iteration loss is 1.3311317723664469\n",
      "at 6800 iteration loss is 1.6732170986773496\n",
      "at 6800 iteration loss is 1.2654158652731975\n",
      "at 6800 iteration loss is 1.0207231237360437\n",
      "at 6900 iteration loss is 1.0454804425287227\n",
      "at 6900 iteration loss is 1.2664252486515508\n",
      "at 6900 iteration loss is 1.1667882617820462\n",
      "at 6900 iteration loss is 1.3837015828667294\n",
      "at 6900 iteration loss is 1.0125036220826462\n",
      "at 6900 iteration loss is 1.36140408446018\n",
      "at 6900 iteration loss is 1.1635866779637802\n",
      "at 6900 iteration loss is 1.2670623620898074\n",
      "at 6900 iteration loss is 1.0488686172567783\n",
      "at 6900 iteration loss is 1.3720471765495812\n",
      "at 6900 iteration loss is 1.1083833923210595\n",
      "at 6900 iteration loss is 1.2366571309260996\n",
      "at 6900 iteration loss is 1.3540746792815943\n",
      "at 6900 iteration loss is 1.0427799595777512\n",
      "at 6900 iteration loss is 1.3311301935058721\n",
      "at 6900 iteration loss is 1.6732313930538436\n",
      "at 6900 iteration loss is 1.2654194426119951\n",
      "at 6900 iteration loss is 1.0207235614350814\n",
      "at 7000 iteration loss is 1.0454774759526757\n",
      "at 7000 iteration loss is 1.2664279304027588\n",
      "at 7000 iteration loss is 1.166790386586587\n",
      "at 7000 iteration loss is 1.3837047220541905\n",
      "at 7000 iteration loss is 1.0125035802084832\n",
      "at 7000 iteration loss is 1.3614059404867926\n",
      "at 7000 iteration loss is 1.1635852998454894\n",
      "at 7000 iteration loss is 1.2670661335843953\n",
      "at 7000 iteration loss is 1.0488683962025216\n",
      "at 7000 iteration loss is 1.3720533771474668\n",
      "at 7000 iteration loss is 1.108381846769363\n",
      "at 7000 iteration loss is 1.2366595105324887\n",
      "at 7000 iteration loss is 1.3540781736149237\n",
      "at 7000 iteration loss is 1.0427804809350973\n",
      "at 7000 iteration loss is 1.331128797264438\n",
      "at 7000 iteration loss is 1.6732440320123871\n",
      "at 7000 iteration loss is 1.265422605519654\n",
      "at 7000 iteration loss is 1.0207239486017918\n",
      "at 7100 iteration loss is 1.0454748524768636\n",
      "at 7100 iteration loss is 1.26643030202433\n",
      "at 7100 iteration loss is 1.1667922657934509\n",
      "at 7100 iteration loss is 1.3837074983380422\n",
      "at 7100 iteration loss is 1.0125035433148166\n",
      "at 7100 iteration loss is 1.361407582094059\n",
      "at 7100 iteration loss is 1.1635840813194307\n",
      "at 7100 iteration loss is 1.2670694687476591\n",
      "at 7100 iteration loss is 1.0488682009835855\n",
      "at 7100 iteration loss is 1.372058860192107\n",
      "at 7100 iteration loss is 1.1083804802157489\n",
      "at 7100 iteration loss is 1.2366616143436264\n",
      "at 7100 iteration loss is 1.3540812636098853\n",
      "at 7100 iteration loss is 1.0427809415641243\n",
      "at 7100 iteration loss is 1.331127562518693\n",
      "at 7100 iteration loss is 1.6732552072766769\n",
      "at 7100 iteration loss is 1.2654254020092293\n",
      "at 7100 iteration loss is 1.0207242910648684\n",
      "at 7200 iteration loss is 1.0454725324216647\n",
      "at 7200 iteration loss is 1.2664323993757214\n",
      "at 7200 iteration loss is 1.1667939277813228\n",
      "at 7200 iteration loss is 1.3837099536621094\n",
      "at 7200 iteration loss is 1.0125035108056106\n",
      "at 7200 iteration loss is 1.3614090340454097\n",
      "at 7200 iteration loss is 1.1635830039023323\n",
      "at 7200 iteration loss is 1.2670724180534432\n",
      "at 7200 iteration loss is 1.0488680285757854\n",
      "at 7200 iteration loss is 1.3720637087145022\n",
      "at 7200 iteration loss is 1.1083792719273429\n",
      "at 7200 iteration loss is 1.236663474328699\n",
      "at 7200 iteration loss is 1.3540839960505608\n",
      "at 7200 iteration loss is 1.0427813485431097\n",
      "at 7200 iteration loss is 1.33112647058902\n",
      "at 7200 iteration loss is 1.6732650883636306\n",
      "at 7200 iteration loss is 1.2654278745313081\n",
      "at 7200 iteration loss is 1.020724593981676\n",
      "at 7300 iteration loss is 1.045470480696651\n",
      "at 7300 iteration loss is 1.26643425417067\n",
      "at 7300 iteration loss is 1.1667953976511387\n",
      "at 7300 iteration loss is 1.3837121251236661\n",
      "at 7300 iteration loss is 1.0125034821568186\n",
      "at 7300 iteration loss is 1.3614103182452997\n",
      "at 7300 iteration loss is 1.1635820512519508\n",
      "at 7300 iteration loss is 1.2670750261377404\n",
      "at 7300 iteration loss is 1.0488678763096684\n",
      "at 7300 iteration loss is 1.3720679961386908\n",
      "at 7300 iteration loss is 1.1083782035731502\n",
      "at 7300 iteration loss is 1.236665118750492\n",
      "at 7300 iteration loss is 1.35408641230813\n",
      "at 7300 iteration loss is 1.0427817081248154\n",
      "at 7300 iteration loss is 1.3311255049567543\n",
      "at 7300 iteration loss is 1.6732738251559538\n",
      "at 7300 iteration loss is 1.265430060618404\n",
      "at 7300 iteration loss is 1.0207248619153788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at 7400 iteration loss is 1.0454686662696946\n",
      "at 7400 iteration loss is 1.2664358944564182\n",
      "at 7400 iteration loss is 1.1667966976044368\n",
      "at 7400 iteration loss is 1.3837140455332837\n",
      "at 7400 iteration loss is 1.0125034569075688\n",
      "at 7400 iteration loss is 1.3614114540691604\n",
      "at 7400 iteration loss is 1.163581208918984\n",
      "at 7400 iteration loss is 1.2670773324737812\n",
      "at 7400 iteration loss is 1.0488677418287824\n",
      "at 7400 iteration loss is 1.3720717873931858\n",
      "at 7400 iteration loss is 1.1083772589457075\n",
      "at 7400 iteration loss is 1.236666572595191\n",
      "at 7400 iteration loss is 1.3540885489671375\n",
      "at 7400 iteration loss is 1.0427820258328082\n",
      "at 7400 iteration loss is 1.3311246510140844\n",
      "at 7400 iteration loss is 1.6732815501765888\n",
      "at 7400 iteration loss is 1.2654319934547016\n",
      "at 7400 iteration loss is 1.0207250989032457\n",
      "at 7500 iteration loss is 1.0454670616975084\n",
      "at 7500 iteration loss is 1.2664373450375468\n",
      "at 7500 iteration loss is 1.1667978472780782\n",
      "at 7500 iteration loss is 1.3837157439100203\n",
      "at 7500 iteration loss is 1.0125034346524386\n",
      "at 7500 iteration loss is 1.3614124586552847\n",
      "at 7500 iteration loss is 1.1635804641277399\n",
      "at 7500 iteration loss is 1.267079371969072\n",
      "at 7500 iteration loss is 1.0488676230528768\n",
      "at 7500 iteration loss is 1.372075139893839\n",
      "at 7500 iteration loss is 1.1083764237150129\n",
      "at 7500 iteration loss is 1.2366678579523287\n",
      "at 7500 iteration loss is 1.3540904383792913\n",
      "at 7500 iteration loss is 1.0427823065465347\n",
      "at 7500 iteration loss is 1.331123895842913\n",
      "at 7500 iteration loss is 1.6732883805996341\n",
      "at 7500 iteration loss is 1.2654337023798214\n",
      "at 7500 iteration loss is 1.0207253085171342\n",
      "at 7600 iteration loss is 1.045465642710548\n",
      "at 7600 iteration loss is 1.2664386278508228\n",
      "at 7600 iteration loss is 1.1667988640403526\n",
      "at 7600 iteration loss is 1.3837172459194413\n",
      "at 7600 iteration loss is 1.01250341503471\n",
      "at 7600 iteration loss is 1.3614133471630416\n",
      "at 7600 iteration loss is 1.1635798055822466\n",
      "at 7600 iteration loss is 1.267081175493414\n",
      "at 7600 iteration loss is 1.0488675181454483\n",
      "at 7600 iteration loss is 1.372078104413021\n",
      "at 7600 iteration loss is 1.1083756852109836\n",
      "at 7600 iteration loss is 1.2366689943506604\n",
      "at 7600 iteration loss is 1.3540921091531877\n",
      "at 7600 iteration loss is 1.0427825545764842\n",
      "at 7600 iteration loss is 1.3311232280193492\n",
      "at 7600 iteration loss is 1.673294420028266\n",
      "at 7600 iteration loss is 1.2654352133342228\n",
      "at 7600 iteration loss is 1.0207254939170451\n",
      "at 7700 iteration loss is 1.0454643878459275\n",
      "at 7700 iteration loss is 1.2664397622967147\n",
      "at 7700 iteration loss is 1.1667997632529334\n",
      "at 7700 iteration loss is 1.3837185742610452\n",
      "at 7700 iteration loss is 1.012503397740454\n",
      "at 7700 iteration loss is 1.3614141330012977\n",
      "at 7700 iteration loss is 1.1635792232948239\n",
      "at 7700 iteration loss is 1.2670827703458591\n",
      "at 7700 iteration loss is 1.0488674254851127\n",
      "at 7700 iteration loss is 1.3720807258482433\n",
      "at 7700 iteration loss is 1.1083750322311383\n",
      "at 7700 iteration loss is 1.2366699990550898\n",
      "at 7700 iteration loss is 1.3540935865873749\n",
      "at 7700 iteration loss is 1.0427827737305622\n",
      "at 7700 iteration loss is 1.3311226374408363\n",
      "at 7700 iteration loss is 1.6732997600666664\n",
      "at 7700 iteration loss is 1.2654365492530162\n",
      "at 7700 iteration loss is 1.0207256578985326\n",
      "at 7800 iteration loss is 1.0454632781228175\n",
      "at 7800 iteration loss is 1.2664407655325907\n",
      "at 7800 iteration loss is 1.1668005585025942\n",
      "at 7800 iteration loss is 1.3837197490109383\n",
      "at 7800 iteration loss is 1.0125033824933352\n",
      "at 7800 iteration loss is 1.3614148280304774\n",
      "at 7800 iteration loss is 1.163578708434525\n",
      "at 7800 iteration loss is 1.2670841806676802\n",
      "at 7800 iteration loss is 1.0488673436403464\n",
      "at 7800 iteration loss is 1.3720830439018694\n",
      "at 7800 iteration loss is 1.1083744548705565\n",
      "at 7800 iteration loss is 1.236670887329145\n",
      "at 7800 iteration loss is 1.3540948930533054\n",
      "at 7800 iteration loss is 1.0427829673727242\n",
      "at 7800 iteration loss is 1.3311221151732782\n",
      "at 7800 iteration loss is 1.6733044817098464\n",
      "at 7800 iteration loss is 1.265437730414145\n",
      "at 7800 iteration loss is 1.0207258029346717\n",
      "at 7900 iteration loss is 1.0454622967553981\n",
      "at 7900 iteration loss is 1.2664416527320301\n",
      "at 7900 iteration loss is 1.1668012618062\n",
      "at 7900 iteration loss is 1.3837207879249536\n",
      "at 7900 iteration loss is 1.0125033690500798\n",
      "at 7900 iteration loss is 1.3614154427413137\n",
      "at 7900 iteration loss is 1.1635782531931496\n",
      "at 7900 iteration loss is 1.2670854278075896\n",
      "at 7900 iteration loss is 1.0488672713472131\n",
      "at 7900 iteration loss is 1.372085093682198\n",
      "at 7900 iteration loss is 1.1083739443715661\n",
      "at 7900 iteration loss is 1.2366716726670328\n",
      "at 7900 iteration loss is 1.3540960483340014\n",
      "at 7900 iteration loss is 1.042783138474773\n",
      "at 7900 iteration loss is 1.331121653315887\n",
      "at 7900 iteration loss is 1.6733086565724649\n",
      "at 7900 iteration loss is 1.2654387747462466\n",
      "at 7900 iteration loss is 1.0207259312132106\n",
      "at 8000 iteration loss is 1.0454614288990114\n",
      "at 8000 iteration loss is 1.2664424373141567\n",
      "at 8000 iteration loss is 1.166801883792023\n",
      "at 8000 iteration loss is 1.3837217067067331\n",
      "at 8000 iteration loss is 1.0125033571964828\n",
      "at 8000 iteration loss is 1.361415986412974\n",
      "at 8000 iteration loss is 1.1635778506667713\n",
      "at 8000 iteration loss is 1.267086530644721\n",
      "at 8000 iteration loss is 1.0488672074896992\n",
      "at 8000 iteration loss is 1.3720869062350014\n",
      "at 8000 iteration loss is 1.1083734929908324\n",
      "at 8000 iteration loss is 1.236672366998763\n",
      "at 8000 iteration loss is 1.3540970699235122\n",
      "at 8000 iteration loss is 1.0427832896620963\n",
      "at 8000 iteration loss is 1.3311212448816476\n",
      "at 8000 iteration loss is 1.6733123479752874\n",
      "at 8000 iteration loss is 1.2654396981008311\n",
      "at 8000 iteration loss is 1.0207260446694435\n",
      "at 8100 iteration loss is 1.0454606614256838\n",
      "at 8100 iteration loss is 1.2664431311464692\n",
      "at 8100 iteration loss is 1.1668024338601404\n",
      "at 8100 iteration loss is 1.3837225192448603\n",
      "at 8100 iteration loss is 1.012503346743903\n",
      "at 8100 iteration loss is 1.3614164672529303\n",
      "at 8100 iteration loss is 1.1635774947510031\n",
      "at 8100 iteration loss is 1.2670875058742663\n",
      "at 8100 iteration loss is 1.0488671510823733\n",
      "at 8100 iteration loss is 1.3720885090135733\n",
      "at 8100 iteration loss is 1.1083730938818612\n",
      "at 8100 iteration loss is 1.2366729808714996\n",
      "at 8100 iteration loss is 1.3540979732917509\n",
      "at 8100 iteration loss is 1.042783423254079\n",
      "at 8100 iteration loss is 1.3311208836916304\n",
      "at 8100 iteration loss is 1.6733156119057995\n",
      "at 8100 iteration loss is 1.265440514492938\n",
      "at 8100 iteration loss is 1.020726145015313\n",
      "at 8200 iteration loss is 1.045459982725604\n",
      "at 8200 iteration loss is 1.2664437447242205\n",
      "at 8200 iteration loss is 1.1668029203243084\n",
      "at 8200 iteration loss is 1.3837232378225912\n",
      "at 8200 iteration loss is 1.0125033375261905\n",
      "at 8200 iteration loss is 1.3614168925206935\n",
      "at 8200 iteration loss is 1.1635771800483858\n",
      "at 8200 iteration loss is 1.2670883682600778\n",
      "at 8200 iteration loss is 1.0488671012550772\n",
      "at 8200 iteration loss is 1.3720899262943969\n",
      "at 8200 iteration loss is 1.10837274099111\n",
      "at 8200 iteration loss is 1.2366735236098774\n",
      "at 8200 iteration loss is 1.3540987721186741\n",
      "at 8200 iteration loss is 1.042783541299792\n",
      "at 8200 iteration loss is 1.3311205642815216\n",
      "at 8200 iteration loss is 1.673318497867538\n",
      "at 8200 iteration loss is 1.265441236313901\n",
      "at 8200 iteration loss is 1.0207262337651593\n",
      "at 8300 iteration loss is 1.0454593825315672\n",
      "at 8300 iteration loss is 1.26644428732907\n",
      "at 8300 iteration loss is 1.1668033505374624\n",
      "at 8300 iteration loss is 1.383723873303369\n",
      "at 8300 iteration loss is 1.0125033293969907\n",
      "at 8300 iteration loss is 1.361417268637268\n",
      "at 8300 iteration loss is 1.16357690178652\n",
      "at 8300 iteration loss is 1.2670891308580625\n",
      "at 8300 iteration loss is 1.0488670572394203\n",
      "at 8300 iteration loss is 1.372091179544729\n",
      "at 8300 iteration loss is 1.1083724289661376\n",
      "at 8300 iteration loss is 1.2366740034577257\n",
      "at 8300 iteration loss is 1.3540994785013816\n",
      "at 8300 iteration loss is 1.0427836456095207\n",
      "at 8300 iteration loss is 1.3311202818189805\n",
      "at 8300 iteration loss is 1.6733210496310567\n",
      "at 8300 iteration loss is 1.2654418745194778\n",
      "at 8300 iteration loss is 1.0207263122585064\n",
      "at 8400 iteration loss is 1.045458851763716\n",
      "at 8400 iteration loss is 1.266444767169386\n",
      "at 8400 iteration loss is 1.166803731002717\n",
      "at 8400 iteration loss is 1.3837244352948928\n",
      "at 8400 iteration loss is 1.012503322227368\n",
      "at 8400 iteration loss is 1.3614176012819672\n",
      "at 8400 iteration loss is 1.1635766557456653\n",
      "at 8400 iteration loss is 1.2670898052137374\n",
      "at 8400 iteration loss is 1.0488670183568547\n",
      "at 8400 iteration loss is 1.3720922877476434\n",
      "at 8400 iteration loss is 1.1083721530743962\n",
      "at 8400 iteration loss is 1.236674427703366\n",
      "at 8400 iteration loss is 1.354100103137245\n",
      "at 8400 iteration loss is 1.042783737782604\n",
      "at 8400 iteration loss is 1.3311200320305419\n",
      "at 8400 iteration loss is 1.6733233058978905\n",
      "at 8400 iteration loss is 1.265442438796166\n",
      "at 8400 iteration loss is 1.0207263816802283\n",
      "at 8500 iteration loss is 1.0454583823922392\n",
      "at 8500 iteration loss is 1.2664451915043418\n",
      "at 8500 iteration loss is 1.1668040674715547\n",
      "at 8500 iteration loss is 1.3837249322942413\n",
      "at 8500 iteration loss is 1.0125033159037176\n",
      "at 8500 iteration loss is 1.361417895478058\n",
      "at 8500 iteration loss is 1.1635764381947347\n",
      "at 8500 iteration loss is 1.2670904015369358\n",
      "at 8500 iteration loss is 1.0488669840081533\n",
      "at 8500 iteration loss is 1.3720932676894761\n",
      "at 8500 iteration loss is 1.1083719091314308\n",
      "at 8500 iteration loss is 1.236674802790375\n",
      "at 8500 iteration loss is 1.354100655485856\n",
      "at 8500 iteration loss is 1.0427838192320389\n",
      "at 8500 iteration loss is 1.3311198111369773\n",
      "at 8500 iteration loss is 1.6733253008876292\n",
      "at 8500 iteration loss is 1.2654429377082594\n",
      "at 8500 iteration loss is 1.0207264430783813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at 8600 iteration loss is 1.0454579673159516\n",
      "at 8600 iteration loss is 1.2664455667536583\n",
      "at 8600 iteration loss is 1.1668043650306754\n",
      "at 8600 iteration loss is 1.3837253718162263\n",
      "at 8600 iteration loss is 1.0125033103259384\n",
      "at 8600 iteration loss is 1.3614181556685252\n",
      "at 8600 iteration loss is 1.163576245834713\n",
      "at 8600 iteration loss is 1.267090928856317\n",
      "at 8600 iteration loss is 1.048866953664131\n",
      "at 8600 iteration loss is 1.3720941342140196\n",
      "at 8600 iteration loss is 1.1083716934373986\n",
      "at 8600 iteration loss is 1.2366751344155116\n",
      "at 8600 iteration loss is 1.3541011439122435\n",
      "at 8600 iteration loss is 1.0427838912062075\n",
      "at 8600 iteration loss is 1.3311196157961533\n",
      "at 8600 iteration loss is 1.673327064856985\n",
      "at 8600 iteration loss is 1.265443378827868\n",
      "at 8600 iteration loss is 1.0207264973800012\n",
      "at 8700 iteration loss is 1.0454576002549054\n",
      "at 8700 iteration loss is 1.2664458985946636\n",
      "at 8700 iteration loss is 1.1668046281788071\n",
      "at 8700 iteration loss is 1.3837257605069244\n",
      "at 8700 iteration loss is 1.0125033054058172\n",
      "at 8700 iteration loss is 1.36141838578308\n",
      "at 8700 iteration loss is 1.1635760757486064\n",
      "at 8700 iteration loss is 1.2670913951559961\n",
      "at 8700 iteration loss is 1.0488669268574362\n",
      "at 8700 iteration loss is 1.3720949004472938\n",
      "at 8700 iteration loss is 1.1083715027209387\n",
      "at 8700 iteration loss is 1.236675427615284\n",
      "at 8700 iteration loss is 1.3541015758135093\n",
      "at 8700 iteration loss is 1.0427839548080626\n",
      "at 8700 iteration loss is 1.331119443052462\n",
      "at 8700 iteration loss is 1.673328624558745\n",
      "at 8700 iteration loss is 1.2654437688498668\n",
      "at 8700 iteration loss is 1.0207265454050611\n",
      "at 8800 iteration loss is 1.0454572756554283\n",
      "at 8800 iteration loss is 1.2664461920481305\n",
      "at 8800 iteration loss is 1.1668048608946553\n",
      "at 8800 iteration loss is 1.383726104244071\n",
      "at 8800 iteration loss is 1.0125033010656064\n",
      "at 8800 iteration loss is 1.3614185892974335\n",
      "at 8800 iteration loss is 1.1635759253572089\n",
      "at 8800 iteration loss is 1.267091807496374\n",
      "at 8800 iteration loss is 1.0488669031753208\n",
      "at 8800 iteration loss is 1.3720955779963155\n",
      "at 8800 iteration loss is 1.1083713340895456\n",
      "at 8800 iteration loss is 1.2366756868424835\n",
      "at 8800 iteration loss is 1.3541019577308222\n",
      "at 8800 iteration loss is 1.0427840110120865\n",
      "at 8800 iteration loss is 1.3311192902921285\n",
      "at 8800 iteration loss is 1.6733300036475651\n",
      "at 8800 iteration loss is 1.2654441136935268\n",
      "at 8800 iteration loss is 1.0207265878788292\n",
      "at 8900 iteration loss is 1.045456988606137\n",
      "at 8900 iteration loss is 1.2664464515541924\n",
      "at 8900 iteration loss is 1.1668050666969936\n",
      "at 8900 iteration loss is 1.3837264082258756\n",
      "at 8900 iteration loss is 1.0125032972367813\n",
      "at 8900 iteration loss is 1.3614187692857393\n",
      "at 8900 iteration loss is 1.1635757923799812\n",
      "at 8900 iteration loss is 1.2670921721209953\n",
      "at 8900 iteration loss is 1.04886688225325\n",
      "at 8900 iteration loss is 1.3720961771248767\n",
      "at 8900 iteration loss is 1.1083711849856903\n",
      "at 8900 iteration loss is 1.2366759160338443\n",
      "at 8900 iteration loss is 1.3541022954484507\n",
      "at 8900 iteration loss is 1.0427840606792624\n",
      "at 8900 iteration loss is 1.3311191552036823\n",
      "at 8900 iteration loss is 1.6733312230387631\n",
      "at 8900 iteration loss is 1.26544441859238\n",
      "at 8900 iteration loss is 1.020726625442801\n",
      "at 9000 iteration loss is 1.0454567347636625\n",
      "at 9000 iteration loss is 1.2664466810394823\n",
      "at 9000 iteration loss is 1.16680524869782\n",
      "at 9000 iteration loss is 1.3837266770495664\n",
      "at 9000 iteration loss is 1.0125032938589436\n",
      "at 9000 iteration loss is 1.3614189284669673\n",
      "at 9000 iteration loss is 1.1635756748004666\n",
      "at 9000 iteration loss is 1.2670924945510444\n",
      "at 9000 iteration loss is 1.0488668637692653\n",
      "at 9000 iteration loss is 1.3720967069089722\n",
      "at 9000 iteration loss is 1.1083710531480278\n",
      "at 9000 iteration loss is 1.2366761186698618\n",
      "at 9000 iteration loss is 1.354102594081343\n",
      "at 9000 iteration loss is 1.0427841045703057\n",
      "at 9000 iteration loss is 1.3311190357429925\n",
      "at 9000 iteration loss is 1.6733323012255652\n",
      "at 9000 iteration loss is 1.265444688173661\n",
      "at 9000 iteration loss is 1.020726658664372\n",
      "at 9100 iteration loss is 1.0454565102869677\n",
      "at 9100 iteration loss is 1.2664468839765106\n",
      "at 9100 iteration loss is 1.1668054096493665\n",
      "at 9100 iteration loss is 1.3837269147808477\n",
      "at 9100 iteration loss is 1.0125032908788447\n",
      "at 9100 iteration loss is 1.361419069245928\n",
      "at 9100 iteration loss is 1.163575570835706\n",
      "at 9100 iteration loss is 1.2670927796689093\n",
      "at 9100 iteration loss is 1.0488668474390004\n",
      "at 9100 iteration loss is 1.3720971753742537\n",
      "at 9100 iteration loss is 1.1083709365770908\n",
      "at 9100 iteration loss is 1.236676297827674\n",
      "at 9100 iteration loss is 1.3541028581525674\n",
      "at 9100 iteration loss is 1.0427841433573488\n",
      "at 9100 iteration loss is 1.3311189301023494\n",
      "at 9100 iteration loss is 1.6733332545596045\n",
      "at 9100 iteration loss is 1.2654449265285541\n",
      "at 9100 iteration loss is 1.0207266880453894\n",
      "at 9200 iteration loss is 1.0454563117792524\n",
      "at 9200 iteration loss is 1.2664470634361749\n",
      "at 9200 iteration loss is 1.1668055519856815\n",
      "at 9200 iteration loss is 1.3837271250153516\n",
      "at 9200 iteration loss is 1.0125032882495417\n",
      "at 9200 iteration loss is 1.3614191937495637\n",
      "at 9200 iteration loss is 1.1635754789092008\n",
      "at 9200 iteration loss is 1.2670930317920832\n",
      "at 9200 iteration loss is 1.0488668330112934\n",
      "at 9200 iteration loss is 1.372097589617573\n",
      "at 9200 iteration loss is 1.1083708335049618\n",
      "at 9200 iteration loss is 1.236676456227811\n",
      "at 9200 iteration loss is 1.354103091661799\n",
      "at 9200 iteration loss is 1.0427841776342572\n",
      "at 9200 iteration loss is 1.3311188366831217\n",
      "at 9200 iteration loss is 1.6733340974989315\n",
      "at 9200 iteration loss is 1.2654451372742916\n",
      "at 9200 iteration loss is 1.0207267140297227\n",
      "at 9300 iteration loss is 1.0454561362365902\n",
      "at 9300 iteration loss is 1.2664472221342051\n",
      "at 9300 iteration loss is 1.1668056778594038\n",
      "at 9300 iteration loss is 1.3837273109329675\n",
      "at 9300 iteration loss is 1.0125032859296494\n",
      "at 9300 iteration loss is 1.3614193038590456\n",
      "at 9300 iteration loss is 1.1635753976270071\n",
      "at 9300 iteration loss is 1.2670932547385143\n",
      "at 9300 iteration loss is 1.0488668202643008\n",
      "at 9300 iteration loss is 1.372097955914462\n",
      "at 9300 iteration loss is 1.108370742368462\n",
      "at 9300 iteration loss is 1.2366765962755295\n",
      "at 9300 iteration loss is 1.3541032981458767\n",
      "at 9300 iteration loss is 1.0427842079257634\n",
      "at 9300 iteration loss is 1.3311187540715828\n",
      "at 9300 iteration loss is 1.6733348428273054\n",
      "at 9300 iteration loss is 1.265445323609066\n",
      "at 9300 iteration loss is 1.0207267370099575\n",
      "at 9400 iteration loss is 1.045455981002481\n",
      "at 9400 iteration loss is 1.2664473624722294\n",
      "at 9400 iteration loss is 1.166805789174293\n",
      "at 9400 iteration loss is 1.383727475345911\n",
      "at 9400 iteration loss is 1.012503283882679\n",
      "at 9400 iteration loss is 1.3614194012381629\n",
      "at 9400 iteration loss is 1.1635753257565868\n",
      "at 9400 iteration loss is 1.2670934518844017\n",
      "at 9400 iteration loss is 1.0488668090020692\n",
      "at 9400 iteration loss is 1.372098279814179\n",
      "at 9400 iteration loss is 1.1083706617854303\n",
      "at 9400 iteration loss is 1.2366767200973512\n",
      "at 9400 iteration loss is 1.3541034807323649\n",
      "at 9400 iteration loss is 1.0427842346955045\n",
      "at 9400 iteration loss is 1.3311186810175213\n",
      "at 9400 iteration loss is 1.6733355018480893\n",
      "at 9400 iteration loss is 1.2654454883605766\n",
      "at 9400 iteration loss is 1.0207267573333216\n",
      "at 9500 iteration loss is 1.0454558437276857\n",
      "at 9500 iteration loss is 1.2664474865741024\n",
      "at 9500 iteration loss is 1.1668058876139942\n",
      "at 9500 iteration loss is 1.3837276207412168\n",
      "at 9500 iteration loss is 1.0125032820764528\n",
      "at 9500 iteration loss is 1.3614194873584387\n",
      "at 9500 iteration loss is 1.16357526220813\n",
      "at 9500 iteration loss is 1.2670936262152979\n",
      "at 9500 iteration loss is 1.0488667990515166\n",
      "at 9500 iteration loss is 1.3720985662237573\n",
      "at 9500 iteration loss is 1.1083705905337697\n",
      "at 9500 iteration loss is 1.2366768295733712\n",
      "at 9500 iteration loss is 1.3541036421869028\n",
      "at 9500 iteration loss is 1.0427842583531537\n",
      "at 9500 iteration loss is 1.3311186164153317\n",
      "at 9500 iteration loss is 1.6733360845556926\n",
      "at 9500 iteration loss is 1.265445634028951\n",
      "at 9500 iteration loss is 1.0207267753069154\n",
      "at 9600 iteration loss is 1.0454557223346832\n",
      "at 9600 iteration loss is 1.2664475963180277\n",
      "at 9600 iteration loss is 1.166805974667487\n",
      "at 9600 iteration loss is 1.383727749318349\n",
      "at 9600 iteration loss is 1.0125032804826009\n",
      "at 9600 iteration loss is 1.3614195635213406\n",
      "at 9600 iteration loss is 1.1635752060180162\n",
      "at 9600 iteration loss is 1.2670937803713112\n",
      "at 9600 iteration loss is 1.0488667902597535\n",
      "at 9600 iteration loss is 1.3720988194823245\n",
      "at 9600 iteration loss is 1.1083705275329048\n",
      "at 9600 iteration loss is 1.2366769263658146\n",
      "at 9600 iteration loss is 1.3541037849550892\n",
      "at 9600 iteration loss is 1.042784279260696\n",
      "at 9600 iteration loss is 1.3311185592872892\n",
      "at 9600 iteration loss is 1.6733365997871488\n",
      "at 9600 iteration loss is 1.2654457628246971\n",
      "at 9600 iteration loss is 1.0207267912023599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at 9700 iteration loss is 1.045455614986251\n",
      "at 9700 iteration loss is 1.2664476933649609\n",
      "at 9700 iteration loss is 1.1668060516515792\n",
      "at 9700 iteration loss is 1.3837278630224243\n",
      "at 9700 iteration loss is 1.0125032790760986\n",
      "at 9700 iteration loss is 1.3614196308779252\n",
      "at 9700 iteration loss is 1.1635751563342054\n",
      "at 9700 iteration loss is 1.2670939166870592\n",
      "at 9700 iteration loss is 1.0488667824917275\n",
      "at 9700 iteration loss is 1.3720990434268192\n",
      "at 9700 iteration loss is 1.108370471827393\n",
      "at 9700 iteration loss is 1.2366770119442878\n",
      "at 9700 iteration loss is 1.3541039111995095\n",
      "at 9700 iteration loss is 1.0427842977379869\n",
      "at 9700 iteration loss is 1.331118508768761\n",
      "at 9700 iteration loss is 1.673337055356147\n",
      "at 9700 iteration loss is 1.2654458767022492\n",
      "at 9700 iteration loss is 1.0207268052598784\n",
      "at 9800 iteration loss is 1.0454555200576756\n",
      "at 9800 iteration loss is 1.2664477791837438\n",
      "at 9800 iteration loss is 1.1668061197308224\n",
      "at 9800 iteration loss is 1.3837279635736404\n",
      "at 9800 iteration loss is 1.0125032778348824\n",
      "at 9800 iteration loss is 1.361419690446223\n",
      "at 9800 iteration loss is 1.1635751124033236\n",
      "at 9800 iteration loss is 1.2670940372270296\n",
      "at 9800 iteration loss is 1.0488667756281425\n",
      "at 9800 iteration loss is 1.3720992414501179\n",
      "at 9800 iteration loss is 1.108370422572437\n",
      "at 9800 iteration loss is 1.2366770876081024\n",
      "at 9800 iteration loss is 1.35410402283249\n",
      "at 9800 iteration loss is 1.0427843140676607\n",
      "at 9800 iteration loss is 1.331118464095129\n",
      "at 9800 iteration loss is 1.6733374581715403\n",
      "at 9800 iteration loss is 1.2654459773896392\n",
      "at 9800 iteration loss is 1.020726817691941\n",
      "at 9900 iteration loss is 1.0454554361121697\n",
      "at 9900 iteration loss is 1.2664478550733154\n",
      "at 9900 iteration loss is 1.1668061799351068\n",
      "at 9900 iteration loss is 1.3837280524932698\n",
      "at 9900 iteration loss is 1.0125032767394921\n",
      "at 9900 iteration loss is 1.3614197431266017\n",
      "at 9900 iteration loss is 1.1635750735592292\n",
      "at 9900 iteration loss is 1.267094143816824\n",
      "at 9900 iteration loss is 1.0488667695636145\n",
      "at 9900 iteration loss is 1.3720994165524176\n",
      "at 9900 iteration loss is 1.1083703790210673\n",
      "at 9900 iteration loss is 1.2366771545060138\n",
      "at 9900 iteration loss is 1.3541041215450553\n",
      "at 9900 iteration loss is 1.042784328499463\n",
      "at 9900 iteration loss is 1.3311184245902195\n",
      "at 9900 iteration loss is 1.6733378143421356\n",
      "at 9900 iteration loss is 1.2654460664147298\n",
      "at 9900 iteration loss is 1.0207268286864588\n"
     ]
    }
   ],
   "source": [
    "data_cv=cross_validation(Train_data,4)\n",
    "scores=[]\n",
    "for val_set,train_set in train_test(data_cv,4):\n",
    "    x_val=val_set[:,0:4]\n",
    "    y_val=val_set[:,4]\n",
    "    train=np.vstack(train_set)\n",
    "    x_train=train[:,0:4]\n",
    "    y_train=train[:,4]\n",
    "    theta,b,_=mini_batch_fit(x_train,y_train,5,0.2,10000,3)\n",
    "    pred =predict(x_val,theta,b)\n",
    "    scores.append(accuracy(pred,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[80.0, 26.666666666666668, 36.666666666666664, 36.666666666666664]"
      ]
     },
     "execution_count": 857,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x280f5370c10>]"
      ]
     },
     "execution_count": 858,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
